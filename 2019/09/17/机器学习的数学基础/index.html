<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,">





  <link rel="alternate" href="/atom.xml" title="SunFeng's Blog" type="application/atom+xml">






<meta name="description" content="机器学习的数学基础">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习的数学基础">
<meta property="og:url" content="http://sunfeng.online/2019/09/17/机器学习的数学基础/index.html">
<meta property="og:site_name" content="SunFeng&#39;s Blog">
<meta property="og:description" content="机器学习的数学基础">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://sunfeng.online/2019/09/17/机器学习的数学基础/image1.PNG">
<meta property="og:updated_time" content="2019-09-19T11:06:58.585Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习的数学基础">
<meta name="twitter:description" content="机器学习的数学基础">
<meta name="twitter:image" content="http://sunfeng.online/2019/09/17/机器学习的数学基础/image1.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sunfeng.online/2019/09/17/机器学习的数学基础/">





  <title>机器学习的数学基础 | SunFeng's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SunFeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">学习，敲码，孤独终老！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>
            
            日程表
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sunfeng.online/2019/09/17/机器学习的数学基础/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SunFeng">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/sun.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SunFeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习的数学基础</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-17T21:34:53+08:00">
                2019-09-17
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学方法整理/" itemprop="url" rel="index">
                    <span itemprop="name">数学方法整理</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,531
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong><font size="4">机器学习的数学基础</font></strong></p>
<a id="more"></a>
<hr>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><h4 id="机器学习的特点"><a href="#机器学习的特点" class="headerlink" title="机器学习的特点"></a>机器学习的特点</h4><ul>
<li>以计算机为工具和平台</li>
<li>以数据为研究对象</li>
<li>以学习方法为中心</li>
</ul>
<h4 id="机器学习涉及的学科"><a href="#机器学习涉及的学科" class="headerlink" title="机器学习涉及的学科"></a>机器学习涉及的学科</h4><ul>
<li>机器学习是一门交叉学科</li>
<li>机器学习涉及的领域：<ul>
<li>概率论</li>
<li>线性代数</li>
<li>数值计算</li>
<li>信息论</li>
<li>最优化理论</li>
<li>计算机科学</li>
</ul>
</li>
</ul>
<hr>
<h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><h4 id="标量-scalar"><a href="#标量-scalar" class="headerlink" title="标量 (scalar)"></a>标量 (scalar)</h4><p>一个标量就是一个单独的数，一般用小写的变量名称表示。</p>
<hr>
<h4 id="向量-vector"><a href="#向量-vector" class="headerlink" title="向量 (vector)"></a>向量 (vector)</h4><p>一个向量就是一列数，这些数是有序排列的。通过次序中的索引，我们可以确定每个单独的数。常会赋予向量粗体的小写名称，当我们需要明确表示向量中的元素时，我们会将元素排列成一个方括号包围的纵柱：</p>
<script type="math/tex; mode=display">
\boldsymbol x = 
\begin{bmatrix}
x_1\\
x_2\\
\vdots \\
x_n
\end{bmatrix}</script><p>我们可以把向量看作空间中的点，每个元素是不同坐标轴上的坐标。</p>
<hr>
<h4 id="矩阵-matrix"><a href="#矩阵-matrix" class="headerlink" title="矩阵 (matrix)"></a>矩阵 (matrix)</h4><p>矩阵是二维数组，其中的每一个元素被两个索引而非一个所确定。我们通常赋予矩阵粗体的大写变量名称，比如 $\boldsymbol A$. 如果一个实数矩阵高度为 $m$, 宽度为 $n$, 那么我们说 $A\in R^{m \times n}$.</p>
<script type="math/tex; mode=display">
\boldsymbol A = 
\begin {bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
a_{31} & a_{32} & \cdots & a_{3n} \\
\vdots & \vdots & \cdots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn} 
\end{bmatrix}</script><p><strong>矩阵在机器学习中非常重要！</strong></p>
<p>实际上，如果我们现在有 $N$ 个用户的数据，每条数据含有 $M$ 个特征，那其实它对应的就是一个 $N \times M$ 的矩阵；在比如，一张图由 $16\times 16$ 个像素点组成，那么这就是一个 $16 \times 16$ 的矩阵了。</p>
<hr>
<h4 id="张量-tensor"><a href="#张量-tensor" class="headerlink" title="张量 (tensor)"></a>张量 (tensor)</h4><p><strong>张量本质上是一个数据容器</strong></p>
<p>几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将<strong>标量视为零阶张量，向量视为一阶张量，那么矩阵就是二阶张量。</strong></p>
<p>例如，可以将任意一张彩色图片表示成一个三阶张量，三个维度分别是图片的高度、宽度和色彩数据。将这张图片用张量表示出来，就是下方的这张表格：</p>
<p><img src="/2019/09/17/机器学习的数学基础/image1.PNG" alt="image1"></p>
<p>其中，表的横轴表示图片的宽度值，这里只截取0~319；表的纵轴表示图片的高度值，这里只截取0~4；表格中的每个方格代表一个像素点，比如第一行第一列的表格数据为[1.0,1.0,1.0]，代表的就是RGB三原色在图片的这个位置的取值情况 (即 R = 1.0, G = 1.0, B = 1.0)</p>
<p>当然，我们还可以将这一定义继续扩展，即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别为：图片在数据集中的编号、图片高度、宽度以及色彩数据。</p>
<font color="#0099ff">张量在深度学习中是一个很重要的概念，因为它是深度学习框架 TensorFlow 中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的</font>



<hr>
<h4 id="范数-norm"><a href="#范数-norm" class="headerlink" title="范数 (norm)"></a>范数 (norm)</h4><p>有时我们需要衡量一个向量的大小，在机器学习中，我们常用被称为范数的函数衡量向量大小，$L_p$范数如下：</p>
<script type="math/tex; mode=display">
\left\|x \right\|_p = \left(\sum_i \left|x_i \right|^p \right)^{\frac{1}{p}}</script><p>所以：</p>
<p>$L_1$ 范数 $\left|x \right|$: 为 $x$ 向量各个元素绝对值之和</p>
<p>$L_2$ 范数 $\left|x \right|_2$: 为 $x$ 向量各个元素平方和的开方</p>
<p><strong>说明：</strong></p>
<p>在机器学习中，$L_1$ 范数和 $L_2$ 范数很常见，主要用在损失函数中起到一个限制模型复杂度的作用，至于为什么要限制模型复杂度，这里又涉及到机器学习中常见的过拟合问题。</p>
<hr>
<h4 id="特征分解-eigendecomposition"><a href="#特征分解-eigendecomposition" class="headerlink" title="特征分解 (eigendecomposition)"></a>特征分解 (eigendecomposition)</h4><p>许多数学对象可以通过将它们分解成多个组成部分，特征分解是使用最广的矩阵分解之一，即将矩阵分解成一组<strong>特征向量</strong>和<strong>特征值</strong>。</p>
<p><strong><font color="#0099ff">方阵 A 的特征向量是指与 A 相乘后相当于对该向量进行缩放的非零向量 v:</font></strong></p>
<script type="math/tex; mode=display">
\boldsymbol A \boldsymbol v = \lambda \boldsymbol v</script><p>标量 $\lambda$ 被称为这个特征向量 $\boldsymbol v $ 对应的特征值</p>
<p>假设矩阵 $\boldsymbol A$ 有 $n$ 个线性无关的特征向量 $\{\boldsymbol v^{(1)},\boldsymbol v^{(2)},…,\boldsymbol v^{(n)} \}$, 对应着特征值 $\{\lambda_{1}, \lambda_{2},…,\lambda_{n} \}$. 我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：$\boldsymbol V = \left[\boldsymbol v^{(1)},\boldsymbol v^{(2)},…,\boldsymbol v^{(n)}  \right]$.  类似地，我们也可以将特征值连接成一个向量 $\boldsymbol \lambda = [\lambda_{1}, \lambda_{2},…,\lambda_{n}]^T$. 因此 $\boldsymbol A$ 的特征分解可记作：</p>
<script type="math/tex; mode=display">
\boldsymbol A = \boldsymbol V diag(\boldsymbol \lambda)\boldsymbol V^{-1}</script><p>其中，$diag(\boldsymbol \lambda)$ 表示向量 $\boldsymbol \lambda$ 在 $n\times n$ 方阵的对角线上。</p>
<hr>
<h4 id="奇异值分解-Singular-Value-Decomposition-SVD"><a href="#奇异值分解-Singular-Value-Decomposition-SVD" class="headerlink" title="奇异值分解 (Singular Value Decomposition, SVD)"></a>奇异值分解 (Singular Value Decomposition, SVD)</h4><p>矩阵的特征分解是由前提条件的，那就是只有对角化的矩阵才可以进行特征分解。但实际中很多矩阵往往不满足这一条件，甚至很多矩阵都不是方阵。</p>
<p>因此，可将矩阵的特征分解进行推广，得到一种叫作<strong>矩阵奇异值分解</strong>的方法。</p>
<p>其具体做法是将一个普通矩阵分解为奇异向量和奇异值，比如将矩阵 $\boldsymbol A$ 分解成三个矩阵的乘积：</p>
<script type="math/tex; mode=display">
\boldsymbol A = \boldsymbol U \boldsymbol D \boldsymbol V^T</script><p>假设 <strong>$\boldsymbol A$ 是一个 $m \times n $ 矩阵</strong>，那么 <strong>$\boldsymbol U$ 是一个 $m \times m$ 矩阵，$\boldsymbol D$ 是一个 $m \times n$ 矩阵，$\boldsymbol V$ 是一个 $n \times n$ 矩阵</strong> </p>
<p>这些矩阵每一个都拥有特殊的结构，其中 $\boldsymbol U$ 和 $\boldsymbol V $ 都是正交矩阵，$\boldsymbol D$ 是对角矩阵。</p>
<p>对角矩阵 $\boldsymbol D$ 对角线上的元素被称为矩阵 $\boldsymbol A$ 的<strong>奇异值</strong></p>
<p>正交矩阵 $\boldsymbol U$ 的列向量被称为<strong>左奇异向量</strong></p>
<p>正交矩阵 $\boldsymbol V$ 的列向量被称为<strong>右奇异向量</strong></p>
<p>SVD最有用的一个性质可能是拓展矩阵求逆到非方矩阵上。另外，SVD可用于推荐系统中。</p>
<hr>
<h4 id="几种常用的距离"><a href="#几种常用的距离" class="headerlink" title="几种常用的距离"></a>几种常用的距离</h4><p>在机器学习中，我们的运算一般都是基于向量的，一条用户具有100个特征，那么他对应的就是一个100维的向量，通过计算两个用户对应向量之间的距离值大小，有时候能反映出这两个用户的相似程度。</p>
<p>设有两个 $n$ 维向量 $\boldsymbol A =\left[x_{11},x_{12},…,x_{1n} \right]$ 和 $\boldsymbol B =\left[x_{21},x_{22},…,x_{2n} \right]$, 则一些常用的距离公式定义如下：</p>
<h5 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h5><p>曼哈顿距离也称为城市街区距离，数学定义如下：</p>
<script type="math/tex; mode=display">
d_{12} = \sum_{k=1}^{n}\left|x_{1k}-x_{2k} \right|</script><p>曼哈顿距离的Python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">dist = sum(abs(vector1 - vector2))</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h5><p>欧式距离是比较常用的距离，数学定义如下：</p>
<script type="math/tex; mode=display">
d_{12} = \sqrt{\sum_{k=1}^{n}(x_{1k}-x_{2k})^2}</script><p>欧式距离的Python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">dist = sqrt((vector1-vector2)*(vector1-vector2).T)</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h5><p>从严格意义上讲，闵可夫斯基距离不是一种距离，而是一组距离的定义：</p>
<script type="math/tex; mode=display">
d_{12} = \sqrt[p]{\sum_{k=1}^{n}(x_{1k}-x_{2k})^p }</script><p>当 $p = 1$ 时，就是曼哈顿距离</p>
<p>当 $p = 2$ 时，就是欧式距离</p>
<hr>
<h5 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h5><p>切比雪夫距离就是 $L_{\infty}$, 即无穷范数，数学表达式如下：</p>
<script type="math/tex; mode=display">
d_{12} = max(\left|x_{1k}-x_{2k} \right|)</script><p>切比雪夫距离的 Python 实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span>*</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">dist = sqrt(abs(vector1-vector2).max)</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="夹角余弦"><a href="#夹角余弦" class="headerlink" title="夹角余弦"></a>夹角余弦</h5><p>夹角余弦的取值范围为 [-1,1], 可以用来衡量两个向量方向的差异；夹角余弦越大，表示两个向量的夹角越小；当两个向量的方向重合时，夹角余弦取最大值1；当两个向量的方向完全相反时，夹角余弦取最小值-1.</p>
<p>机器学习中用这一概念来衡量样本向量之间的差异，用其数学表达式如下：</p>
<script type="math/tex; mode=display">
\cos\theta = \frac{\boldsymbol A \boldsymbol B}{|\boldsymbol A| |\boldsymbol B|} = \frac{\sum_{k=1}^{n}x_{1k}x_{2k}}{\sqrt{\sum_{k=1}^{n}x_{1k}^2}\sqrt{\sum_{k=1}^{n}x_{2k}^2}}</script><p>夹角余弦的 Python 实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">vector1 = mat([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">vector2 = mat([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">dist = dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h5><p>汉明距离定义的是两个字符串中不相同位数的数目。</p>
<p>例如：字符串 <code>&#39;1111&#39;</code>  与 <code>&#39;1001&#39;</code> 之间的汉明距离为2.</p>
<p>信息编码中一般应使得编码间的汉明距离尽可能的小。</p>
<p>汉明距离的 Python 实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">matV = mat([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>][<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">smstr = nonzero(matV[<span class="number">0</span>]-matV[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="杰卡德相似系数"><a href="#杰卡德相似系数" class="headerlink" title="杰卡德相似系数"></a>杰卡德相似系数</h5><p>两个集合 $A$ 和 $B$ 的交集元素在 $A$ 和 $B$ 的并集中所占的比例称为两个集合的杰卡德相似系数，用符号 $J(A,B)$ 表示，表达式为：</p>
<script type="math/tex; mode=display">
J(A,B) = \frac{\left|A\cap B\right|}{\left|A\cup B\right|}</script><p>杰卡德相似系数是衡量两个集合相似度的一种指标，一般可以将其用在衡量样本的相似度上</p>
<hr>
<h5 id="杰卡德距离"><a href="#杰卡德距离" class="headerlink" title="杰卡德距离"></a>杰卡德距离</h5><p>与杰卡德相似系数相反的概念是杰卡德距离，其定义式为：</p>
<script type="math/tex; mode=display">
J_e = 1-J(A,B) = \frac{\left|A\cup B\right| - \left|A\cap B\right|}{\left|A\cup B\right|}</script><p>杰卡德距离的 Python 实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> scipy.spatial.distance <span class="keyword">as</span> dist</span><br><span class="line">matv = mat([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>][<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">d = dist.pdist(matV,<span class="string">'jaccard'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="概率"><a href="#概率" class="headerlink" title="概率"></a>概率</h3><h4 id="为什么使用概率？"><a href="#为什么使用概率？" class="headerlink" title="为什么使用概率？"></a>为什么使用概率？</h4><h4 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h4><h4 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h4><h4 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h4><h4 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h4><h4 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h4><h4 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h4><h4 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h4><h4 id="常见的函数分布"><a href="#常见的函数分布" class="headerlink" title="常见的函数分布"></a>常见的函数分布</h4><h5 id="0-1分布"><a href="#0-1分布" class="headerlink" title="0-1分布"></a>0-1分布</h5><h5 id="几何分布"><a href="#几何分布" class="headerlink" title="几何分布"></a>几何分布</h5><h5 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h5><h5 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h5><h5 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h5><h5 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h5><h4 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h4><h4 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h4><h3 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h3><h4 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h4><h4 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h4><h4 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h4><h4 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h4><h4 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h4><h4 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h4><hr>
<h3 id="数值计算"><a href="#数值计算" class="headerlink" title="数值计算"></a>数值计算</h3><h4 id="上溢和下溢"><a href="#上溢和下溢" class="headerlink" title="上溢和下溢"></a>上溢和下溢</h4><h4 id="计算复杂性和-NP-问题"><a href="#计算复杂性和-NP-问题" class="headerlink" title="计算复杂性和 NP 问题"></a>计算复杂性和 NP 问题</h4><h5 id="算法复杂性"><a href="#算法复杂性" class="headerlink" title="算法复杂性"></a>算法复杂性</h5><h5 id="确定性和非确定性"><a href="#确定性和非确定性" class="headerlink" title="确定性和非确定性"></a>确定性和非确定性</h5><h5 id="NP问题"><a href="#NP问题" class="headerlink" title="NP问题"></a>NP问题</h5><h4 id="数值计算-1"><a href="#数值计算-1" class="headerlink" title="数值计算"></a>数值计算</h4><hr>
<h3 id="最优化"><a href="#最优化" class="headerlink" title="最优化"></a>最优化</h3><h4 id="最优化理论"><a href="#最优化理论" class="headerlink" title="最优化理论"></a>最优化理论</h4><h4 id="最优化问题和数学描述"><a href="#最优化问题和数学描述" class="headerlink" title="最优化问题和数学描述"></a>最优化问题和数学描述</h4><h4 id="凸集和凸集分离定理"><a href="#凸集和凸集分离定理" class="headerlink" title="凸集和凸集分离定理"></a>凸集和凸集分离定理</h4><h5 id="凸集"><a href="#凸集" class="headerlink" title="凸集"></a>凸集</h5><h5 id="超平面和空间"><a href="#超平面和空间" class="headerlink" title="超平面和空间"></a>超平面和空间</h5><h5 id="凸集分离定理"><a href="#凸集分离定理" class="headerlink" title="凸集分离定理"></a>凸集分离定理</h5><h5 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h5><h4 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h4><h5 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h5><h5 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h5><h4 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h4><h4 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h4><h5 id="牛顿法介绍"><a href="#牛顿法介绍" class="headerlink" title="牛顿法介绍"></a>牛顿法介绍</h5><h5 id="牛顿法推导"><a href="#牛顿法推导" class="headerlink" title="牛顿法推导"></a>牛顿法推导</h5><h5 id="牛顿法过程"><a href="#牛顿法过程" class="headerlink" title="牛顿法过程"></a>牛顿法过程</h5><h4 id="阻尼牛顿法"><a href="#阻尼牛顿法" class="headerlink" title="阻尼牛顿法"></a>阻尼牛顿法</h4><h5 id="引入-1"><a href="#引入-1" class="headerlink" title="引入"></a>引入</h5><h5 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h5><h4 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h4><h5 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h5><h5 id="拟牛顿法推导"><a href="#拟牛顿法推导" class="headerlink" title="拟牛顿法推导"></a>拟牛顿法推导</h5><hr>

      
    </div>
    
    
    

    <div>
      
      <div>
    
    <div style="text-align:center;color:#ccc;font-size:14px;">
        -------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------
    </div>
    
</div>
      
    </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/15/吴恩达《改善神经网络》课程笔记（1）-- 深度学习的实践层面/" rel="next" title="吴恩达《改善神经网络》课程笔记（1）-- 深度学习的实践层面">
                <i class="fa fa-chevron-left"></i> 吴恩达《改善神经网络》课程笔记（1）-- 深度学习的实践层面
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/20/论文常见单词积累 (一)/" rel="prev" title="论文常见单词积累 (一)">
                论文常见单词积累 (一) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/sun.jpg" alt="SunFeng">
            
              <p class="site-author-name" itemprop="name">SunFeng</p>
              <p class="site-description motion-element" itemprop="description">南京航空航天大学 | 计算机科学与技术学院 | 物联网工程专业</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/sunfeng2016" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:SunFeng@nuaa.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#机器学习的特点"><span class="nav-number">1.1.</span> <span class="nav-text">机器学习的特点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#机器学习涉及的学科"><span class="nav-number">1.2.</span> <span class="nav-text">机器学习涉及的学科</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性代数"><span class="nav-number">2.</span> <span class="nav-text">线性代数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#标量-scalar"><span class="nav-number">2.1.</span> <span class="nav-text">标量 (scalar)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#向量-vector"><span class="nav-number">2.2.</span> <span class="nav-text">向量 (vector)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#矩阵-matrix"><span class="nav-number">2.3.</span> <span class="nav-text">矩阵 (matrix)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#张量-tensor"><span class="nav-number">2.4.</span> <span class="nav-text">张量 (tensor)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#范数-norm"><span class="nav-number">2.5.</span> <span class="nav-text">范数 (norm)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特征分解-eigendecomposition"><span class="nav-number">2.6.</span> <span class="nav-text">特征分解 (eigendecomposition)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#奇异值分解-Singular-Value-Decomposition-SVD"><span class="nav-number">2.7.</span> <span class="nav-text">奇异值分解 (Singular Value Decomposition, SVD)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#几种常用的距离"><span class="nav-number">2.8.</span> <span class="nav-text">几种常用的距离</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#曼哈顿距离"><span class="nav-number">2.8.1.</span> <span class="nav-text">曼哈顿距离</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#欧式距离"><span class="nav-number">2.8.2.</span> <span class="nav-text">欧式距离</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#闵可夫斯基距离"><span class="nav-number">2.8.3.</span> <span class="nav-text">闵可夫斯基距离</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#切比雪夫距离"><span class="nav-number">2.8.4.</span> <span class="nav-text">切比雪夫距离</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#夹角余弦"><span class="nav-number">2.8.5.</span> <span class="nav-text">夹角余弦</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#汉明距离"><span class="nav-number">2.8.6.</span> <span class="nav-text">汉明距离</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#杰卡德相似系数"><span class="nav-number">2.8.7.</span> <span class="nav-text">杰卡德相似系数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#杰卡德距离"><span class="nav-number">2.8.8.</span> <span class="nav-text">杰卡德距离</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#概率"><span class="nav-number">3.</span> <span class="nav-text">概率</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么使用概率？"><span class="nav-number">3.1.</span> <span class="nav-text">为什么使用概率？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#随机变量"><span class="nav-number">3.2.</span> <span class="nav-text">随机变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#概率分布"><span class="nav-number">3.3.</span> <span class="nav-text">概率分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#条件概率"><span class="nav-number">3.4.</span> <span class="nav-text">条件概率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#贝叶斯公式"><span class="nav-number">3.5.</span> <span class="nav-text">贝叶斯公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#期望"><span class="nav-number">3.6.</span> <span class="nav-text">期望</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#方差"><span class="nav-number">3.7.</span> <span class="nav-text">方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#协方差"><span class="nav-number">3.8.</span> <span class="nav-text">协方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#常见的函数分布"><span class="nav-number">3.9.</span> <span class="nav-text">常见的函数分布</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#0-1分布"><span class="nav-number">3.9.1.</span> <span class="nav-text">0-1分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#几何分布"><span class="nav-number">3.9.2.</span> <span class="nav-text">几何分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#二项分布"><span class="nav-number">3.9.3.</span> <span class="nav-text">二项分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#指数分布"><span class="nav-number">3.9.4.</span> <span class="nav-text">指数分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#高斯分布"><span class="nav-number">3.9.5.</span> <span class="nav-text">高斯分布</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#泊松分布"><span class="nav-number">3.9.6.</span> <span class="nav-text">泊松分布</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拉格朗日乘子法"><span class="nav-number">3.10.</span> <span class="nav-text">拉格朗日乘子法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大似然估计"><span class="nav-number">3.11.</span> <span class="nav-text">最大似然估计</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信息论"><span class="nav-number">4.</span> <span class="nav-text">信息论</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#熵"><span class="nav-number">4.1.</span> <span class="nav-text">熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#联合熵"><span class="nav-number">4.2.</span> <span class="nav-text">联合熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#条件熵"><span class="nav-number">4.3.</span> <span class="nav-text">条件熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#相对熵"><span class="nav-number">4.4.</span> <span class="nav-text">相对熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#互信息"><span class="nav-number">4.5.</span> <span class="nav-text">互信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大熵模型"><span class="nav-number">4.6.</span> <span class="nav-text">最大熵模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数值计算"><span class="nav-number">5.</span> <span class="nav-text">数值计算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#上溢和下溢"><span class="nav-number">5.1.</span> <span class="nav-text">上溢和下溢</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计算复杂性和-NP-问题"><span class="nav-number">5.2.</span> <span class="nav-text">计算复杂性和 NP 问题</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#算法复杂性"><span class="nav-number">5.2.1.</span> <span class="nav-text">算法复杂性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#确定性和非确定性"><span class="nav-number">5.2.2.</span> <span class="nav-text">确定性和非确定性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NP问题"><span class="nav-number">5.2.3.</span> <span class="nav-text">NP问题</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数值计算-1"><span class="nav-number">5.3.</span> <span class="nav-text">数值计算</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最优化"><span class="nav-number">6.</span> <span class="nav-text">最优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#最优化理论"><span class="nav-number">6.1.</span> <span class="nav-text">最优化理论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最优化问题和数学描述"><span class="nav-number">6.2.</span> <span class="nav-text">最优化问题和数学描述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#凸集和凸集分离定理"><span class="nav-number">6.3.</span> <span class="nav-text">凸集和凸集分离定理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#凸集"><span class="nav-number">6.3.1.</span> <span class="nav-text">凸集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#超平面和空间"><span class="nav-number">6.3.2.</span> <span class="nav-text">超平面和空间</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#凸集分离定理"><span class="nav-number">6.3.3.</span> <span class="nav-text">凸集分离定理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#凸函数"><span class="nav-number">6.3.4.</span> <span class="nav-text">凸函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#梯度下降算法"><span class="nav-number">6.4.</span> <span class="nav-text">梯度下降算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#引入"><span class="nav-number">6.4.1.</span> <span class="nav-text">引入</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#梯度下降法"><span class="nav-number">6.4.2.</span> <span class="nav-text">梯度下降法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#随机梯度下降法"><span class="nav-number">6.5.</span> <span class="nav-text">随机梯度下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#牛顿法"><span class="nav-number">6.6.</span> <span class="nav-text">牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#牛顿法介绍"><span class="nav-number">6.6.1.</span> <span class="nav-text">牛顿法介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#牛顿法推导"><span class="nav-number">6.6.2.</span> <span class="nav-text">牛顿法推导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#牛顿法过程"><span class="nav-number">6.6.3.</span> <span class="nav-text">牛顿法过程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#阻尼牛顿法"><span class="nav-number">6.7.</span> <span class="nav-text">阻尼牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#引入-1"><span class="nav-number">6.7.1.</span> <span class="nav-text">引入</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#算法过程"><span class="nav-number">6.7.2.</span> <span class="nav-text">算法过程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拟牛顿法"><span class="nav-number">6.8.</span> <span class="nav-text">拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#概述-1"><span class="nav-number">6.8.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#拟牛顿法推导"><span class="nav-number">6.8.2.</span> <span class="nav-text">拟牛顿法推导</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SunFeng</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">44.3k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共44.3k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
