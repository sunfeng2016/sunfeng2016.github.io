<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="machine learning,">





  <link rel="alternate" href="/atom.xml" title="SunFeng's Blog" type="application/atom+xml">






<meta name="description" content="《机器学习》西瓜书学习笔记（三）线性模型">
<meta name="keywords" content="machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="《机器学习》西瓜书学习笔记（三）-- 线性模型">
<meta property="og:url" content="http://sunfeng.online/2019/08/10/《机器学习》西瓜书学习笔记（二）-- 模型评估与选择/index.html">
<meta property="og:site_name" content="SunFeng&#39;s Blog">
<meta property="og:description" content="《机器学习》西瓜书学习笔记（三）线性模型">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://sunfeng.online/2019/08/10/《机器学习》西瓜书学习笔记（二）--%20模型评估与选择/Figure.PNG">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-433cdde5a09ff2450cb99383ad8211b8_hd.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-cdae5065290f57c9fc387b7d05b5b68a_hd.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-437db32129fdc1d411ac560bfa0f8842_hd.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-2c27bcec29d2a98b0a4725775cb8b2c4_hd.jpg">
<meta property="og:updated_time" content="2019-08-13T08:14:38.880Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《机器学习》西瓜书学习笔记（三）-- 线性模型">
<meta name="twitter:description" content="《机器学习》西瓜书学习笔记（三）线性模型">
<meta name="twitter:image" content="http://sunfeng.online/2019/08/10/《机器学习》西瓜书学习笔记（二）--%20模型评估与选择/Figure.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sunfeng.online/2019/08/10/《机器学习》西瓜书学习笔记（二）-- 模型评估与选择/">





  <title>《机器学习》西瓜书学习笔记（三）-- 线性模型 | SunFeng's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SunFeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">学习，敲码，孤独终老！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>
            
            日程表
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sunfeng.online/2019/08/10/《机器学习》西瓜书学习笔记（二）-- 模型评估与选择/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SunFeng">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/sun.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SunFeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">《机器学习》西瓜书学习笔记（三）-- 线性模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-10T14:54:48+08:00">
                2019-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/《机器学习》西瓜书学习笔记/" itemprop="url" rel="index">
                    <span itemprop="name">《机器学习》西瓜书学习笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4,037
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="《机器学习》西瓜书学习笔记（三）线性模型"><a href="#《机器学习》西瓜书学习笔记（三）线性模型" class="headerlink" title="《机器学习》西瓜书学习笔记（三）线性模型"></a>《机器学习》西瓜书学习笔记（三）线性模型</h2><a id="more"></a>
<h3 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h3><h4 id="1-回顾各符号对应的概念"><a href="#1-回顾各符号对应的概念" class="headerlink" title="1. 回顾各符号对应的概念"></a>1. 回顾各符号对应的概念</h4><p><strong>示例：</strong> $\boldsymbol x = (x_1; x_2; … ; x_d)$</p>
<p><strong>属性：</strong> $x_i$ </p>
<p><strong>属性个数(维度)：</strong> $d$ </p>
<p><strong>数据集：</strong> $D = \{\boldsymbol x_1, \boldsymbol x_2, …, \boldsymbol x_m\}$ </p>
<p><strong>带标记的数据集：</strong> $D = \{ (\boldsymbol x_1, y_1),  (\boldsymbol x_2, y_2), … , (\boldsymbol x_m, y_m)\}$ </p>
<p><strong>模型：</strong> $f$ </p>
<p><strong>模型在示例 $x$ 上的预测输出：</strong>  $f(\boldsymbol x)$</p>
<h4 id="2-线性模型-linear-model"><a href="#2-线性模型-linear-model" class="headerlink" title="2. 线性模型 (linear model)"></a>2. 线性模型 (linear model)</h4><p><strong>线性模型的目的：</strong> 试图学得一个【通过属性的线性组合来进行预测】的【函数】</p>
<p><strong>线性模型的本质：</strong> 学得一个线性函数</p>
<p><strong>线性模型的特征：</strong> 通过属性的线性组合来进行预测，即：</p>
<script type="math/tex; mode=display">
f(\boldsymbol x) = w_1x_1 + w_2x_2 + ... + w_dx_d + b</script><p>向量形式为:</p>
<script type="math/tex; mode=display">
f(x) = \boldsymbol w^T\boldsymbol x + b</script><p>其中 $\boldsymbol w = (w1;w2;…;wd)$ ，<font color="#0099ff">由于w直观的表达了各属性在预测中的重要性，因此线性模型具有很好的可解释性。</font></p>
<hr>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><h4 id="1-线性回归-linear-regression"><a href="#1-线性回归-linear-regression" class="headerlink" title="1. 线性回归 (linear regression)"></a>1. 线性回归 (linear regression)</h4><p>给定数据集 $D = {(\boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), … , (\boldsymbol x_m, y_m)}$ , 其中 $\boldsymbol x_i = (x_{i1}; x_{i2}; … x_{id}), y_i \in R$ .</p>
<p><strong>线性回归的目的：</strong> 试图学得一个【线性模型】以尽可能准确地【预测实值输出标记】</p>
<p><strong>线性回归的本质：</strong> 学得线性模型</p>
<p><strong>线性模型的作用：</strong> 预测实值输出标记</p>
<p><strong>线性模型的目的：</strong> 试图学得一个【通过属性的线性组合来进行预测】的【函数】</p>
<p><strong><font color="#0099ff">总的来讲，线性回归是一个函数，通过属性的线性组合来进行预测，尽可能准确地预测实值输出标记。</font></strong></p>
<p><strong>线性回归的分类：</strong></p>
<ul>
<li><font color="#0099ff">一元线性回归分析：</font>回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，则称为一元线性回归分析</li>
<li><font color="#0099ff">多元线性回归分析：</font>回归分析中，包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析</li>
</ul>
<h4 id="2-最小二乘法-least-square-method"><a href="#2-最小二乘法-least-square-method" class="headerlink" title="2. 最小二乘法 (least square method)"></a>2. 最小二乘法 (least square method)</h4><p><strong>最小二乘法：</strong> 基于均方误差最小化来进行模型求解的方法，均方误差对应了欧氏距离</p>
<ul>
<li>所谓“二乘”，就是用平方来度量观测点与估计点的远近</li>
<li>所谓“最小”，是指参数的估计值要保证各个观测点与估计点的距离平方和达到最小</li>
</ul>
<p><strong>最小二乘法的目的：</strong> 在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到这条直线上的欧式距离之和最小</p>
<p><strong>进一步解释：</strong> <font color="#0099ff">最小二乘法是一种数学优化技术，它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简单的求得未知数据，并使得这些求得的数据与实际数据之间误差的平方和最小。</font></p>
<p><strong>在线性回归中的误差平方和：</strong></p>
<ul>
<li>如果说误差就是预测点 $f(x_i)$ 到标记点 $y_i$ 的距离</li>
<li><p>那么均方误差 $E(f;D) = \frac{1}{m} \sum_{i = 1}^{m} {(f(x_i)-y_i)^2}$ 则可以体现误差的平方和</p>
<font color="#0099ff">这就意味着，线性回归需要最小化均方误差</font>



</li>
</ul>
<h4 id="3-属性数目为1的简单例子-一元线性回归"><a href="#3-属性数目为1的简单例子-一元线性回归" class="headerlink" title="3. (属性数目为1的简单例子)一元线性回归"></a>3. (属性数目为1的简单例子)一元线性回归</h4><p>我们先考虑一种最简单的情形：输入属性的数目只有一个</p>
<p>此时数据集为：$D = \{(x_1, y_1), (x_2, y_2), … , (x_m, y_m)\}$</p>
<p><strong>线性回归模型试图学得：</strong></p>
<script type="math/tex; mode=display">
f(xi) = wx_i + b, 使得f(xi) \approx y_i</script><p><strong>如何确定 $w$ 和 $b$：</strong> 最小二乘法，试图让均方误差最小化，即：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
(w^*, b^*) &= arg \ min \ E_{(w, b)}\\
&= arg \ min \ \sum_{i = 1}^{m}{(f(x_i) - y_i)^2}\\
&= arg \ min \ \sum_{i = 1}^{m}{(y_i - wx_i - b)^2}\\
\end{split}
\end{equation}</script><p><strong>参数估计：</strong> <font color="#0099ff">求解w和b使均方误差最小化的过程，称为线性回归模型的最小二乘“参数估计”（parameter estimation）</font></p>
<p>根据函数知识可知，一般 U形曲线的函数，如$f(x) = x^2$ ，通常都是凸函数，其最小值点一般在函数的极小值点处，也就是偏导数为0的点。</p>
<p>所以，我们可以将 $E(w,b)$ 分别对 $w$ 和 $b$ 求偏导，并令偏导等于0，即可得到 $w$ 和 $b$ 的最优解，具体过程如下：</p>
<ol>
<li><p>将 $E(w,b)$ 分别对 $w$ 和 $b$ 求偏导</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
\frac{\partial{E_{(w,b)}}}{\partial w} &= 2(w\sum_{i = 1}^{m}{x_i^2} - \sum_{i = 1}^{m}{(y_i - b)x_i}) \\
\frac{\partial{E_{(w,b)}}}{\partial b} &= (mb - \sum_{i = 1}^{m}{(y_i-wx_i)}) \\
\end{split}
\end{equation}</script></li>
<li><p>令偏导为零, 得到得到 $w$ 和 $b$ 的最优解</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
w &= \frac{\sum_{i=1}^{m}{y_i(x_i - \overline x)}}{\sum_{i = 1}^{m}{x_i^2}-\frac{1}{m}{(\sum_{i=1}^{m}{x_i})^2}} \\
b &= \frac{1}{m} \sum_{i=1}^{m}{(y_i - wx_i)^2} \\
\end{split}
\end{equation}</script><p>其中 $\overline x = \frac{1}{m} \sum_{i=1}^{m}x_i$ 为 $x$ 的均值。</p>
</li>
</ol>
<h4 id="4-属性数目为d的复杂例子-多元线性回归"><a href="#4-属性数目为d的复杂例子-多元线性回归" class="headerlink" title="4. (属性数目为d的复杂例子)多元线性回归"></a>4. (属性数目为d的复杂例子)多元线性回归</h4><p>现实中我们几乎碰不见属性值个数为1的例子，通常情况下，样本由d个属性描述。</p>
<p>此时，<strong>示例</strong>还是： $\boldsymbol x = (x_1; x_2; … ; x_d)$，<strong>数据集</strong>还是：$D = \{ (\boldsymbol x_1, y_1),  (\boldsymbol x_2, y_2), … , (\boldsymbol x_m, y_m)\}$ </p>
<p><strong>线性回归模型试图学得：</strong> </p>
<script type="math/tex; mode=display">
f(\boldsymbol xi) = w\boldsymbol x_i + b, 使得f(\boldsymbol xi) \approx y_i</script><p><strong>如何确定 w 和 b：</strong> 类似的，可以用最小二乘法来对 $w$ 和 $b$ 进行估计，具体过程如下：</p>
<ol>
<li><p>将$w$ 和 $b$ 吸入向量形式 $\hat w = (w; b)$ </p>
</li>
<li><p>把数据集 $D$ 表示成一个 $m \times (d + 1)$ 大小的矩阵 $\boldsymbol X$，其中每行对应一个示例，该行前个 $d$ 元素对应于示例的 $d$ 个属性值，最后一个元素恒置为1，即：</p>
<script type="math/tex; mode=display">
\boldsymbol X = 
\begin{pmatrix}
x_{11} & x_{12} & \ldots & x_{1d} & 1 \\
x_{21} & x_{22} & \ldots & x_{2d} & 1 \\
\vdots & \vdots & \ddots & \vdots & \vdots & \\
x_{m1} & x_{m2} & \ldots & x_{md} & 1 
\end{pmatrix} =
\begin{pmatrix}
\boldsymbol x_1^T & 1 \\
\boldsymbol x_2^T & 1 \\
\vdots & \vdots \\
\boldsymbol x_m^T & 1 
\end{pmatrix}</script></li>
<li><p>把标记写成向量形式：$y = (y_1; y_2; …;y_m)$ </p>
</li>
<li><p>求预测的误差平方和：$E_{\hat w} = (y - \boldsymbol X \hat w)^T(y - \boldsymbol X \hat w)$ </p>
</li>
<li><p>最小化均方误差：</p>
<script type="math/tex; mode=display">
\begin {equation}
\begin {split}
\hat w^* &= arg\ min \ E_{\hat w}\\
&= arg\ min \ (y - \boldsymbol X \hat w)^T(y - \boldsymbol X \hat w)
\end{split}
\end {equation}</script></li>
<li><p>将 $E_{\hat w}$ 对 $\hat w$ 求导得到:</p>
<script type="math/tex; mode=display">
\frac{\partial E_{\hat w}}{\partial {\hat w}} = 2 \boldsymbol X^T(\boldsymbol X \hat w - y)</script></li>
<li><p>然后分别考虑特殊情况和一般情况：</p>
<ul>
<li><p>特殊情况：$\boldsymbol X^T \boldsymbol X$ 为满秩矩阵或正定矩阵时，令偏导值为0，可得 $\boldsymbol {\hat w ^*} = (\boldsymbol X^T \boldsymbol X)^{-1}\boldsymbol X^T y$ , 令 $\boldsymbol {\hat x_i} = (\boldsymbol x_i; 1)$ ，则最终学得的多元线性回归模型为：</p>
<script type="math/tex; mode=display">
f(\hat x_i) = \hat x_i^T  (\boldsymbol X^T \boldsymbol X)^{-1}\boldsymbol X^T y.</script></li>
<li><p>一般情况：实际上，$\boldsymbol X^T \boldsymbol X$ 一般都不是满秩矩阵，此时可以解出来多个 $\boldsymbol {\hat w}$ , 它们都能使均方误差最小化，选择哪一个作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化项。</p>
</li>
</ul>
</li>
</ol>
<h4 id="5-线性模型的丰富变化"><a href="#5-线性模型的丰富变化" class="headerlink" title="5. 线性模型的丰富变化"></a>5. 线性模型的丰富变化</h4><ul>
<li><p><strong>线性回归模型：</strong> </p>
<p>将线性模型的预测值逼近真实标记 $y$, 即：$y = w^T \boldsymbol x + b$ </p>
</li>
<li><p><strong>对数线性回归：</strong> </p>
<p>将线性模型的预测值逼近真实标记 $y$ 的衍生物，如对数：$\ln(y) = w^T \boldsymbol x + b$ </p>
</li>
<li><p><strong>广义线性模型：</strong> </p>
<p>更一般地，考虑单调可微函数 $g(.)$, 可以得到更多的真实标记 $y$ 的衍生物，令 $g(y) = w^T \boldsymbol x + b$, 即 $y = g^{-1}{(w^T \boldsymbol x + b)}$, 这样得到的模型称为广义线性模型，其中 $g(.)$ 称为 “联系函数”。</p>
</li>
</ul>
<hr>
<h3 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h3><p><strong>预测：</strong> 依靠机器学习学得的模型，对新的示例进行结果判断</p>
<ul>
<li><strong>回归任务：</strong> 预测的是连续值</li>
<li><strong>分类任务：</strong> 预测的是离散值</li>
</ul>
<p>如果说说线性模型预测连续值，只需要让预测值逼近真实标记 $y$ 或其衍生物的话，当预测离散值的时候，如何让线性模型的预测值 (连续) 和真实标记值 $y$ (离散) 联系起来呢？</p>
<p>其实，离散状态的真实标记 $y$, 未尝不可以有一种连续的衍生物 $z$, 这样通过单调可微的联系函数 $g(.)$ , 就可以让连续的预测值联系离散的真实标记。</p>
<h4 id="1-单位阶跃函数-unit-step-function"><a href="#1-单位阶跃函数-unit-step-function" class="headerlink" title="1. 单位阶跃函数 (unit-step function)"></a>1. 单位阶跃函数 (unit-step function)</h4><p>在二分类任务当中，输出标记为 $y = \{0, 1\}$ , 而线性回归模型产生的预测值：$z = \boldsymbol w^T \boldsymbol x + b$   是实值。要将连续值 $z$ 转换为离散值 0/1，最理想的是 “单位阶跃函数” </p>
<script type="math/tex; mode=display">
\begin {equation}
y = 
\begin {cases}
0, & z < 0;\\
0.5 & z = 0; \\
1 & z > 0;
\end {cases}
\end {equation}</script><p><img src="/2019/08/10/《机器学习》西瓜书学习笔记（二）-- 模型评估与选择/Figure.PNG" alt="Figure1"></p>
<h4 id="2-对数几率函数-logistic-function"><a href="#2-对数几率函数-logistic-function" class="headerlink" title="2. 对数几率函数 (logistic function)"></a>2. 对数几率函数 (logistic function)</h4><p>单位阶跃函数虽好，但是不可微，不是理想的联系函数 $g(.)$ , 我们希望找到一个在形态上趋近于单位阶跃函数的连续函数，并且是单调可微的。对数几率函数正是这样的一个函数：</p>
<script type="math/tex; mode=display">
y = \frac {1}{1 + e^{-z}}</script><p><img src="https://pic1.zhimg.com/80/v2-433cdde5a09ff2450cb99383ad8211b8_hd.jpg" alt="img"></p>
<p>将 $ z = \boldsymbol w^T \boldsymbol x + b$ 带入可得 $y = \frac {1}{1 + e^{-(  \boldsymbol w^T \boldsymbol x + b)}}$ , 亦即 $\ln \frac{y}{1-y} =   \boldsymbol w^T \boldsymbol x + b$. </p>
<p>如果说将 $y$ 看作样本 $x$ 作为正例的可能性，那么 $1-y$ 就是其成反例的可能性。</p>
<p><strong>几率：</strong> 两者的比值即为 “几率”，反映了样本作为正例的相对可能性</p>
<script type="math/tex; mode=display">
几率 = \frac {正例可能性}{反例可能性} = \frac{y}{1-y}</script><p><strong>对数几率：</strong> 对几率取对数就可得到 “对数几率”</p>
<script type="math/tex; mode=display">
对数几率 = \ln \frac{y}{1-y}</script><p><strong>对数几率回归：</strong> 用线性模型的预测结果去逼近真实标记的对数几率，其对应的模型叫做“对数几率回归”(logistic regression，亦称逻辑回归)</p>
<hr>
<h3 id="线性判别分析-LDA"><a href="#线性判别分析-LDA" class="headerlink" title="线性判别分析 (LDA)"></a>线性判别分析 (LDA)</h3><p><strong>线性判别分析 (Linear Discriminant Analysis, LDA)</strong> 是一种经典的用于解决二分类问题的线性学习方法。</p>
<h4 id="1-二分类任务中的LDA"><a href="#1-二分类任务中的LDA" class="headerlink" title="1. 二分类任务中的LDA"></a>1. 二分类任务中的LDA</h4><p><strong>LDA大概分为三个步骤：</strong></p>
<ul>
<li>给定样例</li>
<li>寻找一条满足 “同类近，异类远”的投影直线</li>
<li>新样本的分类依靠投影后点的位置来确定</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-cdae5065290f57c9fc387b7d05b5b68a_hd.jpg" alt="img"></p>
<p><strong>第一步：给定样例：</strong></p>
<p>给定数据集 $D = \{(\boldsymbol x_i, y_i)\}_{i = 1}^{m},  y_i \in \{0, 1\}$, 令 $\boldsymbol X_j$、$\boldsymbol \mu_j$、$\boldsymbol \sum_j$ 分别表示第 $j \in \{0, 1\}$ 类示例的集合、均值向量、协方差矩阵。将数据投影到直线 $\boldsymbol w$ 上，则两类样本的 <strong>样本中心</strong> 在直线上的投影分别为 $\boldsymbol w^T \boldsymbol \mu_0$ 和$\boldsymbol w^T \boldsymbol \mu_1$，两类样本的协方差矩阵分别为 $\boldsymbol w^T \boldsymbol \sum_0 \boldsymbol w$ 和 $\boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$，由于直线是一维空间，因此 $\boldsymbol w^T \boldsymbol \mu_0$ 、$\boldsymbol w^T \boldsymbol \mu_1$、 $\boldsymbol w^T \boldsymbol \sum_0 \boldsymbol w$ 和、$\boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$均为实数。</p>
<font color="#0099ff">顺便一提，如上图，横轴坐标分别为 x1 和 x2，代表样本的两个属性，此图代表属性个数为2时张成的二维空间。但当属性个数为n时，属性空间也为n维，只不过无法在图中体现了。 </font>

<p><strong>第二步：寻找投影直线：</strong></p>
<p><strong>两个原则：</strong> </p>
<ul>
<li><strong>同类近：</strong> 欲使得同类投影点尽可能近，可以让异类样例投影点的协方差尽可能小，即 $\boldsymbol w^T \boldsymbol \sum _0 \boldsymbol w + \boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$ 尽可能小</li>
<li><strong>异类远：</strong> 欲使得异类投影点尽可能远离，可以让类中心之间的距离尽可能大，即 $||\boldsymbol w^T \boldsymbol \mu_0 - \boldsymbol w^T \boldsymbol \mu_1||_2^2$ 尽可能大</li>
</ul>
<p><strong>广义瑞利商：</strong> 同时考虑二者，得到最大化目标，即：</p>
<script type="math/tex; mode=display">
\begin {equation}
\begin {split}
J &= \frac{||\boldsymbol w^T \boldsymbol \mu_0 - \boldsymbol w^T \boldsymbol \mu_1||_2^2}{\boldsymbol w^T \boldsymbol \sum _0 \boldsymbol w + \boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w}\\
&= \frac{\boldsymbol w^T(\boldsymbol \mu_0 - \boldsymbol \mu_1)(\boldsymbol \mu_0 - \boldsymbol \mu_1)^T\boldsymbol w}{\boldsymbol w^T (\boldsymbol \sum_0 + \boldsymbol \sum_1) \boldsymbol w}
\end {split}
\end {equation}</script><p><strong>类内散度矩阵：</strong> </p>
<script type="math/tex; mode=display">
\begin {equation}
\begin {split}
\boldsymbol S_w &= \boldsymbol \sum _0 + \boldsymbol \sum _1 \\
& = \boldsymbol \sum_{x \in X_0}(\boldsymbol x - \boldsymbol \mu_0)(\boldsymbol x - \boldsymbol \mu_0)^T + \boldsymbol \sum_{x \in X_1}(\boldsymbol x - \boldsymbol \mu_1)(\boldsymbol x - \boldsymbol \mu_1)^T
\end {split}
\end {equation}</script><p><strong>类间散度矩阵：</strong> </p>
<script type="math/tex; mode=display">
\boldsymbol S_b = (\boldsymbol \mu _0 - \boldsymbol \mu_1) (\boldsymbol \mu _0 - \boldsymbol \mu_1)^T</script><p><strong>重写得：</strong></p>
<script type="math/tex; mode=display">
J = \frac{\boldsymbol w^T \boldsymbol S_b \boldsymbol w}{\boldsymbol w^T \boldsymbol S_w \boldsymbol w}</script><p><strong>确定 $\boldsymbol  w$ :</strong></p>
<p>$\boldsymbol J$ 的分子分母都是关于 $\boldsymbol w$ 的二次项，因此  $\boldsymbol J$  的解与  $\boldsymbol w$  的长度无关，只与其方向有关。</p>
<p>故由拉格朗日乘子法，可列 $\boldsymbol S_b \boldsymbol w = \lambda \boldsymbol S_w \boldsymbol w $，又由于 $\boldsymbol S_b \boldsymbol w$ 方向恒为 $(\boldsymbol \mu _0 - \boldsymbol \mu_1) $，令 $\boldsymbol S_b \boldsymbol w=\lambda(\boldsymbol \mu _0 - \boldsymbol \mu_1) $，带入得 $\boldsymbol w = \boldsymbol S _w ^{-1}(\boldsymbol \mu _0 - \boldsymbol \mu_1) $</p>
<h4 id="2-多分类任务中的LDA"><a href="#2-多分类任务中的LDA" class="headerlink" title="2. 多分类任务中的LDA"></a>2. 多分类任务中的LDA</h4><hr>
<h3 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h3><p><strong>多分类学习的两个思路：</strong> </p>
<ul>
<li><strong>一是将二分类学习方法直接推广到多分类</strong>，如LDA</li>
<li><strong>二是基于某些策略，利用二分类学习器来解决多分类问题</strong></li>
</ul>
<h4 id="拆解法和拆分策略"><a href="#拆解法和拆分策略" class="headerlink" title="拆解法和拆分策略"></a>拆解法和拆分策略</h4><p><strong>拆解法：</strong> 将多分类任务拆解成为若干个二分类任务求解</p>
<p><strong>拆解步骤：</strong> </p>
<ul>
<li>通过拆分策略对问题进行<strong>【拆分】</strong></li>
<li>为拆分出的每个二分类任务<strong>【训练】</strong>一个分类器</li>
<li>对各个分类器的结果进行<strong>【集成】</strong>，以获得多分类结果</li>
</ul>
<p><strong>拆分策略：</strong></p>
<ul>
<li>“一对一 (OvO)”</li>
<li>“一对其余 (OvR)”</li>
<li>“多对多 (MvM)”</li>
</ul>
<p>假设多分类学习有 $\boldsymbol N$ 个类别 $\boldsymbol C_1, \boldsymbol C_2, … \boldsymbol C_N$, 给定数据集 $ D = \{(\boldsymbol x_1, y_1),(\boldsymbol x_2, y_2),…,(\boldsymbol x_m, y_m)\}$, $y_i \in \{C_1, C_2, … ,C_n\}$ </p>
<h5 id="OvO"><a href="#OvO" class="headerlink" title="OvO:"></a>OvO:</h5><ul>
<li>将 $N$ 个分类分别两两配对，从而 <strong>【拆分】</strong> 成 $N(N-1)/2$ 个二分类任务</li>
<li><strong>【训练】</strong> 时为了区分 $C_i$ 和 $C_j$ 这两个分类，这 $N(N-1)/2$ 个分类器的一个将 $C_i$ 作为正例，$C_j$ 作为反例</li>
<li>测试时将新样本同时提交给所有分类器，将得到 $N(N-1)/2$ 个分类结果，<strong>【集成】</strong> 的方法是通过投票在这些结果中选出最终结果</li>
</ul>
<h5 id="OvR"><a href="#OvR" class="headerlink" title="OvR:"></a>OvR:</h5><ul>
<li>将 $N$ 个分类中的1个分类拿出来作为一个分类器的正例，其余均设置为反例，从而<strong>【拆分】</strong>成 $N$ 个分类任务</li>
<li><strong>【训练】</strong> 得到 $N$ 个分类器</li>
<li><strong>【集成】</strong> 的方法是考虑各被判为正例的分类器的置信度，选择置信度大的类别标记作为分类的结果</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-437db32129fdc1d411ac560bfa0f8842_hd.jpg" alt="img"></p>
<h5 id="MvM"><a href="#MvM" class="headerlink" title="MvM:"></a>MvM:</h5><p>MvM是OvO和OvR的一般形式，反过来说，OvO和OvR是MvM的特例。</p>
<p>MvM每次将若干个类作为正类，若干个其他类作为反类。但其构造必须有特殊的设计，不能随意选取。常用的一种MvM技术是“纠错输出码”（ECOC）技术。</p>
<h4 id="“纠错输出码”-ECOC-技术"><a href="#“纠错输出码”-ECOC-技术" class="headerlink" title="“纠错输出码” (ECOC) 技术"></a>“纠错输出码” (ECOC) 技术</h4><p><strong>ECOC过程主要分为两步：</strong></p>
<ul>
<li><strong>编码：</strong>对 $N$ 个类进行 $M$ 次划分，产生 $M$ 个分类器</li>
<li><strong>解码：</strong>$M$ 个分类器对测试样本进行预测，得到 $M$ 个预测标记。将其组成编码；这个编码与 $N$ 个类别各自的编码进行比较，返回其中距离较小的类别作为最终预测的结果</li>
</ul>
<p><strong>编码形式：</strong></p>
<ul>
<li><strong>二元码：</strong> “正类”、“反类”</li>
<li><strong>三元码：</strong> “正类”、“反类”、“停用类”</li>
</ul>
<p>以二元 ECOC 码为例：如下图，首先，将 $N (N = 4)$ 个类提供设计构造成 $M (M = 5)$ 个分类器 $(f_1, f_2,f_3,f_4,f_5)$, 每个分类器为每个类分别配了一个标记结果 (-1或+1)，从而，每一个类 $C_i, i\in \{1, N\}$ 都获得了一个 $M$ 位的编码，这个编码就是 <strong>【各类所对应的编码】</strong></p>
<p>当有一个测试示例 $A$ 时，先将 $A$ 依照次序放入 $M$ 个分类器中，得到了 $M$ 个分类标记结果 $(-1,-1,+1,-1,+1);$ 再将这 $M$ 个标记结果编成一个纠错输出码 $(-1-1+1-1+1);$ 最后去和<strong>【各类所对应的编码】</strong>进行比较海明距离或欧式距离，距离最短的编码对应的分类就是结果。</p>
<p><img src="https://pic1.zhimg.com/80/v2-2c27bcec29d2a98b0a4725775cb8b2c4_hd.jpg" alt="img"></p>
<hr>
<h3 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h3><p><strong>类别不平衡(class-imbalance)</strong> 就是指分类任务中不同类别的训练样例数目差别很大的情况</p>
<p>以二分类问题为例，该问题一般指的是训练集中正负样本数比例相差过大（比如正例9998个，负例2个），其一般会造成以下的一些情况：</p>
<ul>
<li>类别少的误判惩罚过低，导致有所偏袒，当样本不确定时倾向于把样本分类为多数类。</li>
<li>样本数量分布很不平衡时，特征的分布同样会不平衡。</li>
<li>传统的评价指标变得不可靠，例如准确率。</li>
</ul>
<p>而在多分类问题中，尽管原始训练集中可能不同类别训练样本数目相当，通过OvR、MvM进行拆分时也有可能会造成上述情况，所以类别不平衡问题亟待解决。</p>
<p><strong>再缩放：</strong> 解决类别不平衡问题一个最基本思路是 “再缩放”，即当正反例数目不同时，令 $m^+$ 表示正例数目，$m^-$ 表示反例数目，则：</p>
<script type="math/tex; mode=display">
几率 = \frac{y\prime}{1-y\prime} = \frac{y}{1-y}\times\frac{m^-}{m^+}</script><font color="#0099ff">再缩放的思想虽然简单，但实际操作却不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往不成立，即我们未必能基于训练集的观察几率来推断真实几率</font>

<p><strong>现有技术大体上有三类做法：</strong></p>
<ul>
<li>第一类是对训练集里的反类样例进行<strong>欠采样</strong>，即去除一些反例使得正、反例数目接近</li>
<li>第二类是对训练集里的正类样例进行<strong>过采样</strong>，即增加一些正例使得正、反例数目接近</li>
<li>第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将上式嵌入到其决策过程中，称为<strong>阈值移动</strong></li>
</ul>
<hr>

      
    </div>
    
    
    

    <div>
      
      <div>
    
    <div style="text-align:center;color:#ccc;font-size:14px;">
        -------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------
    </div>
    
</div>
      
    </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/08/08/课程一(Neural Networks and Deep Learning), 第四周(Deep Neural Networks)——Programming Assignments 5、Deep Neural Network Application/" rel="next" title="课程一(Neural Networks and Deep Learning), 第四周(Deep Neural Networks)——Programming Assignments 5、Deep Neural Network Application">
                <i class="fa fa-chevron-left"></i> 课程一(Neural Networks and Deep Learning), 第四周(Deep Neural Networks)——Programming Assignments 5、Deep Neural Network Application
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/08/13/《机器学习》西瓜书学习笔记（四）-- 决策树/" rel="prev" title="《机器学习》西瓜书学习笔记（四）-- 决策树">
                《机器学习》西瓜书学习笔记（四）-- 决策树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/sun.jpg" alt="SunFeng">
            
              <p class="site-author-name" itemprop="name">SunFeng</p>
              <p class="site-description motion-element" itemprop="description">南京航空航天大学 | 计算机科学与技术学院 | 物联网工程专业</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/sunfeng2016" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:SunFeng@nuaa.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#《机器学习》西瓜书学习笔记（三）线性模型"><span class="nav-number">1.</span> <span class="nav-text">《机器学习》西瓜书学习笔记（三）线性模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本形式"><span class="nav-number">1.1.</span> <span class="nav-text">基本形式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-回顾各符号对应的概念"><span class="nav-number">1.1.1.</span> <span class="nav-text">1. 回顾各符号对应的概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-线性模型-linear-model"><span class="nav-number">1.1.2.</span> <span class="nav-text">2. 线性模型 (linear model)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性回归"><span class="nav-number">1.2.</span> <span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-线性回归-linear-regression"><span class="nav-number">1.2.1.</span> <span class="nav-text">1. 线性回归 (linear regression)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-最小二乘法-least-square-method"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. 最小二乘法 (least square method)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-属性数目为1的简单例子-一元线性回归"><span class="nav-number">1.2.3.</span> <span class="nav-text">3. (属性数目为1的简单例子)一元线性回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-属性数目为d的复杂例子-多元线性回归"><span class="nav-number">1.2.4.</span> <span class="nav-text">4. (属性数目为d的复杂例子)多元线性回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-线性模型的丰富变化"><span class="nav-number">1.2.5.</span> <span class="nav-text">5. 线性模型的丰富变化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对数几率回归"><span class="nav-number">1.3.</span> <span class="nav-text">对数几率回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-单位阶跃函数-unit-step-function"><span class="nav-number">1.3.1.</span> <span class="nav-text">1. 单位阶跃函数 (unit-step function)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-对数几率函数-logistic-function"><span class="nav-number">1.3.2.</span> <span class="nav-text">2. 对数几率函数 (logistic function)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性判别分析-LDA"><span class="nav-number">1.4.</span> <span class="nav-text">线性判别分析 (LDA)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-二分类任务中的LDA"><span class="nav-number">1.4.1.</span> <span class="nav-text">1. 二分类任务中的LDA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-多分类任务中的LDA"><span class="nav-number">1.4.2.</span> <span class="nav-text">2. 多分类任务中的LDA</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多分类学习"><span class="nav-number">1.5.</span> <span class="nav-text">多分类学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拆解法和拆分策略"><span class="nav-number">1.5.1.</span> <span class="nav-text">拆解法和拆分策略</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#OvO"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">OvO:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#OvR"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">OvR:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MvM"><span class="nav-number">1.5.1.3.</span> <span class="nav-text">MvM:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#“纠错输出码”-ECOC-技术"><span class="nav-number">1.5.2.</span> <span class="nav-text">“纠错输出码” (ECOC) 技术</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#类别不平衡问题"><span class="nav-number">1.6.</span> <span class="nav-text">类别不平衡问题</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SunFeng</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">27.9k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共27.9k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
