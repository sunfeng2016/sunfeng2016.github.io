<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[吴恩达《神经网络与深度学习》课程笔记（2）-- 神经网络基础]]></title>
    <url>%2F2019%2F09%2F05%2F%E5%90%B4%E6%81%A9%E8%BE%BE%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89--%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[吴恩达《神经网络与深度学习》课程笔记（2） 神经网络基础 二分类 (Binary Classification)神经网络的训练过程： 先有一个叫做前向暂停 (forward pause) 或前向传播 (forward propagation) 的步骤 接着有一个叫做反向暂停 (backward pause) 或反向传播 (backward propagation) 的步骤 一个二分类的例子： 输入： 一张图片 输出： 1 (识别这张图片含有猫)、0 (识别这张图片不含猫) 符号定义： $x$: 表示一个 $n_x$ 维数据，为输入数据，维度为 $(n_x,1)$ $y$: 表示输出结果，取值为 $(0,1)$ $(x^{(i)},y^{(i)})$: 表示第 $i$ 组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据 $X = [x^{(1)},x^{(2)},…,x^{(m)}]$: 表示所有训练数据集的输入值，放在一个 $n_x \times m$ 的矩阵中，$m$ 表示样本数目 $Y = [y^{(1)},y^{(2)},…,y^{(m)}]$: 对应所有训练数据集的输出值，维度为 $1\times m$ 逻辑回归 (Logistic Regression)Logistic 回归是一个用于二分类的算法 Logistic 回归中使用的参数如下： 输入的特征向量：$x \in R^{n_x}$, 其中 $n_x$ 是特征数量 用于训练的标签：$y \in \{0,1\}$ 权重：$w\in R^{n_x}$ 偏置：$b\in R$ 输出：$\hat y = \sigma(w^Tx+b)$ 激活函数：Sigmoid 函数 s = \sigma(w^Tx+b) = \sigma(z) = \frac{1}{1+e^{-z}}为将 $w^Tx+b$ 约束在 [0,1]间，引入 Sigmoid函数 Logistic 回归可以看作是一个非常小的神经网络，下图是一个典型的例子： 逻辑回归的代价函数 (Logistic Regression Cost Function)损失函数 (loss function) 用于衡量预测结果与真实值之间的误差 最简单的损失函数定义方式为平方差损失： L(\hat y,y) = \frac{1}{2}(\hat y-y)^2但 Logistic 回归中我们并不倾向于使用这样的损失函数，因为之后讨论优化问题会变成非凸的，最后会得到很多个局部最优解，梯度下降法找不到全局最优值 一般使用交叉熵损失: L(\hat y,y) = -y\log(\hat y)-(1-y)\log(1-\hat y) 损失函数是在单个训练样本中定义的，它衡量了算法在单个训练样本上的表现 代价函数 (Cost function) 代价函数用于衡量算法在全部样本上的表现 代价函数是对 $m$ 个样本的损失函数求和然后除以 $m$: J(w,b)=\frac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)},y^{(i)}) = \frac{1}{m}\left(-y^{(i)}\log(\hat y^{(i)})-(1-y^{(i)})\log(1-\hat y^{(i)})\right) 梯度下降 (Gradient Descent)梯度 (gradient) 梯度是一个向量，其方向是函数增长最快的方向，其大小表示函数的最大增长速度 按梯度的方向走，函数增长的最快 按梯度的负方向走，函数降低的最快 模型训练目标 模型的训练目标即是寻找合适的 $w$ 和 $b$ 以最小化代价函数值 简单起见，先假设 $w$ 与 $b$ 都是一维实数，那么可以得到函数 $J$ 关于 $w$ 和 $b$ 的图如下： 成本函数 J 是一个凸函数，与非凸函数的区别在于其不含有多个局部最低点，选择这样的代价函数就保证了无论怎样初始化模型参数值，都能寻找到合适的最优解 参数更新： 参数 $w$ 的更新公式： w := w-\alpha\frac{\partial J(w,b)}{\partial w} 参数 $b$ 的更新公式： b:=b-\alpha\frac{\partial J(w,b)}{\partial b}其中， $\alpha$ 为学习率，控制步长 逻辑回归中的梯度下降 (Logistic Regression Gradient Descent)问题假设： 假设样本只有两个特征 $x_1$ 和 $x_2$ 参数回顾： 权值：$w_1$ 和 $w_2$ 偏置：$b$ 线性回归输出：$z = w_1x_1+w_2x_2+b$ 逻辑回归输出：$\hat y = a = \sigma(z)$, 其中 $z = w_1x_1+w_2x_2+b$, $\sigma(z) = \frac{1}{1-e^{-z}}$ 损失函数：$L(\hat y^{(i)},y^{(i)}) = -y^{(i)}\log(\hat y^{(i)})-(1-y^{(i)})\log(1-\hat y^{(i)})$ 代价函数：$J(w,b) = \frac{1}{m}\sum_{i =1}^{m}L(\hat y^{(i)},y^{(i)})$ 单个样本的梯度下降： 根据上述假设，输入参数有5个：$x_1$, $x_2$, $w_1$, $w_2$ 和 $b$, 可以推导出如下的计算图： 其中 $L(a,y) = -y\log(a)-(1-y)\log(1-a)$ 首先反向求出 $L$ 对于 $a$ 的导数: da = \frac{d L}{d a} = -y/a+(1-y)/(1-a) 然后继续求出 $L$ 对于 $z$ 的导数： \begin{align} dz = \frac{d L}{d z}&= \frac{d L}{d a} \cdot\frac{d a}{d z}\\ &= \left( -y/a+(1-y)/(1-a) \right)\cdot\left(a(1-a) \right)\\ &= a- y \end {align} 最终求出 $L$ 对于参数 $w$ 和 $b$ 的导数： \begin {align} dw_1 = \frac{\partial L}{\partial w_1} &= \frac{dL}{dz}\cdot\frac{dz}{dw_1} \\ &= (a-y) \cdot x_1 \\ dw_2 = \frac{\partial L}{\partial w_2} &= \frac{dL}{dz}\cdot\frac{dz}{dw_2} \\ &= (a-y) \cdot x_2 \\ db = \frac{\partial L}{\partial w_1} &= \frac{dL}{dz}\cdot\frac{dz}{db} \\ &= (a-y) \end {align} 根据如下公式进行参数更新： \begin {align} w_1 &:= w_1-\alpha dw_1 \\ w_2 &:= w_2-\alpha dw_2 \\ b &:= b - \alpha db \end {align} $m$个样本的梯度下降： 接下来，我们需要将对于单个样本的损失函数扩展到整个训练集的代价函数： J(w,b) = \frac{1}{m}\sum_{i=1}^{m}L(a^{(i)},y^{(i)})\\ a^{(i)} = \hat y^{(i)} = \sigma(z^{(i)})= \sigma(w^Tx^{(i)}+b) 我们可以对于某个权重参数 $w_1$, 其导数计算为: \frac{\partial J(w,b)}{\partial w_1} = \frac{1}{m}\sum_{i=1}^{m}\frac{\partial L(a^{(i)},y^{(i)})}{\partial w_1} 完成的逻辑回归中某次训练流程如下，这里仅假设特征向量的维度为2： 然后，对 $w_1$, $w_2$ 和 $b$ 进行迭代 上述过程在计算时有一个缺点：需要编写两个 for 循环 第一个 for 循环用于遍历所有的样本 第二个 for 循环用于遍历所有的特征 向量化 (Vectorization) 在逻辑回归中，需要计算: z = w^Tx+b 如果是非向量化的循环方式，代码可能如下: 1234z = 0for i in range(n_x): z += w[i] * x[i]z += b 而如果是项量化的操作，代码则会简介很多，并带来近百倍性能的提升(并行指令): 1z = np.dot(w,x) + b 不用显示 for 循环，实现逻辑回归的梯度下降一次迭代 (对应之前蓝色代码的for循环部分，这里公式和 Numpy 的代码混杂，注意分辨)： \begin {align} Z &= w^TX+b=np.dot(w.T,x)+b\\ A &= \sigma(Z)\\ dZ &= A-Y\\ dw &= \frac{1}{m}XdZ^T\\ db &= \frac{1}{m}np.sum(dZ)\\ w &:= w-\sigma dw\\ b &:= b -\sigma db \end {align}]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
        <tag>神经网络与深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达《神经网络与深度学习》课程笔记（1）-- 深度学习概述]]></title>
    <url>%2F2019%2F08%2F30%2F%E5%90%B4%E6%81%A9%E8%BE%BE%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89--%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[吴恩达《神经网络与深度学习》课程笔记（1） 深度学习概述 什么是神经网络？(What is a Neural Network ?)深度学习： 指训练神经网络的过程 有时候特指训练大规模的神经网络 神经网络： 一个房价预测的例子 神经网络的监督学习 (Supervised Learning with Neural Network)常见神经网络的监督学习案例： 为什么深度学习会兴起？(Why the Deep Learning taking off ?) 数据 (Data) 计算能力 (Computation) 算法 (Algorithm)]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>神经网络与深度学习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[课程一(Neural Networks and Deep Learning)，第一周(Introduction to Deep Learning)--10个测试题]]></title>
    <url>%2F2019%2F08%2F26%2F%E8%AF%BE%E7%A8%8B%E4%B8%80(Neural%20Networks%20and%20Deep%20Learning)%EF%BC%8C%E7%AC%AC%E4%B8%80%E5%91%A8(Introduction%20to%20Deep%20Learning)--10%E4%B8%AA%E6%B5%8B%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[课程一(Neural Networks and Deep Learning)，第一周(Introduction to Deep Learning)—10个测试题 1、What does the analogy “AI is the new electricity” refer to? (B) A. Through the “smart grid”, AI is delivering a new wave of electricity. B. Similar to electricity starting about 100 years ago, AI is transforming multiple industries. C. AI is powering personal devices in our homes and offices, similar to electricity. D. AI runs on computers and is thus powered by electricity, but it is letting computers do things not possible before. 2、Which of these are reasons for Deep Learning recently taking off? (Check the three options that apply.) (A、B、D) A. We have access to a lot more data. B. We have access to a lot more computational power. C. Neural Networks are a brand new field. D. Deep learning has resulted in significant improvements in important applications such as online advertising, speech recognition, and image recognition. 3、Recall this diagram of iterating over different ML ideas. Which of the statements below are true? (Check all that apply.) (A、B、D) A. Being able to try out ideas quickly allows deep learning engineers to iterate more quickly. B. Faster computation can help speed up how long a team takes to iterate to a good idea. C. It is faster to train on a big dataset than a small dataset. D. Recent progress in deep learning algorithms has allowed us to train good models faster (even without changing the CPU/GPU hardware). 4、When an experienced deep learning engineer works on a new problem, they can usually use insight from previous problems to train a good model on the first try, without needing to iterate multiple times through different models. True/False? (B) A. True B. False 5、Which one of these plots represents a ReLU activation function? (C) A. Figure 1: B. Figure 2: C. Figure 3: D. Figure4 6、Images for cat recognition is an example of “structured” data, because it is represented as a structured array in a computer. True/False? (B) A. True B. False 7、A demographic dataset with statistics on different cities’ population, GDP per capita, economic growth is an example of “unstructured” data because it contains data coming from different sources. True/False?(B) A. True B. False 8、Why is an RNN (Recurrent Neural Network) used for machine translation, say translating English to French? (Check all that apply.) (A、C) A. It can be trained as a supervised learning problem. B. It is strictly more powerful than a Convolutional Neural Network (CNN). C. It is applicable when the input/output is a sequence (e.g., a sequence of words). D. RNNs represent the recurrent process of Idea-&gt;Code-&gt;Experiment-&gt;Idea-&gt;…. 9、In this diagram which we hand-drew in lecture, what do the horizontal axis (x-axis) and vertical axis (y-axis) represent? (A) A. x-axis is the amount of datay-axis (vertical axis) is the performance of the algorithm. B. x-axis is the performance of the algorithmy-axis (vertical axis) is the amount of data. C. x-axis is the amount of datay-axis is the size of the model you train. D. x-axis is the input to the algorithmy-axis is outputs. 10、Assuming the trends described in the previous question’s figure are accurate (and hoping you got the axis labels right), which of the following are true? (Check all that apply.) (A、C) A. Increasing the size of a neural network generally does not hurt an algorithm’s performance, and it may help significantly. B. Decreasing the size of a neural network generally does not hurt an algorithm’s performance, and it may help significantly. C. Increasing the training set size generally does not hurt an algorithm’s performance, and it may help significantly. D. Decreasing the training set size generally does not hurt an algorithm’s performance, and it may help significantly.]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>课后习题及编程练习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拉格朗日乘子法(Lagrange Multiplier)和KKT条件]]></title>
    <url>%2F2019%2F08%2F26%2F%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95(Lagrange%20Multiplier)%E5%92%8CKKT%E6%9D%A1%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[深入理解拉格朗日乘子法和KKT条件 简介 在求解最优化问题中，拉格朗日乘子法 (Lagrange Multiplier) 和 KKT (Karush Kuhn Tucker) 条件 是两种常用的方法。 在有等式约束时使用拉格朗日乘子法 在有不等式约束时使用KKT条件 优化问题&ensp;&ensp; 我们这里提到的 最优化问题是指对于给定的某一函数，求其在指定作用域上的全局最小值 (因为最小值与最大值可以很容易转化，即最大值问题可以转化为最小值问题)。 &ensp;&ensp; 一般情况下，最优化问题可分为以下三种情况： 无约束条件 这是最简单的情况，解决方法通常是函数对变量求导，令求导函数等于0的点可能是极值点。将极值点带回原函数进行验证即可 等式约束条件问题描述 设目标函数为 $f(x)$ 约束条件为 $h_k(x)$ 求： \begin {align} &\mathop{\min}_{x}f(x)\\ &s.t\ \ h_k(x) = 0\ \ k=1,2,...,l \end {align} \tag{1}此问题的解决方法是 消元法或拉格朗日法 拉格朗日乘子法 &ensp;&ensp;拉格朗日乘子法是一种寻找多元函数在其变量受到一个或多个条件的约束时的极值的方法。 &ensp;&ensp;这种方法可以将一个拥有 n 个变量与 k 个约束条件的最优化问题转换为一个求解有 n+k 个变量的方程组的解的问题。 首先定义拉格朗日函数： F(x,\lambda) = f(x)+\sum_{k=1}^l\lambda_kh_k(x)\tag{2}其中，$\lambda_k$ 是各个约束条件的待定系数, 称作 拉格朗日乘数 然后解变量的偏导数方程： \begin {align} \frac{\partial F}{\partial x} &= 0 \\ \frac{\partial F}{\partial \lambda_1} &= 0\\ &\vdots\\ \frac{\partial F}{\partial \lambda_l} &= 0 \end {align} \tag{3}如果有 $l$ 个约束条件，则有 $l+1$ 个方程。求出方程的解就可能是最优化解。 一个例子 给定一个椭球： \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1\tag{4} 求这个椭球的内接长方体的最大体积 此问题实际上就是条件极值问题，即在条件 $\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1$ 求 $f(x,y,z) = 8xyz$ 的最大值 用拉格朗日法求解该问题： \begin {align} F(x,y,z,\lambda) &= f(x,y,z)+\lambda\varphi(x,y,z)\\ &= 8xyz+\lambda\left(\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} - 1 \right) \end {align} \tag{5} 对 $F(x,y,z,\lambda)$ 求偏导得到： \begin {align} \frac{\partial F(x,y,z,\lambda)}{\partial x} &= 8yz+\frac{2\lambda x}{a^2} =0\\ \frac{\partial F(x,y,z,\lambda)}{\partial y} &= 8xz+\frac{2\lambda y}{b^2} =0\\ \frac{\partial F(x,y,z,\lambda)}{\partial z} &= 8xy+\frac{2\lambda z}{a^2} =0\\ \frac{\partial F(x,y,z,\lambda)}{\partial \lambda} &= \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} - 1 = 0 \end {align} \tag{6} 求解方程 (6) 可得： \begin {equation} \begin {cases} x = \frac{\sqrt 3}{3}a\\ y = \frac{\sqrt 3}{3}b\\ z = \frac{\sqrt 3}{3}c \end {cases} \end {equation} \tag{7} 带入解得最大体积为： V_{max} = f\left(\frac{\sqrt 3}{3}a, \frac{\sqrt 3}{3}b, \frac{\sqrt 3}{3}c\right)= \frac{8\sqrt 3}{9}abc\tag{8} 直观解释 &ensp;&ensp;举个二维最优化的例子： \begin {align} &\mathop{\min}_{x,y}f(x,y)\\ &s.t\ \ g(x,y) = c \end {align} \tag{9}下图是 $z = f(x,y)$ 的等高线：&ensp;下图是 $z = f(x,y)$ 的等高线： &ensp;&ensp;绿线是约束条件 $g(x,y) = c$ 的轨迹；蓝线是 $f(x,y)$ 的等高线；箭头表示斜率，和等高线的发现平行。从梯度方向上来看，显然 $d_1 &gt; d_2$ &ensp;&ensp;绿色的线表示约束，也就是说，只要正好落在这条绿线上的点才可能是满足要求的点。如果没有这条约束，f(x,y)的最小值应该会是会落在最小那圈等高线内部的某一点上。 &ensp;&ensp;而现在加上了约束条件，最小值点应该是 f(x,y)等高线和约束条件相切的位置，因为如果只是相交意味着肯定还存在其他等高线在该条等高线的内部或者外部，使得新的等高线与目标函数的交点的值更大或者更小 &ensp;&ensp;只有到等高线与约束条件的函数曲线相切的时候，才可能取到最优值 &ensp;&ensp;如果我们对约束也求梯度 $\nabla g(x,y)$, 则其梯度如图中绿色箭头所示；显然，当目标函数 $f(x,y)$ 的等高线和约束相切，则它们切点的梯度一定在一条直线上($f$ 和 $g$ 的斜率平行) &ensp;&ensp;即在最优解的时候: $\nabla f(x,y) = \lambda(\nabla g(x,y) - c)$, 即 $\nabla[f(x,y) + \lambda(g(x,y)-c) ] = 0$ &ensp;&ensp;那么拉格朗日函数： $F(x,y) = f(x,y)+\lambda(g(x,y)-c)$ 在达到极值时与 $f(x,y)$ 相等，因为 $g(x,y)-c$ 总为0 不等式约束条件]]></content>
      <categories>
        <category>数学方法整理</category>
      </categories>
      <tags>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（十）-- 降维与度量学习]]></title>
    <url>%2F2019%2F08%2F22%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89--%20%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（十）降维与度量学习 k 近邻学习k 近邻简介： k 近邻 (k-Nearest Neighbor, 简称KNN) 一种常用的监督学习方法 k 近邻思想： 给定测试样本，基于某种距离度量找出训练集中与其最靠近的 $k$ 个训练样本 然后基于这 $k$ 个邻居的信息来进行预测 在分类任务中，可采用 “投票法” 即选择 $k$ 个样本中出现最多的类别标记作为预测结果 在回归任务中，可采用 “平均法” 即将这 $k$ 个样本的实值输出标记的平均值作为预测结果 k 近邻特点： 没有显式的训练过程 低维嵌入维数灾难 (curse of dimensionality) 在高维情形下出现的数据样本稀疏、距离计算困难等问题 降维 (dimension reduction) 缓解维数灾难的一个重要途径 通过某种数学变换将原始高维属性空间转变为一个低维 “子空间” 在子空间中样本密度大幅提高，距离计算也变得更为容易 多维缩放 (Multiple Dimensional Scaling，简称 MDS) 设 $m$ 个样本在原始空间的距离矩阵为 $\boldsymbol D\in {\Bbb R}^{m\times m}$ 其第 $i$ 行 $j$ 列元素 $dist_{ij}$ 为样本 $\boldsymbol x_i$ 到 $\boldsymbol x_j$ 的距离 目标是获得样本在 $d\prime$ 维空间的表示 $\boldsymbol Z\in {\Bbb R}^{d\prime\times m}$, $d\prime \le d$ 且任意两个样本在 $d\prime$ 维空间中欧式距离等于在原始空间中的距离，即 $\left|z_i-z_j \right| = dist_{ij}$ 令 $\boldsymbol B$ 为降维后样本的内积矩阵，即 $\boldsymbol B = \boldsymbol Z^T\boldsymbol Z \in {\Bbb R}^{m\times m}$, 其中，$b_{ij} = z_i^Tz_j$ 则： \begin{equation} \begin{split} dist_{ij}^2 &= \left\| z_i\right\|^2 +\left\| z_j\right\|^2 -2z_i^Tz_j\\ &=b_{ii} + b_{jj}-2b_{ij} \end{split}\tag{1} \end{equation} 则矩阵 $\boldsymbol B$ 的行和列之和为零： \begin {equation} \begin {split} \sum_{i=1}^{m} b_{ij} &= \sum_{i=1}^{m}(z_i^Tz_j) \\ &=z_j\sum_{i=1}^{m}z_i^T\\ &= 0\\ \sum_{j=1}^{m} b_{ij} &= \sum_{j=1}^{m}(z_i^Tz_j) \\ &= z_i\sum_{j=1}^{m}z_j^T\\ &= 0 \end {split} \end {equation} 易知： \sum_{i=1}^{m}dist_{ij}^2 = \text tr(\boldsymbol B) + mb_{jj}\tag{2} \sum_{j=1}^{m}dist_{ij}^2 = \text tr(\boldsymbol B) + mb_{ii}\tag{3} \sum_{i=1}^{m}\sum_{j=1}^{m}dist_{ij}^2 = 2m \ \text tr(\boldsymbol B)\tag{4}其中，$\text{tr} (\cdot)$ 表示矩阵的迹，$\text{tr} = \sum_{i=1}^{m}{\left|z_i \right|}$ 令： \begin{align} dist_{i \cdot}^2 &= \frac{1}{m}\sum_{j=1}^{m}dist_{ij}^2 \tag{5} \\ dist_{\cdot j}^2 &= \frac{1}{m}\sum_{i=1}^{m}dist_{ij}^2 \tag{6} \\ dist_{\cdot \cdot}^2 &= \frac{1}{m^2}\sum_{i=1}^{m}\sum_{j=1}^{m}dist_{ij}^2 \tag{7}\\ \end{align} 由式(1)和(2)~(7)可得： b_{ij} = -\frac{1}{2}(dist_{ij}^2 - dist_{i\cdot}^2-dist_{\cdot j}^2+dist_{\cdot\cdot}^2)\tag{8}推导过程如下： 由式(1)得： b_{ij} = -\frac{1}{2}(dist_{ij}-b_{ii}-b_{jj})由式(4)和(7)得： \begin{align} \text tr(\boldsymbol B) &= \frac{1}{2m}\sum_{i=1}^{m}\sum_{j=1}^{m}dist_{ij}^2\\ &=\frac{1}{2m} \cdot m^2 dist_{\cdot \cdot}^2 \\ &=\frac{m}{2}dist_{\cdot \cdot}^2 \end{align}由式(2)和(6)得： \begin{align} b_{jj} &= \frac{1}{m}\sum_{i=1}^{m}dist_{ij}^2 - \frac{1}{m}\text tr(\boldsymbol B)\\ &=dist_{\cdot j}^2 - \frac{1}{2}dist_{\cdot \cdot}^2 \end{align}由式(3)和(5)得: \begin{align} b_{jj} &= \frac{1}{m}\sum_{j=1}^{m}dist_{ij}^2 - \frac{1}{m}\text tr(\boldsymbol B)\\ &=dist_{i\cdot}^2 - \frac{1}{2}dist_{\cdot \cdot}^2 \end{align}综上得： b_{ij} = -\frac{1}{2}(dist_{ij}^2 - dist_{i\cdot}^2-dist_{\cdot j}^2+dist_{\cdot\cdot}^2) 由此可通过降维前后保持不变的距离矩阵 $\boldsymbol D$ 求得内积矩阵 $\boldsymbol B$ 对矩阵 $\boldsymbol B$ 做特征值分解 $\boldsymbol B = \boldsymbol V \boldsymbol \Lambda \boldsymbol V^T$ 其中 $\Lambda = \text{diag}(\lambda_1,\lambda_2,….,\lambda_d)$ 为特征值构成的特征矩阵，$\lambda_1\ge\lambda_2\ge…\ge\lambda_d$ $\boldsymbol V $ 为特征向量矩阵 取 $d\prime &lt;&lt; d$ 个最大特征值构成对角矩阵 $\tilde{\Lambda} = \text{diag}(\lambda_1,\lambda_2,….,\lambda_{d\prime})$ 令 $\tilde{\boldsymbol V }$ 为相应的特征向量矩阵 则 $\boldsymbol Z$ 可表达为: \boldsymbol Z = \tilde{\Lambda}^{\frac{1}{2}}\tilde{\boldsymbol V }^T\ \in {\Bbb R}^{d\prime \times m}\tag{9} MDS 算法描述： 线性降维 对原始高维空间进行线性变换，得到低维子空间 给定 $d$ 维空间中的样本 $\boldsymbol X = (\boldsymbol x_1, \boldsymbol x_2,…, \boldsymbol x_m ) \in {\Bbb R}^{d\times m}$ 变换之后得到 $d\prime \le d$ 维空间中的样本 \boldsymbol Z = \boldsymbol W^T\boldsymbol X\tag{10} $\boldsymbol W \in {\Bbb R}^{d\times d\prime}$ 是变换矩阵 $\boldsymbol Z \in {\Bbb R}^{d\times m}$ 是样本在新空间中的表达 主成分分析 核化线性降维 流形学习等度量映射局部线性嵌入 度量学习]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（九）-- 聚类]]></title>
    <url>%2F2019%2F08%2F19%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89--%20%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（九） 聚类 聚类任务聚类 (clustering) 无监督学习 (unsupervised learning) 的一种 试图将数据划分为若干个不相交的子集，每个子集为一个 簇 (cluster) 每个簇可能对应于一些潜在的概念(类别) 聚类的形式化解释 样本集 $D = \{\boldsymbol x_1, \boldsymbol x_2,…,\boldsymbol x_m\}$ 包含 $m$ 个样本 每个样本 $\boldsymbol x_i = (x_{i1}; x_{i2}; …;x_{in})$ 是一个 $n$ 维向量 聚类算法将样本 $D$ 划分为 $k$ 个不相交的簇 $\{C_l | l = 1,2,…,k \}$, 其中 $C_i \bigcap C_j = \emptyset$, $ (i \ne j)$ 且 $D = \bigcup_{l=1}^{k}C_l$ 用 $\lambda_j \in \{1,2,…,k \}$ 表示样本 $\boldsymbol x_j$ 的 “簇标记”，即 $\boldsymbol x_j \in C_{\lambda_j}$ 聚类结果 $\boldsymbol \lambda = \{\lambda_1;\lambda_2;…;\lambda_m\}$ 性能度量外部指标 (external index)变量符号定义： 数据集 $D = \{\boldsymbol x_1, \boldsymbol x_2,…,\boldsymbol x_m\}$ 聚类的簇划分 ${\cal C} = \{C_1,C_2,…, C_k\}$，簇标记向量 $\boldsymbol \lambda$ 参考模型给出的簇划分 ${\cal C^{*}} = \{C_1^{*}, C_2^{*},…, C_k^{*}\}$，簇标记向量 $\boldsymbol \lambda^{*}$ 定义： a = |SS|,\ \ SS=\{(\boldsymbol x_i,\boldsymbol x_j)\ |\ \lambda_i = \lambda_j,\lambda_i^* = \lambda_j^*, i < j\} \tag{1} b = |SD|,\ \ SD=\{(\boldsymbol x_i,\boldsymbol x_j)\ |\ \lambda_i = \lambda_j,\lambda_i^* \ne \lambda_j^*, i < j\} \tag{2} c = |DS|,\ \ DS=\{(\boldsymbol x_i,\boldsymbol x_j)\ |\ \lambda_i \ne \lambda_j,\lambda_i^* = \lambda_j^*, i < j\} \tag{3} d = |DD|,\ \ DD=\{(\boldsymbol x_i,\boldsymbol x_j)\ |\ \lambda_i \ne \lambda_j,\lambda_i^* \ne \lambda_j^*, i < j\} \tag{4} 其中： 集合 $SS$ 包含了在 $C$ 中隶属于相同簇且在 $C^*$ 中也隶属于相同簇的样本对 集合 $SD$ 包含了在 $C$ 中隶属于相同簇但在 $C^*$ 中隶属于不相同簇的样本对 …… 常用外部指标： Jaccard 系数 (Jaccard Coefficient, 简称 JC) JC = \frac{a}{a+b+c}\tag{5} FM 指数 (Fowlkes and Mallows Index, 简称FMI) FMI = \sqrt{\frac{a}{a+b}\cdot\frac{a}{a+c}}\tag{6} Rand 指数 (Rand Index, 简称 RI) RI = \frac{2(a+d)}{m(m-1)}\tag{7} 度量方法：上述性能度量的结果值均在 [0,1] 区间，值越大越好 内部指标 (internal index)变量符号定义： $avg(C)$: 簇 $C$ 内样本间的平均距离 avg(C) = \frac{2}{|C|(|C|-1)}\sum_{1\le i]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（八）-- 集成学习]]></title>
    <url>%2F2019%2F08%2F19%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89--%20%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（八）集成学习 个体与集成集成学习 (ensemble learning)集成学习的一般思路： 集成学习通过构建并结合多个学习器来完成学习任务 集成学习的一般结构： 先产生一组 “个体学习器” 在用某种策略将它们结合起来 集成学习的集成分类： 同质 (homogeneous) 集成中只包含同种类型的个体学习器 异质 (heterogenous) 集成中包含不同类型的个体学习器 集成学习的基本原则：若要获得好的集成 个体学习器应该 “好而不同” 即个体学习器要有一定的 “准确性” 即学习器不能太坏，并且要有 “多样性”，即学习器间有差异 集成学习的方法分类： 序列化方法 个体学习器间存在强依赖关系、必须串行生成 代表：Boosting 并行化方法 个体学习器间不存在强依赖关系、可同时生成 代表：Bagging、随机森林 BoostingBoosting简介Boosting 是一族可将弱学习器提升为强学习其的算法 工作机制： 先从初始训练集训练出一个基学习器 再根据基学习器的表现对训练样本分布进行调整 使得先前基学习器做错的训练样本在后续受到更多关注 然后再基于调整后的样本分布来训练下一个基学习器 如此重复，直到基学习器的数目达到指定值 $T$ 再将 $T$ 个基学习器进行加权结合 AdaBoost 算法AdaBoost算法是Boosting 族算法的代表 AdaBoost算法描述： 其中：$y_i \in \{-1,+1 \}$, $f$ 是真实函数 AdaBoost 算法推导： Bagging 与随机森林BaggingBagging算法简介： Bagging 是并行式集成学习方法最著名的代表 Bagging算法流程： 基于自助采样法采样出 $T$ 个含有 $m$ 个样本的训练集 然后基于每个采样集训练出一个基学习器 再将这些基学习器结合 在对预测输出进行结合时： 分类任务：简单投票法 回归任务：简单平均法 随机森林 (Random Forrest, 简称 RF)随机森林算法简介： RF 在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中加入随机属性的选择 随机森林算法流程： 在选择划分属性时，对决策树的每个结点，先从该结点的属性集合中随机选择一个包含 $k$ 个属性的子集 $k$ 控制了随机性的引入程度，其推荐值为 $k = \log_2d$ 然后再从这个子集中选择一个最优属性用于划分 结合策略学习器结合的好处： 假定集成包含 $T$ 个基学习器 $\{h_1,h_2,…,h_T \}$, 其中 $h_i$ 在示例 $\boldsymbol x$ 上的输出为 $h_i(\boldsymbol x)$ 平均法平均法是回归任务，即数值型输出 $h_i(\boldsymbol x) \in {\Bbb R}$, 常使用的结合策略 简单平均法 (simple average) H(\boldsymbol x) = \frac{1}{T}\sum_{i=1}^{T}h_i(\boldsymbol x) 加权平均法 (weighted average) H(\boldsymbol x) = \sum_{i=1}^{T}w_ih_i(\boldsymbol x)其中 $w_i$ 为个体学习器 $h_i$ 的权重，权重一般需要从训练数据中学习而得 在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时宜使用简单平均法 投票法投票法是分类任务，即学习器 $h_i$ 将从类别标记集合 $\{c_1,c_2,…,c_N \}$ 中预测出一个标记，常用的结合策略 假定 $h_i$ 在样本 $\boldsymbol x$ 上的预测输出为一个 $N$ 维向量 $(h_i^1(\boldsymbol x);h_i^2(\boldsymbol x);…;h_i^N(\boldsymbol x))$, 其中 $h_i^j(\boldsymbol x)$ 是 $h_i$ 在类别标记 $c_j$ 上的输出 绝对多数投票法 \begin {equation} H(\boldsymbol x) = \begin {cases} c_j \qquad &{\text if}\ \sum_{i=1}^{T}h_i^j(x)>0.5\sum_{k=1}^{T}\sum_{i=1}^{T}h_i^j(x)\\ {\text reject} &{\text otherwise} \end {cases} \end {equation}即，若某类标记得票过半数，则预测为该标记，否则拒绝预测 相对多数投票法 H(\boldsymbol x) = c_{\mathop{\arg \max}_{j}\sum_{i=1}^{T}h_i^j(\boldsymbol x)}即，预测为得票最多的标记 加权投票法 H(\boldsymbol x) = c_{\mathop{\arg \max}_{j}\sum_{i=1}^{T}w_ih_i^j(\boldsymbol x)}$w_i$ 是 $h_i$ 的权重 学习法学习法简介： 当训练数据很多时，一种更为强大的结合策略是使用 “学习法” 即通过另一个学习器来进行结合 其中个体学习器称为初级学习器 用于结合的学习器称为次级学习器 典型代表：Stacking Stack算法流程： 先从初始训练集中训练出初级学习器 然后 “生成” 一个新数据集用于训练次级学习器 在新数据集中，初级学习器的输出被当做样例输入特征 初始样本的标记仍被当做样例标记 多样性误差-分歧分解问题描述： 假定用个体学习器 $h_1,h_2,…,h_T$ 通过加权平均法结合产生的集成来完成回归任务 $f : {\Bbb R}^d\mapsto {\Bbb R} $ 误差-分歧分解： 对于示例 $\boldsymbol x$ ，定义学习器 $h_i$ 的 分歧 为： A(h_i|\boldsymbol x) = \left(h_i(\boldsymbol x)-H(\boldsymbol x) \right)^2\tag{8.27} 则集成的 分歧 是： \begin {align} \overline A(h|\boldsymbol x) &= \sum_{i=1}^Tw_iA(h_i|\boldsymbol x) \\ &= \sum_{i=1}^Tw_i\left(h_i(\boldsymbol x)-H(\boldsymbol x) \right)^2\tag{8.28} \end {align} 分歧 项表征了个体学习器在样本 $\boldsymbol x$ 上的不一致性 即在一定程度上反映了个体学习器的多样性 个体学习器 $h_i$ 的平方误差为： E(h_i|\boldsymbol x) = (f(\boldsymbol x)-h_i(\boldsymbol x))^2\tag{8.29} 集成 $H$ 的平方误差为： E(H|\boldsymbol x) = (f(\boldsymbol x)-H(\boldsymbol x))^2\tag{8.30} 令个体学习器误差的加权值为：$\overline E(h|\boldsymbol) = \sum_{i=1}^Tw_i\cdot E(h_i|\boldsymbol x) $ 则，集成的分歧 \begin {align} \overline A(h|\boldsymbol x) &= \sum_{i=1}^{T}w_iE(h_i|\boldsymbol x)-E(H|\boldsymbol x)\\ &= \overline E(h|\boldsymbol x)-E(H|\boldsymbol x)\tag{8.31} \end {align} 令 $p(\boldsymbol x)$ 表示样本的概率密度，则在全样本上有： \sum_{i=1}^{T}w_i\int A(h_i|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x = \sum_{i=1}^{T}w_i\int E(h_i|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x - \int E(H|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x \tag{8.32} 令个体学习器 $h_i$ 在全样本上的泛化误差和分歧项分别为: E_i = \int E(h_i|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x\tag{8.33} A_i = \int A(h_i|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x \tag{8.34} 集成的泛化误差为： E = \int E(H|\boldsymbol x)p(\boldsymbol x)d\boldsymbol x \tag{8.35} 令 $\overline E = \sum_{i=1}^Tw_iE_i$ 表示个体学习器泛化误差的加权均值 令 $\overline A = \sum_{i=1}^Tw_iA_i$ 表示个体学习器的加权分歧值 将 (8.33)~(8.34)带入(8.32)得： E = \overline E-\overline A \tag{8.36}个体学习器的准确性越高、多样性越大，则集成越好 多样性度量多样性度量 (diversity measure) 用于度量集成中个体分类器的多样性 即估算个体学习器的多样化程度 列联表 给定数据集 $D = \{ (\boldsymbol x_1,y_1),(\boldsymbol x_2,y_2),…,(\boldsymbol x_m,y_m)\}$ 对二分类任务，$y_i \in \{-1, +1\}$ 分类器 $h_i$ 和 $h_j$ 的预测结果列联表为: 其中，$a$ 表示 $h_i$ 和 $h_j$ 均预测为正类的样本数目 …… 常见多样性性能度量 不合度量 (disagreement measure) dis_{ij} =\frac{b+c}{m}\tag{8.37}$dis_{ij}$ 的值域为 [0, 1], 值越大则多样性越大 相关系数 (correlation coefficient) \rho_{ij} = \frac{ad-bc}{\sqrt{a+b}\sqrt{a+c}\sqrt{c+d}\sqrt{b+d}}\tag{8.38}$\rho_{ij}$ 的值域为 [-1,1], 若 $h_i$ 和 $h_j$ 无关，则值为0；若 $h_i$ 和 $h_j$ 正相关则值为正，否则为负 Q-统计量 (Q-statistic) Q_{ij} = \frac{ad-bc}{ad+bc}\tag{8.39}$Q_{ij}$ 的值域为 [-1,1], 若 $h_i$ 和 $h_j$ 无关，则值为0；若 $h_i$ 和 $h_j$ 正相关则值为正，否则为负 $\kappa$-统计量 ($\kappa$-statistics) \kappa = \frac{p_1-p_2}{1-p_2}\tag{8.40}其中，$p_1$ 是两个分类器取得一致的概率： p_1 = \frac{a+d}{m}\tag{8.41}$p_2$ 是 两个分类器偶然达成一致的概率： p_2 = \frac{(a+b)(a+c)+(c+d)(b+d)}{m^2}\tag{8.42}若分类器 $h_i$ 与 $h_j$ 在 $D$ 上完全一致，则 $\kappa = 1$; 若它们仅是偶然达成一致，则 $\kappa = 0$ 多样性增强 数据样本扰动 输入属性扰动 输出表示扰动 算法参数扰动]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（七）-- 贝叶斯分类器]]></title>
    <url>%2F2019%2F08%2F17%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89--%20%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（七）贝叶斯分类器 贝叶斯决策论条件风险 (conditional risk) 假设有 $N$ 种可能的类别标记，即 $ {\cal Y} = \{c_1,c_2,…,c_N \}$ 将样本 $\boldsymbol x$ 分类为 $c_i$ 所产生的期望损失 ，即在样本 $\boldsymbol x$ 上的 “条件风险” 为： R(c_i|\boldsymbol x) = \sum_{j=1}^{N}\lambda_{ij}P(c_j|\boldsymbol x) \tag{1}其中： $\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本分类为 $c_i$ 所产生的损失； $P(c_i|\boldsymbol x)$ 表示样本 $\boldsymbol x $ 属于类别 $c_j$ 的后验概率 贝叶斯决策论 (Bayesian decision theory) 基于相关概率和误判损失来选择最优类别标记 即寻找一个判定准则 $h: {\cal X} \mapsto {\cal Y}$ 以最小化总体风险 R(h) = E_x[R(h(\boldsymbol x)\ | \ \boldsymbol x)] \tag{2} 贝叶斯判定准则 (Bayes decision rule) 为最小化总体风险，只需在每个样本上选择那个能使条件风险 $R(c|\boldsymbol x)$ 最小的类别标记，即： h^*(\boldsymbol x) = \mathop{\arg\min}_{c\in {\cal Y}}\ {R(c\ |\ \boldsymbol x)} \tag{3} 此时： $h^*$ 称为贝叶斯最优分类器 (Bayes optimal classifier) 总体风险 $R(h^*)$ 称为贝叶斯风险 (Bayes risk) $1-R(h^*)$ 反映了分类器所能达到的最好性能 最小化的错误率的贝叶斯最优分类器： 若目标是最小化分类错误率，则误判损失 $\lambda_{ij}$ 可写为： \lambda_{ij} = \begin{cases} 0, & \text{if} \ \ i = j\\ 1, & \text{otherwise} \end{cases} \tag{4} 此时条件风险为 R(c\ |\ \boldsymbol x) = 1-P(c\ | \ \boldsymbol x) \tag{5}解析： \begin {equation} \begin {split} &R(c_i|\boldsymbol x) = 1 * P(c_1|\boldsymbol x) + 1 * P(c_2|\boldsymbol x) + ... + 0 * P(c_i|\boldsymbol x)+ ... + 1 * P(c_N|\boldsymbol x) \\ &\because \ \sum_{j=1}^{N}P(c_j|\boldsymbol x) = 1 \\ &\therefore \ R(c_i|\boldsymbol x) = 1-P(c_i|\boldsymbol x) \end {split} \end {equation} 于是，最小化分类错误率的贝叶斯最优分类器为： h^*{(\boldsymbol x)} = \mathop{\arg\max}_{c\in\cal Y}\ P(c \ |\ \boldsymbol x) \tag {6}即，对每个样本 $x$, 选择能使后验概率 $P(c | \boldsymbol x)$ 最大的类别标记 欲使用贝叶斯判定准则最小化决策风险，首先要获得后验概率 $P(c | \boldsymbol x)$ 估计后验概率 $P(c | \boldsymbol x)$ 的两种策略： 判别式模型 (discriminative models) 给定 $x$, 可通过直接建模 $P(c | \boldsymbol x)$ 来预测 $c$ 如：决策树、BP神经网络、支持向量机 生成式模型 (generative models) 先对联合概率分布 $P(\boldsymbol x,c)$ 建模，然后由此获得 $P(c | \boldsymbol x)$ ，即： P(c \ |\ \boldsymbol x) = \frac{P(\boldsymbol x, c)}{P(\boldsymbol x)}\tag{7} 基于贝叶斯定理，得： P(c \ |\ \boldsymbol x) = \frac{P(c)\ P(\boldsymbol x \ |\ c)}{P(\boldsymbol x)}\tag{8} $P(c)$: 是类先验概率 表达了样本空间中各类样本所占的比例 根据大数定律，当训练集中包含充足的独立同分布样本时，$P(c)$ 可通过各类样本出现的频率来进行估计 $P(\boldsymbol x | c)$: 是样本 $\boldsymbol x$ 相对于类标记 $c$ 的类条件概率，或称为“似然” 类条件概率涉及关于 $\boldsymbol x$ 所有属性的联合概率 不能直接根据样本出现的频率来进行估计 $P(\boldsymbol x)$: 是用于归一化的证据因子 对给定的样本 $\boldsymbol x$, 证据因子与类别标记无关 极大似然估计极大似然估计 (Maximum Likehood Estimation) 估计类条件概率的一种常用策略 令 $D_c$ 表示训练集 $D$ 中第 $c$ 类样本组成的集合 假设这些样本时独立同分布的，则参数 $\theta_c$ 对于数据集 $D_c$ 的似然是： P(D_c \ | \ \theta_c) = \prod_{\boldsymbol x\in D_c} \ P(\boldsymbol x \ |\ \theta_c)\tag{9} 对 $\theta_c$ 进行极大似然估计，就是寻找能最大化似然 $P(D_c | \theta_c)$ 的参数值 $\hat \theta_c$. 为了避免下溢，通常使用对数似然： \begin{equation} \begin{split} LL(\theta_c) &= \log\ P(D_c\ | \ \theta_c)\\ &= \sum_{x\in D_C}\ \log\ P(\boldsymbol x\ | \ \theta_c) \end{split} \end{equation} \tag{10} 此时，参数 $\theta_c$ 的极大似然估计 $\hat \theta_c$ 为： \hat \theta = \mathop{\arg \max}_{\theta_c}\ LL(\theta_c) \tag{11} 极大似然估计的例子： 例如，在连续属性情形下，假设概率密度函数 $p(\boldsymbol x | c) $ ~ $\cal N(\boldsymbol\mu_c,\boldsymbol\sigma_c)$. 则参数 $\boldsymbol\mu_c$ 和 $\boldsymbol\sigma_c$ 的极大似然估计为: \boldsymbol{\hat \mu_c} = \frac{1}{|D_c|}\ \sum_{\boldsymbol x\in D_c}\ \boldsymbol x \tag{12} \boldsymbol{\hat \sigma_c} = \frac{1}{|D_c|} \ \sum_{\boldsymbol x \in D_c}(\boldsymbol x - \boldsymbol {\hat \mu})(\boldsymbol x - \boldsymbol {\hat \mu})^T\tag{13} 解析过程如下： 朴素贝叶斯分类器朴素贝叶斯分类器 (naive Bayes classifier)： 采用了属性条件独立性假设 (attribute conditional independence assumption)：对已知类别，假设所有属性相互独立 基于属性独立性条件假设，式 (8) 可重写为： P(c\ |\ \boldsymbol x) = \frac{P(c)P(\boldsymbol x\ |\ c)}{P(\boldsymbol x)} = \frac{P(c)}{P(\boldsymbol x)}\prod_{i=1}^{d}P(x_i\ |\ c)\tag{14}其中 $d$ 为属性数目，$x_i$ 为 $\boldsymbol x$ 在第 $i$ 个属性上的取值 朴素贝叶斯分类器的表达式： h_{nb}(x) = \mathop{\arg\max}_{c\in \cal Y} \ P(c)\prod_{i=1}^{d}\ P(x_i\ |\ c)\tag{15} 朴素贝叶斯分类器的训练过程就是基于训练集 D 来估计类先验概率 P(c), 并为每个属性估计条件概率 $P(x_i | c)$ . $P(c)$ : 类先验概率 P(c) = \frac{|D_c|}{|D|}\tag{16}其中, $D_c$ 表示训练集 $D$ 中，第 $c$ 类样本组成的集合 $P(x_i | c)$ : 表示第 $c$ 类样本在 i 个属性上取值为 $x_i$ 的条件概率 P(x_i\ | \ c) = \frac{|D_{c,x_i}|}{|D_c|}\tag{17}其中，$D_{c,x_i}$ 表示 $D_c$ 中在第 $i$ 个属性上取值为 $x_i$ 的样本组成的集合 对于连续属性，假设服从正态分布，则： P(x_i\ | \ c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}}\exp\left(-\frac{(x_i - \mu_{c,i})^2}{2\sigma^2_{c,i}} \right)\tag{18}其中，$\mu_{c,i}$ 和 $\sigma^2_{c,i}$ 分别是第 $c$ 类样本在第 $i$ 个属性上取值的均值和方差 朴素贝叶斯分类器例子： 用西瓜数据集 3.0 训练一个朴素贝叶斯分类器，对测试例 “测1” 进行分类： 西瓜数据集 3.0 首先估计类先验概率 $P(c)$ P(好瓜 = 是) = \frac{8}{17}\approx 0.471\\ P(好瓜 = 否) = \frac{9}{17}\approx 0.529\\ 然后，为每个属性估计类条件概率 $P(x_i | c)$ 测试例 于是，有： 因此，朴素贝叶斯分类器将测试样本 “测1” 判别为 “好瓜” 拉普拉斯修正 (Laplacian correction)： 为了避免其他属性携带的信息被训练集中未出现的属性值 “抹去”，在估计概率值是通常要进行 “平滑” 拉普拉斯修正： \begin{align} \hat P(c) &= \frac{|D_c|+1}{|D|+N} \tag{19}\\ \hat P(x_i\ |\ c) &= \frac{|D_{c,x_i}|+1}{|D|+N_i} \tag{20}\\ \end{align}其中，$N$ 表示训练集 $D$ 中可能的类别数，$N_i$ 表示第 $i$ 个属性可能的取值数 半朴素贝叶斯分类器 贝叶斯网结构学习推断 EM算法]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（六）-- 支持向量机]]></title>
    <url>%2F2019%2F08%2F16%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89--%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（六） 支持向量机 间隔与支持向量给定训练集，分类学习最基本的想法就是基于训练集在样本空间中找到一个划分超平面，将不同类别的样本划分开来，且要求划分超平面产生的分类结果要尽可能鲁棒，对未见示例的泛化能力要尽可能强 划分超平面 划分超平面的线性方程描述： \boldsymbol w^T \boldsymbol x + b = 0\tag{6.1}其中 $\boldsymbol w = (w_1;w_2;…;w_d)$ 为法向量，决定超平面的方向； $b$ 为位移项，决定了超平面与原点之间的距离； 将此超平面记为 $(\boldsymbol w, b)$ 样本空间中的任意点 $\boldsymbol x$ 到超平面的 $(\boldsymbol w, b)$ 距离为: r = \frac{|\boldsymbol w^T \boldsymbol x + b|}{||\boldsymbol w||}\tag{6.2} 假设超平面 $(\boldsymbol w, b)$ 能将训练样本正确分类，即对于 $(\boldsymbol x_i, y_i) \in D$: 若 $y_i = +1$, 则有 $\boldsymbol w^T \boldsymbol x_i + b &gt; 0$ 若 $y_i = -1$, 则有 $\boldsymbol w^T \boldsymbol x_i + b &lt; 0$ 令 \begin {equation} \begin {cases} \boldsymbol w^T \boldsymbol x_i + b \ge +1, \ \ y_i = +1 \\ \boldsymbol w^T \boldsymbol x_i + b \le -1, \ \ y_i = -1 \end {cases}\tag{6.3} \end {equation} 式 (6.3) 推导 假设超平面是 $(\boldsymbol w^\prime)^T\boldsymbol x + \boldsymbol b^\prime= 0 $, 对于 $(\boldsymbol x_i, y_i)$, 有： \begin {equation} \begin {cases} (\boldsymbol w^\prime)^T \boldsymbol x_i + b^\prime > 0, \ \ y_i = +1 \\ (\boldsymbol w^\prime)^T \boldsymbol x_i + b^\prime < 0, \ \ y_i = -1 \end {cases}\tag{*} \end {equation} 根据几何间隔，将以上关系可修正为: \begin {equation} \begin {cases} (\boldsymbol w^\prime)^T \boldsymbol x_i + b^\prime \ge +\xi, \ \ y_i = +1 \\ (\boldsymbol w^\prime)^T \boldsymbol x_i + b^\prime \le -\xi, \ \ y_i = -1 \end {cases}\tag{**} \end {equation} 由 $\xi &gt; 0$ 得： \begin {equation} \begin {cases} (\frac{1}{\xi} \boldsymbol w^\prime)^T \boldsymbol x_i + \frac{1}{\xi}b^\prime \ge +1, \ \ y_i = +1 \\ (\frac{1}{\xi}\boldsymbol w^\prime)^T \boldsymbol x_i + \frac{1}{\xi}b^\prime \le -1, \ \ y_i = -1 \end {cases}\tag{***} \end {equation} 令 $\boldsymbol w = \frac{1}{\xi} \boldsymbol w^\prime$, $b = \frac{1}{\xi}b^\prime$, 得： \begin {equation} \begin {cases} \boldsymbol w^T \boldsymbol x_i + b \ge +1, \ \ y_i = +1 \\ \boldsymbol w^T \boldsymbol x_i + b \le -1, \ \ y_i = -1 \end {cases}\tag{****} \end {equation} 支持向量 (support vector)： 距离超平面最近的几个训练样本可使上式 (6.6) 的等号成立，它们被称为 “支持向量” 间隔 (margin): 两个异类支持向量到超平面的距离之和为 \gamma = \frac{2}{||\boldsymbol w ||}\tag{6.4}它被称为 “间隔” 支持向量机(Support Vector Machine, SVM) 最大化间隔： \begin {equation} \begin {split} & \mathop{\max} _{\boldsymbol w,b}\frac{2}{||\boldsymbol w||}\\ & s.t.\ y_i(\boldsymbol w^T \boldsymbol x_i + b) \ge 1,i = 1,2,...,m \end {split}\tag{6.5} \end {equation} 最大化 $||\boldsymbol w||^{-1}:$ 最小化 $||\boldsymbol w||^{2}:$ \begin {equation} \begin {split} & \mathop{\min}_{\boldsymbol w,b} \frac{1}{2} {||\boldsymbol w||}^2\\ & s.t.\ y_i(\boldsymbol w^T \boldsymbol x_i + b) \ge 1,i = 1,2,...,m \end {split}\tag{6.6} \end {equation} 此为支持向量机 (Support vector Machine，简称SVM) 的基本型 对偶问题SVM 基本型的对偶问题 (dual problem) 式 (6.6) 对应的拉格朗日函数： L(\boldsymbol w, b, \alpha) = \frac{1}{2}\left\|\boldsymbol w \right\|^2+\sum_{i=1}^{m}{\alpha_i\left( 1-y_i(\boldsymbol w^T\boldsymbol x_i+b)\right )}\tag{6.8}其中，$\alpha = (\alpha_i;\alpha_2;…;\alpha_m)$. 令 $L(\boldsymbol w, b, \alpha)$ 对 $\boldsymbol w$ 和 $b$ 求偏导为零可得: \begin {align} \boldsymbol w &= \sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i}\tag{6.9}\\ 0 &= \sum_{i=1}^{m}{\alpha_i y_i}\tag{6.10} \end {align} 式 (6.9) 和 (6.10) 推导： \begin {align} L(\boldsymbol w, b, \alpha) &= \frac{1}{2}\left\|\boldsymbol w \right\|^2+\sum_{i=1}^{m}{\alpha_i\left( 1-y_i(\boldsymbol w^T\boldsymbol x_i+b)\right )}\\ &= \frac{1}{2}\left\|\boldsymbol w \right\|^2+\sum_{i=1}^{m}{\left( \alpha_i-\alpha_iy_i\boldsymbol w^T\boldsymbol x_i+\alpha_iy_ib)\right )}\\ &= \frac{1}{2}\left\|\boldsymbol w \right\|^2 + \sum_{i=1}^{m}\alpha_i - \sum_{i=1}^{m}\alpha_iy_i\boldsymbol w^T\boldsymbol x_i - \sum_{i=1}^{m}\alpha_iy_ib \end {align}对 $\boldsymbol w$ 和 $b$ 求偏导为零可得: \begin {align} \frac{\partial L}{\partial \boldsymbol w} &= \frac{1}{2}\times 2\times \boldsymbol w + 0 - \sum_{i=1}^{m}\alpha_iy_i\boldsymbol x_i - 0 = 0 \Rightarrow \boldsymbol w = \sum_{i=1}^{m}\alpha_iy_i\boldsymbol x_i \\ \frac{\partial L}{\partial \boldsymbol b} &= 0 + 0 - 0 - \sum_{i=1}^{m}\alpha_iy_i\Rightarrow 0 = \sum_{i=1}^{m}\alpha_iy_i \end {align} 将式 (6.9) 带入 (6.8) 得: \begin {align} L(\boldsymbol w, b, \alpha) &= \frac{1}{2}\boldsymbol w^T\boldsymbol w +\sum_{i=1}^{m}{\alpha_i} - \sum_{i=1}^{m}\alpha_iy_i\boldsymbol w^T\boldsymbol x_i - \sum_{i=1}^{m}\alpha_iy_ib \\ &= \frac{1}{2}\boldsymbol w^T \sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i}+\sum_{i=1}^{m}{\alpha_i} - \sum_{i=1}^{m}\alpha_iy_i\boldsymbol w^T\boldsymbol x_i - \sum_{i=1}^{m}\alpha_iy_ib \\ &= \frac{1}{2}\boldsymbol w^T \sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i} - \boldsymbol w^T\sum_{i=1}^{m}\alpha_iy_i\boldsymbol x_i + \sum_{i=1}^{m}{\alpha_i} - b\sum_{i=1}^{m}\alpha_iy_i \\ &=- \frac{1}{2}\boldsymbol w^T \sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i} + \sum_{i=1}^{m}{\alpha_i} - b\sum_{i=1}^{m}\alpha_iy_i \\ &= - \frac{1}{2}\boldsymbol (\sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i})^T \sum_{i=1}^{m}{\alpha_i y_i\boldsymbol x_i} + \sum_{i=1}^{m}{\alpha_i} - b\sum_{i=1}^{m}\alpha_iy_i \\ &= \sum_{i=1}^{m}{\alpha_i} - \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}{\alpha_i\alpha_jy_iy_j\boldsymbol x_i^T\boldsymbol x_j} -b\sum_{i=1}^{m}\alpha_iy_i \\ \end {align} 再考虑式 (6.10) 的约束，得到式 (6.6) 的对对偶问题： \begin {align} &\mathop{\max}_{\alpha}{\sum_{i=1}^{m}{\alpha_i} - \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}{\alpha_i\alpha_jy_iy_j\boldsymbol x_i^T\boldsymbol x_j}}\tag{6.11}\\ &s.t \ \sum_{i=1}^{m}\alpha_iy_i = 0, \ \alpha_i \ge0,i = 1, 2,...,m \end {align} 核函数 间隔与正则化 支持向量回归]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（五）-- 神经网络]]></title>
    <url>%2F2019%2F08%2F14%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89--%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（五） 神经网络 神经元模型神经网络 (neural network): 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的反应 神经网络中最基本的成分是神经元模型 神经元 (neuron) 模型: M-P神经元模型 神经元接收到来自 $n$ 个其他神经元传递过来的输入信号 这些输入信号通过权重的连接进行传递 神经元收到的总输入值将与神经元的阈值进行比较，然后通过 “激活函数” 处理以产生神经元的输出 激活函数 (activation function): 阶跃函数 Sigmoid函数 感知机与多层网络感知机 (Perceptron)感知机： 由两层神经元组成 输入层接收外界输入信号传递给输出层 输出层是M-P神经元 给定训练数据集，权重 $w_i (i = 1,2,…,n)$ 以及阈值 $\theta$ 可通过学习得到 将阈值 $\theta$ 可以看做一个固定输入为 -1.0 的 “哑结点” 所对应的权重$w_{n+1}$ 感知机学习规则： 对训练样例 $(\boldsymbol x, y)$, 若当前感知机的输出为 $\hat y$, 则感知机的权重将这样调整： \begin {equation} \begin {split} w_i &\leftarrow w_i + \Delta w_i,\\ \Delta w_i &= \eta(y-\hat y)x_i, \end {split} \end{equation}其中 $\eta \in (0, 1)$ 称为学习率 (learning rate). 注意： 感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非常有限 感知机无法解决非线性可分问题 要解决非线性可分问题，需要考虑使用多层功能神经元 多层前馈神经网络 (multi-layer feedforward neural networks)多层前馈神经网络： 每层神经元与下一层神经元完全互联，神经元之间不存在同层连接，也不存在跨层连接 输入层神经元接收外界输入 隐层与输出层神经元对信号进行加工，最终结果有输出层神经元输出 即，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元 神经网络学习： 神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权” (connection weight) 以及每个神经元的阈值 误差逆传播算法误差逆传播算法 (error BackPropagation)： 一种用来训练神经网络的强大学习算法，简称 BP 算法 BP网络通常是指用 BP 算法训练的多层前馈神经网络 符号定义： 训练集： $D = \{(\boldsymbol x_1, \boldsymbol y_1), (\boldsymbol x_2, \boldsymbol y_12, …, (\boldsymbol x_m, \boldsymbol y_m) \}, \boldsymbol x_i \in R^d, \boldsymbol y_i \in R^l$ , 即输入示例由 $d$ 个属性描述，输出 $l$ 维实值向量 网络结构： $d$ 个输入神经元 $l$ 个输出神经元 $q$ 个隐层神经元 阈值： $\theta_j$: 输出层第 $j$ 个神经元的阈值 $\gamma_h$: 隐层第 $h$ 个神经元的阈值 连接权： $v_{ih}$: 输入层第 $i$ 个神经元与隐层第 $h$ 个神经元之间连接权 $w_{hj}$: 隐层第 $h$ 个神经元与输出层第 $j$ 个神经元之间的连接权 神经元输出： $b_h$: 隐层第 $h$ 个神经元的输出 神经元输入： $a_h$: 隐层第 $h$ 个神经元接收到的输入 $a_h = \sum_{i=1}^{d}v_{ih}x_i$ $\beta_j$: 输出层第 $j$ 个神经元接收到的输入 $\beta_j = \sum_{i=1}^{d}w_{hj}b_h$ 激活函数： 假设隐层和输出层神经元都使用 Sigmoid 函数 神经网络输出： 对训练样例 $(\boldsymbol x_k, \boldsymbol y_k)$, 假定神经网络输出为 $\hat y_k = (\hat y_1 ^k,\hat y_2 ^k,…,\hat y_l ^k)$, 即： \hat y_j^k = f(\beta _j - \theta_j) \tag {1} 均方误差： 网络在样例 $(\boldsymbol x_k, \boldsymbol y_k)$ 上的误差为： E_k = \frac{1}{2}\sum_{j=1}^{l}{(\hat y_j^k - y_j^k)^2} \tag{2} 需要学习的参数： 基于上述定义，网络中有 $(d + l + 1)q + l$ 个参数需要确定 输入层到隐层的 $d\times q$ 个权值 隐层到输出层的 $q \times l$ 个权值 隐层的 $q$ 个阈值 输出层的 $l$ 个阈值 参数更新： BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计，即对任意参数 $v$ 的更新为: v \leftarrow v + \Delta v 基于梯度下降 (gradient descent)策略，以目标的负梯度方向对参数进行调整，对式(2)的误差 $E_k$ , 给定学习率 $\eta$, 有： \Delta w_{hj} = -\eta \frac{\partial E_k}{\partial w_{hj}}\tag{3} 反向传播：由于 $w_{hj}$ 先影响到第 $j$ 个输出层神经元的输入值 $\beta_j$, 再影响到其输出值 $\hat y_j^k$ , 然后影响到 $E_k$, 由链式法则得: \frac{\partial E_k}{\partial w_{hj}} = \frac{\partial E_k}{\partial \hat y_j^k} \cdot \frac{\partial y_j^k}{\partial \beta _j} \cdot \frac{\partial \beta_j}{\partial w_{hj}}\tag{4} 根据 $\beta_j$ 的定义，得: \frac{\partial \beta_j}{\partial w_{hj}} = b_h \tag{5} Sigmoid函数 $f(x)$ 的导数： f\prime(x) = f(x)(1-f(x)) \tag{6} 根据式(1)(2)和(6)，有: \begin {equation} \begin {split} g_j &= - \frac{\partial E_k}{\partial \hat y_j^k} \cdot \frac{\partial y_j^k}{\partial \beta _j}\\ &= -(\hat y_j^k - y_j^k)f\prime(\beta_j-\theta_j)\\ &= \hat y_j ^k(1-\hat y_j^k)(y_j^k-\hat y_j^k) \end {split} \end {equation} \tag{7} 由式(3)(4)(5)和(7)即可得 BP 算法中关于 $w_{hj}$ 的更新公式: \Delta w_{hj} = \eta g_jb_h \tag{8} 类似可得： \begin {align} \Delta \theta_j &= -\eta g_j\tag{9}\\ \Delta v_{ih} &= \eta e_hx_i \tag{10}\\ \Delta \gamma_h &= -\eta e_h \tag{11} \end {align} 其中： \begin {equation} \begin {split} e_h &= -\frac{\partial E_k}{\partial b_h} \cdot \frac{\partial b_h}{\partial\alpha_h}\\ &= -\sum_{j=1}^{l}\frac{\partial E_k}{\partial \beta_j} \cdot \frac{\partial \beta_j}{\partial b_h} f\prime(\alpha_h-\gamma_h)\\ &=\sum_{j=1}^{l}w_{hj}g_jf\prime(\alpha_h-\gamma_h)\\ &= b_h(1-b_h)\sum_{j=1}^{l}w_{hj}g_j \end {split} \end {equation} \tag{12} BP算法工作流程: 对于每个输入样例： 先将输入示例提供给输入层神经元 然后逐层将信号前传，直到产生输出层的结果 然后计算输出层的误差 (4-5行) 再将误差逆向传播至隐层神经元 (第6行) 最后根据隐层神经元的误差来对连接权和阈值进行调整 (第7行) 标准BP算法： 以上介绍的误差逆传播算法称为 标准BP算法 更新规则基于单个的 $E_k$ 推导而得 每次仅针对一个训练样本更新连接权和阈值 参数更新的非常频繁，而且对于不同的样例进行更新的效果可能出现 “抵消” 现象 需要更多的迭代次数 累积BP算法： 累积误差逆传播算法是要最小化训练集 $D$ 上的累积误差: $E = \frac{1}{m}\sum_{k=1}^{m}E_k$ 在读取整个训练集 $D$ 一遍后才对参数进行更新 参数更新频率低得多 缓解BP网络过拟合的策略： 早停 (early stopping): 将数据集分为训练集和验证集 训练集用来计算梯度、更新连接权和阈值 验证集用来估计误差 若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值 正则化 (regularization): 基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分 例如连接权和阈值的平方和 仍令 $E_k$ 表示第 $k$ 个训练样本上的误差， $w_i$ 表示连接权和阈值，则误差目标函数改变为： E_k = \lambda\frac{1}{m}\sum_{k=1}^{m}E_k + (1-\lambda)\sum_{i}{w_i^2}其中 $\lambda \in (0,1)$ 用于对经验误差和网络复杂度这两项进行折中，常通过交叉验证法来估计。 全局最小与局部极小局部极小 (local minimum)局部极小解： 对 $ \boldsymbol w^\prime$ 和 $ \theta^\prime $，若存在 $\epsilon &gt; 0$ 使得： \forall (\boldsymbol w;\theta) \in \{(\boldsymbol w; \theta) \boldsymbol | \ ||(\boldsymbol w;\theta) - (\boldsymbol w^\prime;\theta^\prime)|| \le \epsilon \}都有 $E(\boldsymbol w;\theta ) &gt; E(\boldsymbol w^\prime;\theta^\prime)$ 成立，则 $(\boldsymbol w^\prime;\theta^\prime)$ 为局部极小解 局部极小解是参数空间中的某个点，其领域点的误差函数值均不小于该点的函数值 参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点 可能存在多个局部极小值，但却只会有一个全局最小值 全局最小 (global minimum)全局最小解： 对 $\boldsymbol w^\prime$ 和 $\theta^\prime$，若存在 $\epsilon &gt; 0$ 使得： \forall (\boldsymbol w;\theta) \in \{(\boldsymbol w; \theta) \boldsymbol | \ ||(\boldsymbol w;\theta) - (\boldsymbol w^\prime;\theta^\prime)|| \le \epsilon \}对参数空间的任意 $(\boldsymbol w;\theta)$, $E(\boldsymbol w;\theta ) &gt; E(\boldsymbol w^\prime;\theta^\prime)$ 成立，则 $(\boldsymbol w^\prime;\theta^\prime)$ 为全局最小解 全局最小解则是指参数空间中所有点的误差函数值均不小于该点的误差函数值 全局最小一定是局部极小，反之不成立 参数寻优参数寻优： 参数寻优过程中就是希望找到全局最小 参数寻优方法：梯度下降 梯度下降法参数寻优： 从某些初始解出发，迭代寻找参数最优解 每次迭代中，先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向 由于梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜素最优解 若误差函数的当前梯度为零，则已达到局部极小，更新量将为零，这意味着参数的迭代更新将在此停止 如果误差函数仅有一个局部极小，则此时找到的局部极小就是全局最小 如果误差函数具有多个局部极小，则不能保证找的的解是全局最小，即参数寻优陷入了局部极小 “跳出”局部极小，达到全局最小： 以多组不同参数初始化多个神经网络，选择最接近全局最小的 模拟退火：每一步以一定的概率接收比当前解更差的结果 随机梯度下降 其他常见的神经网络RBF网络ART网络SOM网络级联相关网络Elman网络Boltzmann机 深度学习]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（四）-- 决策树]]></title>
    <url>%2F2019%2F08%2F13%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89--%20%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（四） 决策树 基本流程决策树 (decision tree)： 一类常见的机器学习算法 决策树是基于树形结构进行决策的 决策树学习的目的是产生一棵泛化能力强，即处理未见示例能力强的决策树 基本流程：决策树基本流程遵循简单直观的“分而治之”策略，如下图所示： 在决策树基本算法中，有三种情形会导致递归返回： 当前结点包含的样本全属于同一类别，无需划分 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分 将当前结点标记为叶子结点 并将其类别设定为该结点所含样本最多的类别 当前结点包含的样本集合为空，不能划分 将当前结点标记为叶子结点 并将类别设定为其父节点所含样本最多的类别 划分选择决策树学习的关键是 如何选择最优划分属性，一般而言，随着划分过程的不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”越来越高。 信息增益信息熵 (information entropy): 信息熵是度量样本集合纯度最常用的一种指标。 假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为 $p_k (k = 1, 2, …, |{\cal Y}|)$, 则 $D$ 的信息熵定义为： Ent(D) = - \sum _{k = 1}^{|{\cal Y}|}p_k\log_2p_k$Ent(D)$ 的值越小，则 $D$ 的纯度越高 信息增益 (information gain): 假设离散属性 $a$ 有 $V$ 个可能的取值 $\{a^1, a^2, … , a^V\}$ 使用 $a$ 对样本集 $D$ 进行划分，则会产生 $V$ 个分支结点，其中第 $v$ 个分支结点包含了 $D$ 中所有在属性 $a$ 上取值为 $a^v$ 的样本，记为 $D^v$. Gain(D, a) = Ent(D) - \sum _{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v).信息增益越大，则意味着使用属性 $a$ 来进行划分所获得的 “纯度提升”越大。 以信息增益为准则选择划分属性： a_* = \mathop{\arg\max}_{a\in A} Gain(D, a)增益率信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，C4.5决策树算法不直接使用信息增益，而是使用“增益率”来选择最优划分属性。 增益率 (gain ratio): Gain\_ratio(D,a) = \frac{Gain(D, a)}{IV(a)}其中： IV(a) = - \sum_{v=1}^{V}\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}称为属性 $a$ 的 “固有值” 基尼指数GART 决策树使用 “基尼指数”来选择划分属性 基尼值：用来度量数据集 $D$ 的纯度 \begin {equation} \begin {split} Gini(D) &= \sum_{k=1}^{|y|}\sum_{k\prime \ne k} p_kp_{k\prime}\\ &= 1 - \sum_{k=1}^{|y|}{p_k^2} \end {split} \end {equation}$Gini(D)$ 越小，则数据集 $D$ 的纯度越高 基尼指数 (Gini index): Gini\_index(D, a) = \sum_{v=1}^{V}\frac{|D^v|}{|D|}Gini(D^v) 剪枝处理剪枝 (pruning): 决策树学习算法对付“过拟合”的主要手段 预剪枝 (pre-pruning) 指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分并将当前结点标记为叶结点 具体示例详见课本 P-80 后剪枝 (post-pruning) 先从训练集生成一棵完整的决策树，然后自底向上对非叶结点进行考察，若将该结点对应子树替换成叶结点能带来决策树泛化能力的提升，则将该子树替换为叶结点 具体示例详见课本 P-82 连续与缺失值连续值处理常用的将连续属性离散化技术是二分法策略。 二分法 (bi-partition): 给定样本集 $D$ 和连续属性 $a$ , 假定 $a$ 在 $D$ 上出现了 $n$ 个不同的取值 将这些值从小到大进行排序，记为 $\{a^1, a^2,…,a^n\}$. 基于划分点 $t$, 将 $D$ 分为两个子集 $D_t^-$ 和 $D_t^+$ 其中 $D_t^-$ 包含那些在属性 $a$ 取值不大于 $t$ 的样本，而 $D_t^+$ 则包含那些在属性 $a$ 取值大于 $t$ 的样本 对于相邻属性取值 $a^i$ 和 $a^{i+1}$ 来说，$t$ 在区间 $[a^i, a^{i+1})$ 中取任意值所产生的划分结果相同 因此，对于连续属性 $a$, 我们可考察包含 $n-1$ 个元素的候选划分点集合： T_a = \{\frac{a^i + a^{i+1}}{2} \ |\ 1 \le i \le n-1 \}即，以区间 $[a^i, a^{i+1})$ 的中位点 $\frac{a^i + a^{i+1}}{2}$ 作为候选划分点 选取最优划分点进行样本集合划分： \begin {equation} \begin {split} Gain(D, a) &= max_{t \in T_a} Gain(D,a,t) \\ &= max_{t \in Ta} Ent(D) - \sum_{\lambda \in \{-, +\}}\frac{|D_t^\lambda|}{|D|}Ent(D_t^\lambda) \end {split} \end {equation}其中 $Gain(D, a, t)$ 是样本集 $D$ 基于划分点 $t$ 二分后的信息增益 于是，我们就可选出使 $Gain(D, a, t)$ 最大化的划分点 缺失值处理如何在属性值缺失的情况下进行划分属性选择？ 给定训练集 $D$ 和属性 $a$ , 令 $\tilde D$ 表示 $D$ 在属性 $a$ 上没有缺失值的样本子集 假定属性 $a$ 有 $V$ 个可能的取值 $\{a^1, a^2, … ,a^V \}$ 令 $\tilde D^v$ 表示 $\tilde D$ 中在属性 $a$ 取值为 $a^v$ 的样本子集，则 $\tilde D = \bigcup_{v=1}^{V}\tilde D^v.$ 令 $\tilde D_k$ 表示 $\tilde D$ 中属于第 $k$ 类 $(k = 1,2 , … , |y|)$ 的样本子集 $\tilde D = \bigcup_{k=1}^{|y|}\tilde D_k.$ 假定为每个样本 $x$ 赋予一个权重 $w_x$, 并定义： $\rho$ 表示无缺失值样本所占的比例： \rho = \frac{\sum_{x\in\tilde D}w_x}{\sum_{x\in D}w_x} $\tilde p_k$ 表示无缺失值样本中第 $k$ 类所占的比例： \tilde p_k = \frac{\sum_{x\in\tilde D_k}w_x}{\sum_{x\in\tilde D}w_x}显然：$\sum_{k=1}^{|y|}\tilde p_k = 1$ $\tilde r_v$ 表示无缺失值样本中在属性 $a$ 上取值 $a^v$ 的样本所占的比例： \tilde r_v = \frac{\sum_{x\in\tilde D^v}w_x}{\sum_{x\in\tilde D}w_x}显然：$\sum_{v=1}^{V}\tilde r_v = 1$ 基于上述定义，我们可以将信息增益的计算式推广为： \begin {equation} \begin {split} Gain(D, a) &= \rho \times Gain(\tilde D, a)\\ &= \rho \times (Ent(\tilde D) - \sum_{v =1}^{V}\tilde r_v Ent(\tilde D^v)) \end {split} \end{equation}其中： Ent(\tilde D) = -\sum _{k=1}^{|y|}{\tilde p_k \log_2 \tilde p_k} 给定划分属性，若样本在该属性上的值确实，如何对样本进行划分？ 若样本 $x$ 在划分属性 $a$ 上的取值已知： 则将 $x$ 划入与其取值对应的子结点，且样本权值在子结点中保持为 $w_x$ 若样本 $x$ 在划分属性 $a$ 上的取值未知： 则将 $x$ 同时划分到所有子结点，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\tilde r^v \cdot w_x$ 多变量决策树多变量决策树 (multivariate decision tree)： 能实现 “斜划分” 甚至更复杂划分的决策树 非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试 在多变量决策树的学习过程中，不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（三）-- 线性模型]]></title>
    <url>%2F2019%2F08%2F10%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89--%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（三）线性模型 基本形式1. 回顾各符号对应的概念示例： $\boldsymbol x = (x_1; x_2; … ; x_d)$ 属性： $x_i$ 属性个数(维度)： $d$ 数据集： $D = \{\boldsymbol x_1, \boldsymbol x_2, …, \boldsymbol x_m\}$ 模型： $f$ 模型在示例 $\boldsymbol x$ 上的预测输出： $f(\boldsymbol x)$ 2. 线性模型 (linear model)线性模型的目的： 试图学得一个【通过属性的线性组合来进行预测】的【函数】 线性模型的本质： 学得一个线性函数 线性模型的特征： 通过属性的线性组合来进行预测，即： f(\boldsymbol x) = w_1x_1 + w_2x_2 + ... + w_dx_d + b向量形式为: f(x) = \boldsymbol w^T\boldsymbol x + b其中 $\boldsymbol w = (w1;w2;…;wd)$ ，由于w直观的表达了各属性在预测中的重要性，因此线性模型具有很好的可解释性。 线性回归1. 线性回归 (linear regression)给定数据集 $D = {(\boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), … , (\boldsymbol x_m, y_m)}$ , 其中 $\boldsymbol x_i = (x_{i1}; x_{i2}; … x_{id}), y_i \in R$ . 线性回归的目的： 试图学得一个【线性模型】以尽可能准确地【预测实值输出标记】 线性回归的本质： 学得线性模型 线性模型的作用： 预测实值输出标记 线性模型的目的： 试图学得一个【通过属性的线性组合来进行预测】的【函数】 总的来讲，线性回归是一个函数，通过属性的线性组合来进行预测，尽可能准确地预测实值输出标记。 线性回归的分类： 一元线性回归分析：回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，则称为一元线性回归分析 多元线性回归分析：回归分析中，包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析 2. 最小二乘法 (least square method)最小二乘法： 基于均方误差最小化来进行模型求解的方法，均方误差对应了欧氏距离 所谓“二乘”，就是用平方来度量观测点与估计点的远近 所谓“最小”，是指参数的估计值要保证各个观测点与估计点的距离平方和达到最小 最小二乘法的目的： 在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到这条直线上的欧式距离之和最小 进一步解释： 最小二乘法是一种数学优化技术，它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简单的求得未知数据，并使得这些求得的数据与实际数据之间误差的平方和最小。 在线性回归中的误差平方和： 如果说误差就是预测点 $f(x_i)$ 到标记点 $y_i$ 的距离 那么均方误差 $E(f;D) = \frac{1}{m} \sum_{i = 1}^{m} {(f(x_i)-y_i)^2}$ 则可以体现误差的平方和 这就意味着，线性回归需要最小化均方误差 3. (属性数目为1的简单例子)一元线性回归我们先考虑一种最简单的情形：输入属性的数目只有一个 此时数据集为：$D = \{(x_1, y_1), (x_2, y_2), … , (x_m, y_m)\}$ 线性回归模型试图学得： f(x_i) = wx_i + b, 使得f(x_i) \approx y_i如何确定 $w$ 和 $b$： 最小二乘法，试图让均方误差最小化，即： \begin{equation} \begin{split} (w^*, b^*) &= \mathop{\arg\min}_{(w,b)} \ E_{(w, b)}\\ &= \mathop{\arg\min}_{(w,b)} \ \sum_{i = 1}^{m}{(f(x_i) - y_i)^2}\\ &= \mathop{\arg\min}_{(w,b)} \ \sum_{i = 1}^{m}{(y_i - wx_i - b)^2}\\ \end{split} \end{equation}参数估计： 求解w和b使均方误差最小化的过程，称为线性回归模型的最小二乘“参数估计”（parameter estimation） 根据函数知识可知，一般 U形曲线的函数，如$f(x) = x^2$ ，通常都是凸函数，其最小值点一般在函数的极小值点处，也就是偏导数为0的点。 所以，我们可以将 $E(w,b)$ 分别对 $w$ 和 $b$ 求偏导，并令偏导等于0，即可得到 $w$ 和 $b$ 的最优解，具体过程如下： 将 $E(w,b)$ 分别对 $w$ 和 $b$ 求偏导 \begin{equation} \begin{split} \frac{\partial{E_{(w,b)}}}{\partial w} &= 2(w\sum_{i = 1}^{m}{x_i^2} - \sum_{i = 1}^{m}{(y_i - b)x_i}) \\ \frac{\partial{E_{(w,b)}}}{\partial b} &= (mb - \sum_{i = 1}^{m}{(y_i-wx_i)}) \\ \end{split} \end{equation} 令偏导为零, 得到得到 $w$ 和 $b$ 的最优解 \begin{equation} \begin{split} w &= \frac{\sum_{i=1}^{m}{y_i(x_i - \overline x)}}{\sum_{i = 1}^{m}{x_i^2}-\frac{1}{m}{(\sum_{i=1}^{m}{x_i})^2}} \\ b &= \frac{1}{m} \sum_{i=1}^{m}{(y_i - wx_i)^2} \\ \end{split} \end{equation}其中 $\overline x = \frac{1}{m} \sum_{i=1}^{m}x_i$ 为 $x$ 的均值。 4. (属性数目为d的复杂例子)多元线性回归现实中我们几乎碰不见属性值个数为1的例子，通常情况下，样本由d个属性描述。 此时，数据集为：$D = \{ (\boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), … , (\boldsymbol x_m, y_m)\}$ ，其中 $\boldsymbol x_i = (x_{i1}; x_{i2}; … x_{id}), y_i \in R$ 线性回归模型试图学得： f(\boldsymbol x_i) = w\boldsymbol x_i + b, 使得f(\boldsymbol x_i) \approx y_i如何确定 w 和 b： 类似的，可以用最小二乘法来对 $w$ 和 $b$ 进行估计，具体过程如下： 将$w$ 和 $b$ 吸入向量形式 $\hat w = (w; b)$ 把数据集 $D$ 表示成一个 $m \times (d + 1)$ 大小的矩阵 $\boldsymbol X$，其中每行对应一个示例，该行前个 $d$ 元素对应于示例的 $d$ 个属性值，最后一个元素恒置为1，即： \boldsymbol X = \begin{pmatrix} x_{11} & x_{12} & \ldots & x_{1d} & 1 \\ x_{21} & x_{22} & \ldots & x_{2d} & 1 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \\ x_{m1} & x_{m2} & \ldots & x_{md} & 1 \end{pmatrix} = \begin{pmatrix} \boldsymbol x_1^T & 1 \\ \boldsymbol x_2^T & 1 \\ \vdots & \vdots \\ \boldsymbol x_m^T & 1 \end{pmatrix} 把标记写成向量形式：$y = (y_1; y_2; …;y_m)$ 求预测的误差平方和：$E_{\hat w} = (y - \boldsymbol X \hat w)^T(y - \boldsymbol X \hat w)$ 最小化均方误差： \begin {equation} \begin {split} \hat w^* &= \mathop{\arg \min}_{\hat w} \ E_{\hat w}\\ &= \mathop{\arg \min}_{\hat w} \ (y - \boldsymbol X \hat w)^T(y - \boldsymbol X \hat w) \end{split} \end {equation} 将 $E_{\hat w}$ 对 $\hat w$ 求导得到: \frac{\partial E_{\hat w}}{\partial {\hat w}} = 2 \boldsymbol X^T(\boldsymbol X \hat w - y) 然后分别考虑特殊情况和一般情况： 特殊情况：$\boldsymbol X^T \boldsymbol X$ 为满秩矩阵或正定矩阵时，令偏导值为0，可得 $\boldsymbol {\hat w ^*} = (\boldsymbol X^T \boldsymbol X)^{-1}\boldsymbol X^T y$ , 令 $\boldsymbol {\hat x_i} = (\boldsymbol x_i; 1)$ ，则最终学得的多元线性回归模型为： f(\hat x_i) = \hat x_i^T (\boldsymbol X^T \boldsymbol X)^{-1}\boldsymbol X^T y. 一般情况：实际上，$\boldsymbol X^T \boldsymbol X$ 一般都不是满秩矩阵，此时可以解出来多个 $\boldsymbol {\hat w}$ , 它们都能使均方误差最小化，选择哪一个作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化项。 5. 线性模型的丰富变化 线性回归模型： 将线性模型的预测值逼近真实标记 $y$, 即：$y = w^T \boldsymbol x + b$ 对数线性回归： 将线性模型的预测值逼近真实标记 $y$ 的衍生物，如对数：$\ln(y) = w^T \boldsymbol x + b$ 广义线性模型： 更一般地，考虑单调可微函数 $g(.)$, 可以得到更多的真实标记 $y$ 的衍生物，令 $g(y) = w^T \boldsymbol x + b$, 即 $y = g^{-1}{(w^T \boldsymbol x + b)}$, 这样得到的模型称为广义线性模型，其中 $g(.)$ 称为 “联系函数”。 对数几率回归预测： 依靠机器学习学得的模型，对新的示例进行结果判断 回归任务： 预测的是连续值 分类任务： 预测的是离散值 如果说线性模型预测连续值，只需要让预测值逼近真实标记 $y$ 或其衍生物的话，当预测离散值的时候，如何让线性模型的预测值 (连续) 和真实标记值 $y$ (离散) 联系起来呢？ 其实，离散状态的真实标记 $y$, 未尝不可以有一种连续的衍生物 $z$, 这样通过单调可微的联系函数 $g(.)$ , 就可以让连续的预测值联系离散的真实标记。 1. 单位阶跃函数 (unit-step function)在二分类任务当中，输出标记为 $y = \{0, 1\}$ , 而线性回归模型产生的预测值：$z = \boldsymbol w^T \boldsymbol x + b$ 是实值。要将连续值 $z$ 转换为离散值 0/1，最理想的是 “单位阶跃函数” \begin {equation} y = \begin {cases} 0, & z < 0;\\ 0.5 & z = 0; \\ 1 & z > 0; \end {cases} \end {equation} 2. 对数几率函数 (logistic function)单位阶跃函数虽好，但是不可微，不是理想的联系函数 $g(.)$ , 我们希望找到一个在形态上趋近于单位阶跃函数的连续函数，并且是单调可微的。对数几率函数正是这样的一个函数： y = \frac {1}{1 + e^{-z}} 将 $ z = \boldsymbol w^T \boldsymbol x + b$ 带入可得 $y = \frac {1}{1 + e^{-( \boldsymbol w^T \boldsymbol x + b)}}$ , 亦即 $\ln \frac{y}{1-y} = \boldsymbol w^T \boldsymbol x + b$. 如果说将 $y$ 看作样本 $x$ 作为正例的可能性，那么 $1-y$ 就是其成反例的可能性。 几率： 两者的比值即为 “几率”，反映了样本作为正例的相对可能性 几率 = \frac {正例可能性}{反例可能性} = \frac{y}{1-y}对数几率： 对几率取对数就可得到 “对数几率” 对数几率 = \ln \frac{y}{1-y}对数几率回归： 用线性模型的预测结果去逼近真实标记的对数几率，其对应的模型叫做“对数几率回归”(logistic regression，亦称逻辑回归) 线性判别分析 (LDA)线性判别分析 (Linear Discriminant Analysis, LDA) 是一种经典的用于解决二分类问题的线性学习方法。 1. 二分类任务中的LDALDA大概分为三个步骤： 给定样例 寻找一条满足 “同类近，异类远”的投影直线 新样本的分类依靠投影后点的位置来确定 第一步：给定样例： 给定数据集 $D = \{(\boldsymbol x_i, y_i)\}_{i = 1}^{m}, y_i \in \{0, 1\}$, 令 $\boldsymbol X_j$、$\boldsymbol \mu_j$、$\boldsymbol \sum_j$ 分别表示第 $j \in \{0, 1\}$ 类示例的集合、均值向量、协方差矩阵。将数据投影到直线 $\boldsymbol w$ 上，则两类样本的 样本中心 在直线上的投影分别为 $\boldsymbol w^T \boldsymbol \mu_0$ 和$\boldsymbol w^T \boldsymbol \mu_1$，两类样本的协方差矩阵分别为 $\boldsymbol w^T \boldsymbol \sum_0 \boldsymbol w$ 和 $\boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$，由于直线是一维空间，因此 $\boldsymbol w^T \boldsymbol \mu_0$ 、$\boldsymbol w^T \boldsymbol \mu_1$、 $\boldsymbol w^T \boldsymbol \sum_0 \boldsymbol w$ 和、$\boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$均为实数。 顺便一提，如上图，横轴坐标分别为 x1 和 x2，代表样本的两个属性，此图代表属性个数为2时张成的二维空间。但当属性个数为n时，属性空间也为n维，只不过无法在图中体现了。 第二步：寻找投影直线： 两个原则： 同类近： 欲使得同类投影点尽可能近，可以让异类样例投影点的协方差尽可能小，即 $\boldsymbol w^T \boldsymbol \sum _0 \boldsymbol w + \boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w$ 尽可能小 异类远： 欲使得异类投影点尽可能远离，可以让类中心之间的距离尽可能大，即 $||\boldsymbol w^T \boldsymbol \mu_0 - \boldsymbol w^T \boldsymbol \mu_1||_2^2$ 尽可能大 广义瑞利商： 同时考虑二者，得到最大化目标，即： \begin {equation} \begin {split} J &= \frac{||\boldsymbol w^T \boldsymbol \mu_0 - \boldsymbol w^T \boldsymbol \mu_1||_2^2}{\boldsymbol w^T \boldsymbol \sum _0 \boldsymbol w + \boldsymbol w^T \boldsymbol \sum_1 \boldsymbol w}\\ &= \frac{\boldsymbol w^T(\boldsymbol \mu_0 - \boldsymbol \mu_1)(\boldsymbol \mu_0 - \boldsymbol \mu_1)^T\boldsymbol w}{\boldsymbol w^T (\boldsymbol \sum_0 + \boldsymbol \sum_1) \boldsymbol w} \end {split} \end {equation}类内散度矩阵： \begin {equation} \begin {split} \boldsymbol S_w &= \boldsymbol \sum _0 + \boldsymbol \sum _1 \\ & = \boldsymbol \sum_{x \in X_0}(\boldsymbol x - \boldsymbol \mu_0)(\boldsymbol x - \boldsymbol \mu_0)^T + \boldsymbol \sum_{x \in X_1}(\boldsymbol x - \boldsymbol \mu_1)(\boldsymbol x - \boldsymbol \mu_1)^T \end {split} \end {equation}类间散度矩阵： \boldsymbol S_b = (\boldsymbol \mu _0 - \boldsymbol \mu_1) (\boldsymbol \mu _0 - \boldsymbol \mu_1)^T重写得： J = \frac{\boldsymbol w^T \boldsymbol S_b \boldsymbol w}{\boldsymbol w^T \boldsymbol S_w \boldsymbol w}确定 $\boldsymbol w$ : $\boldsymbol J$ 的分子分母都是关于 $\boldsymbol w$ 的二次项，因此 $\boldsymbol J$ 的解与 $\boldsymbol w$ 的长度无关，只与其方向有关。 故由拉格朗日乘子法，可列 $\boldsymbol S_b \boldsymbol w = \lambda \boldsymbol S_w \boldsymbol w $，又由于 $\boldsymbol S_b \boldsymbol w$ 方向恒为 $(\boldsymbol \mu _0 - \boldsymbol \mu_1) $，令 $\boldsymbol S_b \boldsymbol w=\lambda(\boldsymbol \mu _0 - \boldsymbol \mu_1) $，带入得 $\boldsymbol w = \boldsymbol S _w ^{-1}(\boldsymbol \mu _0 - \boldsymbol \mu_1) $ 2. 多分类任务中的LDA 多分类学习多分类学习的两个思路： 一是将二分类学习方法直接推广到多分类，如LDA 二是基于某些策略，利用二分类学习器来解决多分类问题 拆解法和拆分策略拆解法： 将多分类任务拆解成为若干个二分类任务求解 拆解步骤： 通过拆分策略对问题进行【拆分】 为拆分出的每个二分类任务【训练】一个分类器 对各个分类器的结果进行【集成】，以获得多分类结果 拆分策略： “一对一 (OvO)” “一对其余 (OvR)” “多对多 (MvM)” 假设多分类学习有 $\boldsymbol N$ 个类别 $\boldsymbol C_1, \boldsymbol C_2, … \boldsymbol C_N$, 给定数据集 $ D = \{(\boldsymbol x_1, y_1),(\boldsymbol x_2, y_2),…,(\boldsymbol x_m, y_m)\}$, $y_i \in \{C_1, C_2, … ,C_n\}$ OvO: 将 $N$ 个分类分别两两配对，从而 【拆分】 成 $N(N-1)/2$ 个二分类任务 【训练】 时为了区分 $C_i$ 和 $C_j$ 这两个分类，这 $N(N-1)/2$ 个分类器的一个将 $C_i$ 作为正例，$C_j$ 作为反例 测试时将新样本同时提交给所有分类器，将得到 $N(N-1)/2$ 个分类结果，【集成】 的方法是通过投票在这些结果中选出最终结果 OvR: 将 $N$ 个分类中的1个分类拿出来作为一个分类器的正例，其余均设置为反例，从而【拆分】成 $N$ 个分类任务 【训练】 得到 $N$ 个分类器 【集成】 的方法是考虑各被判为正例的分类器的置信度，选择置信度大的类别标记作为分类的结果 MvM:MvM是OvO和OvR的一般形式，反过来说，OvO和OvR是MvM的特例。 MvM每次将若干个类作为正类，若干个其他类作为反类。但其构造必须有特殊的设计，不能随意选取。常用的一种MvM技术是“纠错输出码”（ECOC）技术。 “纠错输出码” (ECOC) 技术ECOC过程主要分为两步： 编码：对 $N$ 个类进行 $M$ 次划分，产生 $M$ 个分类器 解码：$M$ 个分类器对测试样本进行预测，得到 $M$ 个预测标记。将其组成编码；这个编码与 $N$ 个类别各自的编码进行比较，返回其中距离较小的类别作为最终预测的结果 编码形式： 二元码： “正类”、“反类” 三元码： “正类”、“反类”、“停用类” 以二元 ECOC 码为例：如下图，首先，将 $N (N = 4)$ 个类提供设计构造成 $M (M = 5)$ 个分类器 $(f_1, f_2,f_3,f_4,f_5)$, 每个分类器为每个类分别配了一个标记结果 (-1或+1)，从而，每一个类 $C_i, i\in \{1, N\}$ 都获得了一个 $M$ 位的编码，这个编码就是 【各类所对应的编码】 当有一个测试示例 $A$ 时，先将 $A$ 依照次序放入 $M$ 个分类器中，得到了 $M$ 个分类标记结果 $(-1,-1,+1,-1,+1);$ 再将这 $M$ 个标记结果编成一个纠错输出码 $(-1-1+1-1+1);$ 最后去和【各类所对应的编码】进行比较海明距离或欧式距离，距离最短的编码对应的分类就是结果。 类别不平衡问题类别不平衡(class-imbalance) 就是指分类任务中不同类别的训练样例数目差别很大的情况 以二分类问题为例，该问题一般指的是训练集中正负样本数比例相差过大（比如正例9998个，负例2个），其一般会造成以下的一些情况： 类别少的误判惩罚过低，导致有所偏袒，当样本不确定时倾向于把样本分类为多数类。 样本数量分布很不平衡时，特征的分布同样会不平衡。 传统的评价指标变得不可靠，例如准确率。 而在多分类问题中，尽管原始训练集中可能不同类别训练样本数目相当，通过OvR、MvM进行拆分时也有可能会造成上述情况，所以类别不平衡问题亟待解决。 再缩放： 解决类别不平衡问题一个最基本思路是 “再缩放”，即当正反例数目不同时，令 $m^+$ 表示正例数目，$m^-$ 表示反例数目，则： 几率 = \frac{y\prime}{1-y\prime} = \frac{y}{1-y}\times\frac{m^-}{m^+}再缩放的思想虽然简单，但实际操作却不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往不成立，即我们未必能基于训练集的观察几率来推断真实几率 现有技术大体上有三类做法： 第一类是对训练集里的反类样例进行欠采样，即去除一些反例使得正、反例数目接近 第二类是对训练集里的正类样例进行过采样，即增加一些正例使得正、反例数目接近 第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将上式嵌入到其决策过程中，称为阈值移动]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[课程一(Neural Networks and Deep Learning), 第四周(Deep Neural Networks)——Programming Assignments 5、Deep Neural Network Application]]></title>
    <url>%2F2019%2F08%2F08%2F%E8%AF%BE%E7%A8%8B%E4%B8%80(Neural%20Networks%20and%20Deep%20Learning)%2C%20%E7%AC%AC%E5%9B%9B%E5%91%A8(Deep%20Neural%20Networks)%E2%80%94%E2%80%94Programming%20Assignments%205%E3%80%81Deep%20Neural%20Network%20Application%2F</url>
    <content type="text"><![CDATA[Deep Neural Network for Image Classification Application When you finish this, you will have finished the last programming assignment of Week 4, and also the last programming assignment of this course! You will use the functions you had implemented in the previous assignment to build a deep network, and apply it to cat vs non-cat classification. Hopefully, you will see an improvement in accuracy relative to your previous logistic regression implementation. After this assignment you will be able to: Build and apply a deep neural network to supervised learning. Let’s get started! PackagesLet’s first import all the packages that you will need during this assignment. numpy is the fundamental packages for scientific computing with Python. matplotlib is a library to plot graphs in Python. h5py is a common package to interact with a dataset that is stored on an H5 file. PIL and scipy are used here to test your model with your own picture at the end. dnn_app_utils provides the functions implemented in the “Building your Deep Neural Network: Step by Step” assignment to this notebook. np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Code: 123456789101112131415import timeimport numpy as npimport h5pyimport matplotlib.pyplot as pltimport scipyfrom PIL import Imagefrom scipy import ndimage from dnn_app_utils_v2 import *from lr_utils import load_datasetplt.rcParams['figure.figsize'] = (5.0, 4.0)plt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'np.random.seed(1) DatasetYou will use the same “Cat vs non-Cat” dataset as in “Logistic Regression as a Neural Network “ (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better! Problem Statement: You are given a dataset (“data.h5”) containing: 123- a training set of m_train images labelled as cat (1) or non-cat (0)- a test set of m_test images labelled as cat and non-cat- each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Let’s get more familiar with the dataset. Load the data by running the cell below. 1train_x_orig, train_y, test_x_orig, test_y, classes = load_data() The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. 1234# Example of a pictureindex = 7plt.imshow(train_x_orig[index])print ("y = " + str(train_y[0,index]) + ". It's a " + classes[train_y[0,index]].decode("utf-8") + " picture.") Result: y = 1. It’s a cat picture. Code: 123456789101112# Explore your dataset m_train = train_x_orig.shape[0] # 行数num_px = train_x_orig.shape[1] # 列数m_test = test_x_orig.shape[0] # 行数print ("Number of training examples: " + str(m_train))print ("Number of testing examples: " + str(m_test))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_x_orig shape: " + str(train_x_orig.shape))print ("train_y shape: " + str(train_y.shape))print ("test_x_orig shape: " + str(test_x_orig.shape))print ("test_y shape: " + str(test_y.shape)) Result: 1234567Number of training examples: 209Number of testing examples: 50Each image is of size: (64, 64, 3)train_x_orig shape: (209, 64, 64, 3)train_y shape: (1, 209)test_x_orig shape: (50, 64, 64, 3)test_y shape: (1, 50) As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below. Code: 12345678910# Reshape the training and test examples train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T # The "-1" makes reshape flatten the remaining dimensionstest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T # "-1" 使得剩下的维度变为1维# Standardize data to have feature values between 0 and 1.train_x = train_x_flatten/255.test_x = test_x_flatten/255.print ("train_x's shape: " + str(train_x.shape))print ("test_x's shape: " + str(test_x.shape)) Result: 12train_x's shape: (12288, 209)test_x's shape: (12288, 50) 12,288 equals 64×64×3 which is the size of one reshaped image vector. Then, integrate the above code into the function dataset_preprocess() 123456789101112131415161718192021222324# Datasetdef dataset_preprocess(): """ Implementing Data Set Preprocessing Arguments: Returns: train_x: your training set features train_y: your training set labels test_x: your test set features test_y: your test set labels classes: """ # load data set train_x_orig, train_y, test_x_orig, test_y, classes = load_data() # Reshape the training and test examples train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T # 参数-1使得剩下的维度变为1维 test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T # Standardize data to have feature values between 0 and 1 train_x = train_x_flatten / 255 test_x = test_x_flatten / 255 return train_x, train_y, test_x, test_y, classes Architecture of your modelNow that you are familiar with the dataset, it is time to build a deep neural network distinguish cat images from non-cat images. You will build two different models: A 2-layer neural network. An L-layer neural network. You will then compare the performance of these models, and also try out different values for L. 2-layer neural network The model can be summarized as : INPUT -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID -&gt; OUTPUT. Detailed Architecture of figure 2: The input is a (64, 64, 3) image which is flatten to a vector of size (12288, 1) The corresponding vector: ${[x_0, x_1, …… ,x_{12287} ]}^T$ is then multiplied by the weight matrix $W^{[1]}$ of size ($n^{[1]}$, 12288). You then add a bias term and take its relu to get following vector: ${[a_0^{[1]}, a_1^{[1]}, …… ,a_{n^{[1]}-1} ^{[1]}]}^T$ You the repeat the same process. You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat. L-layer neural networkIt is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation: The model can be summarized as：[ LINEAR -&gt; RELU ] $ \times $ (L-1) -&gt; LINEAR -&gt;SIGMOID Detailed Architecture of figure 3: The input is a (64, 64, 3) image which is flattened to a vector of size (12288, 1). The corresponding vector: ${[x_0, x_1, …… ,x_{12287} ]}^T$ is the multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[1]}$. The result is called the linear unit. Next, you take the relu of the linear unit. This process could be repeated several times for each ($W^{[l]}, b^{[l]}$) depending on the model architecture. Finally, you take the sigmoid of the final linear unit. If it is a greater than 0.5, you classify it to be a cat. General methodologyAs usual you will follow the Deep Learning methodology to build the model: Initialize parameters / Define hyperparameters Loop for num_iterations: Forward propagation Compute cost function Backward propagation Update parameters Use trained parameters to predict labels Two - layer neural networkExercise: Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: LINEAR -&gt; RELU -&gt;LINEAR -&gt;SIGMOID. The functions you may need and their inputs are: 123456789101112131415def initialize_parameters(n_x, n_h, n_y): ... return parameters def linear_activation_forward(A_prev, W, b, activation): ... return A, cachedef compute_cost(AL, Y): ... return costdef linear_activation_backward(dA, cache, activation): ... return dA_prev, dW, dbdef update_parameters(parameters, grads, learning_rate): ... return parameters Code: 1234n_x = 12288 # num_px * num_px * 3n_h = 7n_y = 1layers_dims = (n_x, n_h, n_y) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# Two-layer neural networkdef two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False): """ Implements a two-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID Arguments: X -- input data, of shape (n_x, number of examples) Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) layers_dims -- dimensions of the layers (n_x, n_h, n_y) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- If set to True, this will print the cost every 100 iterations Returns: parameters -- a dictionary containing W1, W2, b1, and b2 """ np.random.seed(1) grads = &#123;&#125; costs = [] m = X.shape[1] (n_x, n_h, n_y) = layers_dims # Initialize parameters dictionary, by calling one # of the functions you'd previously implemented parameters = initialize_parameters(n_x, n_h, n_y) # Get W1, b1, W2, and b2 W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR-&gt; SIGMOID # Inputs: "X, W1, b1" # Outputs: "A1, cache1, A2, cache2" A1, cache1 = linear_activation_forward(X, W1, b1, activation = "relu") A2, cache2 = linear_activation_forward(A1, W2, b2, activation = "sigmoid") # Compute cost cost = compute_cost(A2, Y) # Initializing backward propagation dA2 = -(np.divide(Y, A2) - np.divide(1 - Y, 1 - A2)) # Backward propagation # Inputs: dA2, cache2, cache1 # Outputs: dA1, dW2, db2, dA0(not used), dW1, db1 dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation = "sigmoid") dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation = "relu") grads['dW1'] = dW1 grads['db1'] = db1 grads['dW2'] = dW2 grads['db2'] = db2 # Update parameters parameters = update_parameters(parameters, grads, learning_rate) # Retrieve W1, b1, W2, b2 from parameters W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Print the cost every 100 training iterations if print_cost and i % 100 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, np.squeeze(cost))) costs.append(cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per tens)') plt.title("Learning rate = " + str(learning_rate)) plt.show() return parameters Run the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Test: 1parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True) Result: 12345678910111213141516171819202122232425Cost after iteration 0: 0.693049735659989Cost after iteration 100: 0.6464320953428849Cost after iteration 200: 0.6325140647912678Cost after iteration 300: 0.6015024920354665Cost after iteration 400: 0.5601966311605748Cost after iteration 500: 0.515830477276473Cost after iteration 600: 0.4754901313943325Cost after iteration 700: 0.43391631512257495Cost after iteration 800: 0.4007977536203886Cost after iteration 900: 0.35807050113237987Cost after iteration 1000: 0.3394281538366413Cost after iteration 1100: 0.30527536361962654Cost after iteration 1200: 0.2749137728213015Cost after iteration 1300: 0.24681768210614827Cost after iteration 1400: 0.1985073503746611Cost after iteration 1500: 0.17448318112556593Cost after iteration 1600: 0.1708076297809661Cost after iteration 1700: 0.11306524562164737Cost after iteration 1800: 0.09629426845937163Cost after iteration 1900: 0.08342617959726878Cost after iteration 2000: 0.0743907870431909Cost after iteration 2100: 0.06630748132267938Cost after iteration 2200: 0.05919329501038176Cost after iteration 2300: 0.05336140348560564Cost after iteration 2400: 0.048554785628770226 Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this. Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below. Test: 1predictions_train = predict(train_x, train_y, parameters) Result: 1Accuracy: 1.0 Test: 1predictions_test = predict(test_x, test_y, parameters) Result: 1Accuracy: 0.72 Note: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called “early stopping” and we will talk about it in the next course. Early stopping is a way to prevent overfitting. Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Let’s see if you can do even better with an LL-layer model. L-layer Neural NetworkExercise: Use the helper functions you have implemented previously to build an LL-layer neural network with the following structure: [LINEAR -&gt; RELU]×(L-1) -&gt; LINEAR -&gt; SIGMOID. The functions you may need and their inputs are: 123456789101112131415def initialize_parameters_deep(layer_dims): ... return parameters def L_model_forward(X, parameters): ... return AL, cachesdef compute_cost(AL, Y): ... return costdef L_model_backward(AL, Y, caches): ... return gradsdef update_parameters(parameters, grads, learning_rate): ... return parameter Code: 1layers_dims = [12288, 20, 7, 5, 1] # 5-layer model 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# L-layer Neural Networkdef L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False): """ Implements a L-layer neural network: [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR-&gt;SIGMOID Arguments: X -- data, numpy array of shape (number of examples, num_px * num_px * 3) Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) layers_dims -- list containing the input size and each layer size, of length (number of layers + 1) learning_rate -- learning rate of the gradient descent update rule num_iterations -- number of iterations of the optimization loop print_cost -- if True, it prints the cost every 100 steps Returns: parameters -- parameters learnt by the model. They can then be used to predict """ np.random.seed(1) costs = [] # Parameters initialization parameters = initialize_parameters_deep(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: [LINEAR -&gt; RELU] * (L-1) -&gt; LINEAR -&gt;SIGMOID AL, caches = L_model_forward(X, parameters) # Compute cost cost = compute_cost(AL, Y) # Backward propagation grads = L_model_backward(AL, Y, caches) # Update parameters parameters = update_parameters(parameters, grads, learning_rate) # Print the cost every 100 training iterations if print_cost and i % 100 == 0: print("Cost after iteration &#123;&#125; : &#123;&#125;".format(i, np.squeeze(cost))) costs.append(cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations(per tens)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parameters You will now train the model as a 5-layer neural network. Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Test: 1parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True) Result: 12345678910111213141516171819202122232425Cost after iteration 0: 0.771749Cost after iteration 100: 0.672053Cost after iteration 200: 0.648263Cost after iteration 300: 0.611507Cost after iteration 400: 0.567047Cost after iteration 500: 0.540138Cost after iteration 600: 0.527930Cost after iteration 700: 0.465477Cost after iteration 800: 0.369126Cost after iteration 900: 0.391747Cost after iteration 1000: 0.315187Cost after iteration 1100: 0.272700Cost after iteration 1200: 0.237419Cost after iteration 1300: 0.199601Cost after iteration 1400: 0.189263Cost after iteration 1500: 0.161189Cost after iteration 1600: 0.148214Cost after iteration 1700: 0.137775Cost after iteration 1800: 0.129740Cost after iteration 1900: 0.121225Cost after iteration 2000: 0.113821Cost after iteration 2100: 0.107839Cost after iteration 2200: 0.102855Cost after iteration 2300: 0.100897Cost after iteration 2400: 0.092878 Test: 1pred_train = predict(train_x, train_y, parameters) Result: 1Accuracy: 0.985645933014 Test: 1pred_test = predict(test_x, test_y, parameters) Result: 1Accuracy: 0.8 Congrats! It seems that your 5-layer neural network has better performance (80%) than your 2-layer neural network (72%) on the same test set. This is a good performance for this task. Nice job! Though in the next course on “Improving deep neural networks” you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others you’ll also learn in the next course). Result AnalysisFirst, let’s take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images. Code: 1print_mislabeled_images(classes, test_x, test_y, pred_test) Result: A few type of images the model tends to do poorly on include: Cat body in an unusual position. Cat appears against a background of a similar color. Unusual cat color and species. Camera Angle. Brightness of the picture. Scale variation (cat is very large or small in image) Source Code]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>课后习题及编程练习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[课程一(Neural Networks and Deep Learning), 第四周(Deep neural networks)——Programming assignment 4、Building your Deep Neural Network, step by step]]></title>
    <url>%2F2019%2F08%2F07%2F%E8%AF%BE%E7%A8%8B%E4%B8%80(Neural%20Networks%20and%20Deep%20Learning)%2C%20%E7%AC%AC%E5%9B%9B%E5%91%A8(Deep%20neural%20networks)%E2%80%94%E2%80%94Programming%20assignment%204%E3%80%81Building%20your%20Deep%20Neural%20Network%2C%20step%20by%20step%2F</url>
    <content type="text"><![CDATA[Building your Deep Neural Network: Step by Step Welcome to your week 4 assignment (part 1 of 2)! You have previously trained a 2-layer Neural Network (with a signal hidden layer). This week, you will build a deep neural network, with as many layers as you want! In this notebook, you will implement all the functions required to build a deep neural network. In the next assignment, you will use these functions to build a deep neural network for image classification. After this assignment you will be able to: Use non-linear units like ReLU to improve your model Build a deeper neural network (with more than 1 hidden layer) Implement an easy-to-use neural network class Notation: Superscript [I] denotes a quantity associated with the $1^{th}$ layer. Example: $a^{[L]}$is the $L^{th}$ layer activation. $W^{[L]}$ and $b^{[L]}$ are the $L^{th}$ layer parameters. Superscript (i) denotes a quantity associated with the $i^{th}$ example. Example: $x^{(i)}$ is the $i^{th}$ training example. Lowerscript i denotes the $i^{th}$ entry of a vector. Example: $a_i^{[I]}$ denotes the $i^{th}$ entry of the $I^{th}$ layer’s activations. Let’s get started! PackagesLet’s first import all the packages that you will need during this assignment. numpy is the main packages for scientific computing with Python. matplotlib is a library to plot graphs in Python. dnn_utils provides some necessary functions for this notebook. testCases provides some test cases to assess the correctness of your functions. np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please don’t change the seed. Code: 1234567891011import numpy as npimport h5pyimport matplotlib.pyplot as pltfrom testCases_v2 import *from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backwardplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'np.random.seed(1) Outline of the AssignmentTo build your neural network, you will be implementing several “helper functions”. These helper functions will be used in the next assignment to build a two-layer neural network and an L-layer neural network. Each small helper function you will implement will have detailed instructions that will walk you through the necessary steps. Here is an outline of the assignment, you will: Initialize the parameters for a two-layer network and for an L-layer neural network. Implement the forward propagation module (shown in purple in the figure below). Complete the LINEAR part of a layer’s forward propagation step (resulting in $Z^{l}$). We give you the ACTIVATION function (relu / sigmoid). Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] forward function. Stack the [LINEAR-&gt;RELU] forward function L-1 times (for layers 1 through L-1) and add a [LINEAR-&gt;SIGMOID] at the end (for the final layer L). This gives you a new L_model_forward function. Compute the loss. Implement the backward propagation module (denoted in red in the figure below). Complete the LINEAR part of a layer’s backward propagation step. We give you the gradient of the ACTIVATION function (relu_backward / sigmoid_backward). Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] backward function. Stack [LINEAR-&gt;RELU] backward L-1 times and add [LINEAR-&gt;SIGMOID] backward in a new L_model_backward function Finally update the parameters. Note that for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backward propagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps. InitializationYou will write two helper functions that will initialize the parameters for your model. The first function will be used to initialize parameters for a two layer model. The second one will generalize this initialization process to L layers. 2-layer Neural NetworkExercise: Create and initialize the parameters of the 2-layer neural network. Instructions: The model’s structure is: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID​. Use random initialization for the weight matrices. Use np.random.randn(shape) *0.01 with the correct shape. Use zero initialize for the biases. Use np.zeros(shape). Code: 1234567891011121314151617181920212223242526272829303132333435# 1. 2-layer Neural Networkdef initialize_parameters(n_x, n_h, n_y): ''' Initialize parameters for a two-layer network Arguments: @n_x: size of the input layer @n_h: size of the hidden layer @n_y: size of the output layer Returns: @parameters: python dictionary containing your parameters: @W1: weight matrix of shape (n_h, n_x) @b1: bias vector of shape (n_h, 1) @W2: weight matrix of shape (n_y, n_h) @b2: bias vector of shape (n_y, 1) ''' np.random.seed(1) W1 = np.random.randn(n_h, n_x) * 0.01 b1 = np.zeros((n_h, 1)) W2 = np.random.randn(n_y, n_h) * 0.01 b2 = np.zeros((n_y, 1)) assert(W1.shape == (n_h, n_x)) assert(b1.shape == (n_h, 1)) assert(W2.shape == (n_y, n_h)) assert(b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters Test: 12345parameters = initialize_parameters(3,2,1)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) Result: 123456W1 = [[ 0.01624345 -0.00611756 -0.00528172] [-0.01072969 0.00865408 -0.02301539]]b1 = [[ 0.] [ 0.]]W2 = [[ 0.01744812 -0.00761207]]b2 = [[ 0.]] L-layer Neural NetworkThe initialization for a deeper L-layer neural network is more complicated because there are many more weight matrices and bias vectors. When completing the initialize_parameters_deep, you should make sure that your dimensions match between each layer. Recall that $n^{[l]}$ is the number of units of layer l. Thus for example if the size of our input X is (12288, 209) (with m = 209 examples) then: Remember that when we compute $WX + b$ in Python, it carries out broadcasting. For example, if: The $WX + b$ will be: Exercise: Implement initialization for an L-layer Neural Network. Instructions: The model’s structure is [LINEAR -&gt; RELU] $\times$ (L-1) -&gt; LINEAR -&gt; SIGMOID. It has L-1 layers using a ReLU activation function followed by an output layer with a sigmoid activation function. Use random initialization for the weight matrices. Use np.random.randn(shape) * 0.01. We will store $n^{[l]}$, the number of units in different layers, in a variables layer_dims. For example, the layer_dims for the “Planar Data classification model” from last week would have been [2,4,1]: There were two inputs, one hidden layer with 4 hidden units, and an output layer with 1 output unit. Thus means W1‘s shape was (4,2), b1 was (4,1), W2 was (1,4) and b2 was (1,1). Now you will generalize this to LL layers! Here is the implementation for L = 1 (one layer neural network). It should inspire you to implement the general case (L-layer neural network). 123if L == 1: parameters["W" + str(L)] = np.random.randn(layer_dims[1], layer_dims[0]) * 0.01 parameters["b" + str(L)] = np.zeros((layer_dims[1], 1)) Code: 123456789101112131415161718192021222324252627# 2. L-layer Neural Networkdef initialize_parameters_deep(layer_dims): ''' Initailize parameters for an L-layer neural network Arguments: @layer_dims: python array (list) containing the dimensions of each layer in our network Returns: @parameters: python dictionary containing your parameters "W1", "b1",... @W1: weight matrix of shape (layer_dims[l], layer_dims[l-1]) @b1: bias vector of shape (layer_dims[1], 1) ''' np.random.seed(3) parameters = &#123;&#125; L = len(layer_dims) # number of layers in the network for l in range(1, L): # Random Initialization parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01 parameters['b' + str(l)] = np.zeros((layer_dims[l], 1)) assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1])) assert(parameters['b' + str(l)].shape == (layer_dims[l], 1)) return parameters Test: 12345parameters = initialize_parameters_deep([5,4,3])print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) Result: 1234567891011121314W1 = [[ 0.01788628 0.0043651 0.00096497 -0.01863493 -0.00277388] [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218] [-0.01313865 0.00884622 0.00881318 0.01709573 0.00050034] [-0.00404677 -0.0054536 -0.01546477 0.00982367 -0.01101068]]b1 = [[ 0.] [ 0.] [ 0.] [ 0.]]W2 = [[-0.01185047 -0.0020565 0.01486148 0.00236716] [-0.01023785 -0.00712993 0.00625245 -0.00160513] [-0.00768836 -0.00230031 0.00745056 0.01976111]]b2 = [[ 0.] [ 0.] [ 0.]] Forward propagation moduleLinear ForwardNow that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order: LINEAR LINEAR -&gt; ACTIVATION where ACTIVATION will be either ReLU or Sigmoid. [LINEAR -&gt; RELU] $\times$ (L-1) -&gt; LINEAR -&gt;SIGMOID (whole model) The linear forward module (vectorized over all the examples) computes the following equations: Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}where $A^{[0]} = X$. Exercise: Build the linear part of forward propagation. Reminder: The mathematical representation of this unit is $Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$. You may also find np.dot() useful. If your dimensions don’t match, printing W.shape may help. Code: 123456789101112131415161718192021# 1. Linear Forwarddef linear_forward(A, W, b): """ Implement the linear part of a layer's forward propagation Arguments: @A: activations from previous layer (or input data) of shape (size of previous layer, number of examples) @W: weights matrix: numpy array of shape (size of current layer, size of previous layer) @b: bias vector, numpy array of shape (size of the current layer, 1) Returns: @z: the input of activation function, also called pre-activation parameter @cache: a python dictionary containing "A", "W", and "b"; stored for computing the backword pass efficiently """ Z = np.dot(W, A) + b assert(Z.shape == (W.shape[0], A.shape[1])) cache = (A, W, b) return Z, cache Test: 1234A, W, b = linear_forward_test_case()Z, linear_cache = linear_forward(A, W, b)print("Z = " + str(Z)) Result: 1Z = [[ 3.26295337 -1.23429987]] Linear-Activation ForwardIn this notebook, you will use two activation functions: Sigmoid: $\sigma(Z) = \sigma(WA + b) = \frac{1}{1 + e^{-(WA + b)}}$. We have provided you with the sigmoid function. This function returns two items: the activation value &quot;a&quot; and a &quot;cache&quot; that contains &quot;Z&quot; (it’s what we feed in to the corresponding backward function). To use it you could just call: 1A, activation_cache = sigmoid(Z) ReLU: The mathematical formula for ReLu is $A = ReLU(Z) = max(0, Z)$. We have provided you with the relu function. This function returns two items: the activation value “A“ and a “cache“ that contains “Z“ (it’s what we will feed in to the corresponding backward function). To use it you could just call: 1A, activation_cache = relu(Z) For more convenience, you are going to group two functions (Linear and Activation) into one function (LINEAR-&gt;ACTIVATION). Hence, you will implement a function that does the LINEAR forward step followed by an ACTIVATION forward step. Exercise: Implement the forward propagation of the LINEAR -&gt; ACTIVATION layer. Mathematical relation is: $A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} + b^{[l]})$ where the activation &quot;g&quot; can be sigmoid() or relu(). Use linear_forward() and the correct activation function. Code: 1234567891011121314151617181920212223242526272829303132# 2. Linear-Activation Forwarddef linear_activation_forward(A_prev, W, b, activation): """ Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer Arguments: @A_prev: activations from previous layer (or input data) of shape (size of previous layer, number of examples) @W: weight matrix: numpy array of shape (size pf current layer, size of previous layer) @b: bias vector: numpy array of shape (size of the current layer, 1) @activation: the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: @A: the output of the activation function, also called the post-activation value @cache: a python tuple containing "linear_cache" and "activation_cache"; stored for computing the backward pass efficiently """ if activation == "sigmoid": # Inputs: A_prev, W, b # Outputs: A, activation_cache Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = sigmoid(Z) elif activation == "relu": # Inputs: A_prev, W, b # Outputs: A, activation_cache Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = relu(Z) assert(A.shape == (W.shape[0], A_prev.shape[1])) cache = (linear_cache, activation_cache) return A, cache Test: 1234567A_prev, W, b = linear_activation_forward_test_case()A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = "sigmoid")print("With sigmoid: A = " + str(A))A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = "relu")print("With ReLU: A = " + str(A)) Result: 12With sigmoid: A = [[ 0.96890023 0.11013289]]With ReLU: A = [[ 3.43896131 0. ]] Note: In deep learning, the “[LINEAR-&gt;ACTIVATION]” computation is counted as a single layer in the neural network, not two layers. L-Layer ModelFor even convenience when implementing the L-layer Neural Network, you will need a function that replicates the previous one linear_activation_forward with ReLU L-1 times, then follows that with one linear_activation_forwardwith SIGMOID. Exercise: Implement the forward propagation of the above model. Instruction: In the code below, the variable AL will denote $A^{[L]} = \sigma(Z^{[L]}) = \sigma(W^{[L]}A^{[L-1]} + b^{[L]})$. Tips: Use the functions you had previously written. Use a for loop to replicate [LINEAR-&gt;RELU] (L-1) times Don’t forget to keep track of the caches in the “caches” list. To add a new value c to a list, you can use list.append(c). Code: 123456789101112131415161718192021222324252627282930313233343536# L-layer Modeldef L_model_forward(X, parameters): """ Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1) -&gt; [LINEAR-&gt;SIGMOID] computation Arguments: @X -- data, numpy array of shape (input size, number of examples) @parameters -- output of initialize_parameters_deep() Returns: @AL -- last post-activation value @caches -- list of caches containing: every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2) the cache of linear_sigmoid_forward() (there is one, indexed L-1) """ caches = [] A = X L = len(parameters) // 2 # number of layers in the neural network # Implement [LINEAR -&gt; RELU] * (L-1). # Add "cache" to the "caches" list for l in range(1, L): A_prev = A A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = "relu") caches.append(cache) # Implement [LINEAR -&gt; SIGMOID] # Add "cache" to the "caches" list AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = "sigmoid") caches.append(cache) assert(AL.shape == (1, X.shape[1])) return AL, caches Test: 1234X, parameters = L_model_forward_test_case_2hidden()AL, caches = L_model_forward(X, parameters)print("AL = " + str(AL))print("Length of caches list = " + str(len(caches))) Result: 12AL = [[ 0.03921668 0.70498921 0.19734387 0.04728177]]Length of caches list = 3 Great! Now you have a full forward propagation that takes the input X and outputs a row vector AL containing your predictions. It also records all intermediate values in “caches”. Using AL, you can computes the cost of your predictions. Cost functionNow you will implement forward and backward propagation. You need to compute the cost, because you want to check if your model is actually learning. Exercise: Compute the cross-entropy cost J, using the following formula: J = -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(a^{[L] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right)) \tag{7}Code: 123456789101112131415161718192021# Cost functiondef compute_cost(AL, Y): """ Implement the cost function (the cross-entropy cost J) Arguments: AL -- probability vector corresponding to your label predictions, shape (1, number of examples) Y -- true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape of (1, number of examples) Returns: cost -- cross-entropy cost """ m = Y.shape[1] # Compute loss from aL and y cost = - (np.dot(Y, np.log(AL).T) + np.dot(1 - Y, np.log(1 - AL).T)) / m cost = np.squeeze(cost) # To make sure your cost's shape is waht we expect assert(cost.shape == ()) return cost Test: 123Y, AL = compute_cost_test_case()print("cost = " + str(compute_cost(AL, Y))) Result: 1cost = 0.414931599615397 Backward propagation moduleJust like with forward propagation, you will implement helper functions for backward propagation. Remember that backward propagation is used to calculate the gradient of the loss function with respect to the parameters. Reminder: The purple blocks represent the forward propagation, and the red blocks represent the backward propagation. Now, similar to forward propagation, you are going to build the backward propagation in three steps: LINEAR backward LINEAR -&gt; ACTIVATION backward where ACTIVATION computes the derivative of either the ReLU or sigmoid activation [LINEAR -&gt; RELU] ×× (L-1) -&gt; LINEAR -&gt; SIGMOID backward (whole model) Linear backwardFor layer l, the linear part is: $Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$ (followed by an activation). Suppose you have already calculated the derivative $dZ^{[l]} = \frac{\partial J}{\partial Z^{[l]}}$ . You want to get ($dW^{[l]}$, $db^{[l]}$, $dA^{[l]}$). The three output ($dW^{[l]}$, $db^{[l]}$, $dA^{[l-1]}$) are computed using the input $dZ^{[l]}$. Here are the formulas you need: Exercise： Use the 3 formulas above to implement linear_backward(). 1234567891011121314151617181920212223242526# 1. Linear backwarddef linear_backward(dZ, cache): """ Implement the linear portion of backward propagation for a single layer (layer l) Arguments: dZ -- Gradient of the cost with respect to the linear output (of current layer l) cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer Returns: dA -- Gradient of the cost with respect to the activation (of the prevous layer l-1), same shape as A_prev dW -- Gradient of the cost with respect to the W (current layer l), same shape as W db -- Gradient of the cost with respect to the b (current layer l), same shape as b """ A_prev, W, b = cache m = A_prev.shape[1] dW = np.dot(dZ, A_prev.T) / m db = np.sum(dZ, axis = 1, keepdims=True) / m dA_prev = np.dot(W.T, dZ) assert(dA_prev.shape == A_prev.shape) assert(dW.shape == W.shape) assert(db.shape == b.shape) return dA_prev, dW, db Test: 1234567# Set up some test inputsdZ, linear_cache = linear_backward_test_case()dA_prev, dW, db = linear_backward(dZ, linear_cache) print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db)) Result: 12345dA_prev = [[ 0.51822968 -0.19517421] [-0.40506361 0.15255393] [ 2.37496825 -0.89445391]]dW = [[-0.10076895 1.40685096 1.64992505]]db = [[ 0.50629448]] Linear-Activation backwardNext, you will create a function that merges the two helper functions: linear_backward and the backward step for the activation linear_activation_backward. To help you implement linear_activation_backward, we provided two backward functions: sigmoid_backward: Implements the backward propagation for SIGMOID unit. You can call it as follows: 1dZ = sigmoid_backward(dA, activation_cache) relu_backward: Implements the backward propagation for RELU unit. You can call it as follows: 1dZ = relu_backward(dA, activation_cache) If g(.) is the activation function, sigmoid_backward and relu_backward compute: $dZ^{[l]} = dA^{[l]} * g^{\prime}(Z^{[l]})$ Code: 123456789101112131415161718192021222324252627# 2. Linear-Activation backwarddef linear_activation_backward(dA, cache, activation): """ Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer Arguments: dA -- post-activation gradient for current layer 1 cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently activation -- the activation function to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: dA_prev -- Gradient of cost with respect to the activation (of the previous layer l - 1), same shape as A_prev dW -- Gradient of cost with respect to W (current layer l), same shape as W db -- Gradient of cost with respect to b (current layer l), same shape as b """ linear_cache, activation_cache = cache if activation == "relu": dZ = relu_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) elif activation == "sigmoid": dZ = sigmoid_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) return dA_prev, dW, db Test: 12345678910111213dA, linear_activation_cache = linear_activation_backward_test_case()dA_prev, dW, db = linear_activation_backward(dA, linear_activation_cache, activation = "sigmoid")print ("sigmoid:")print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db) + "\n")dA_prev, dW, db = linear_activation_backward(dA, linear_activation_cache, activation = "relu")print ("relu:")print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db)) Result: 12345678910111213sigmoid:dA_prev = [[ 0.11017994 0.01105339] [ 0.09466817 0.00949723] [-0.05743092 -0.00576154]]dW = [[ 0.10266786 0.09778551 -0.01968084]]db = [[-0.05729622]]relu:dA_prev = [[ 0.44090989 0. ] [ 0.37883606 0. ] [-0.2298228 0. ]]dW = [[ 0.44513824 0.37371418 -0.10478989]]db = [[-0.20837892]] L-Model BackwardNow you will implement the backward function for the whole network. Recall that when you implemented the L_model_forward function, at each iteration, you stored a cache which contains (X,W,b, and z). In the back propagation module, you will use those variables to compute the gradients. Therefore, in the L_model_backward function, you will iterate through all the hidden layers backward, starting from layer L. On each step, you will use the cached values for layer l to backward propagate through layer l. Figure 5 below shows the backward pass. Initializing backward propagation: To implement backward propagate through this network, we know that output is, $A^{[L]} = \sigma(Z^{[L]}) $ . Your code thus need to compute $dAL = \frac{\partial J}{\partial A^{[L]}}$. To do so, use this formula (derived using calculus which you don’t need in-depth knowledge of): 1dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL You can then use this post-activation gradient dAL to keep going backward. As seen in Figure 5, you can now feed in dAL into the LINEAR-&gt;SIGMOID backward function you implemented (which will use the cached values stored by the L_model_forward function). After that, you will have to use a for loop to iterate through all the other layers using the LINEAR-&gt;RELU backward function. You should store each dA, dW, and db in the grads dictionary. To do so, use this formula: grads[“dW” + str(l)] = $dW^{[l]}$ For example, for l=3 this would store $dW^{[l]}$ in grads[&quot;dW3&quot;]. Exercise: Implement backpropagation for the [LINEAR-&gt;RELU] × (L-1) -&gt; LINEAR -&gt; SIGMOID model. Code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 3. L-Model Backwarddef L_model_backward(AL, Y, caches): """ Implement the backword propagaiton for the [LINEAR-&gt;RELU] * (L - 1) -&gt; LINEAR -&gt; SIGMOID group Arguments: AL -- probability vector, output of the forward propagation (L_model_forward()) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) caches -- list of caches containing: every cache of linear_activation_forward() with "relu" (it's caches[1], for l in range(L - 1) i.e l = 0...L-2) the cache of linear_activation_foreward() with "sigmoid" (it's caches[L-1]) Returns: grads -- A dictionary with the gradients grads["dA" + str(l)] = ... grads["dW" + str(l)] = ... grads["db" + str(l)] = ... """ grads = &#123;&#125; L = len(caches) # the number of layers m = AL.shape[1] # the number of examples Y = Y.reshape(AL.shape) # Initializing the backpropagation dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL # Lth layer (SIGMOID -&gt; LINEAR) gradients. # Inputs: AL, Y, caches # Outputs: grads["dAL"], grads["dWL"], grads["dbL"] current_cache = caches[L-1] grads["dA" + str(L)], grads["dW" + str(L)], grads["db" + str(L)] = linear_activation_backward(dAL, current_cache, activation = "sigmoid") for l in reversed(range(L-1)): # lth layer: (RELU -&gt; LINEAR) gradients # Inputs: grads["dA" + str(l + 2)], caches # outputs: grads["dA" + str(l + 1)], grads["dW" + str(l + 1)], grads["db" + str(l + 1)] current_cache = caches[l] dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads["dA" + str(l + 2)], current_cache, activation = "relu") grads["dA" + str(l + 1)] = dA_prev_temp grads["dW" + str(l + 1)] = dW_temp grads["db" + str(l + 1)] = db_temp return grads Test: 123AL, Y_assess, caches = L_model_backward_test_case()grads = L_model_backward(AL, Y_assess, caches)print_grads(grads) Result: 123456789dW1 = [[ 0.41010002 0.07807203 0.13798444 0.10502167] [ 0. 0. 0. 0. ] [ 0.05283652 0.01005865 0.01777766 0.0135308 ]]db1 = [[-0.22007063] [ 0. ] [-0.02835349]]dA1 = [[ 0.12913162 -0.44014127] [-0.14175655 0.48317296] [ 0.01663708 -0.05670698]] Update ParametersIn this section you will update the parameters of the model, using gradient descent: where $\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary. Exercise: Implement update_parameters() to update your parameters using gradient descent. Instructions: Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for l = 1, 2, … L. Code: 1234567891011121314151617181920212223# 4. Update Parametersdef update_parameters(parameters, grads, learning_rate): """ Update parameters using gradient descent Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients, output of L_model_backward learning_rate -- learning rate of the gradient descent updatte rule Returns: parameters -- python dictionary containing your updated parameters parameters["W" + str(l)] = ... parameters["b" + str(l)] = ... """ L = len(parameters) // 2 # number of layers in the neural network for l in range(1, L + 1): parameters["W" + str(l)] = parameters["W" + str(l)] - learning_rate * grads["dW" + str(l)] parameters["b" + str(l)] = parameters["b" + str(l)] - learning_rate * grads["db" + str(l)] return parameters Test: 1234567parameters, grads = update_parameters_test_case()parameters = update_parameters(parameters, grads, 0.1)print ("W1 = "+ str(parameters["W1"]))print ("b1 = "+ str(parameters["b1"]))print ("W2 = "+ str(parameters["W2"]))print ("b2 = "+ str(parameters["b2"])) Result: 12345678W1 = [[-0.59562069 -0.09991781 -2.14584584 1.82662008] [-1.76569676 -0.80627147 0.51115557 -1.18258802] [-1.0535704 -0.86128581 0.68284052 2.20374577]]b1 = [[-0.04659241] [-1.28888275] [ 0.53405496]]W2 = [[-0.55569196 0.0354055 1.32964895]]b2 = [[-0.84610769]] ConclusionCongrats on implementing all the functions required for building a deep neural network! We know it was a long assignment but going forward it will only get better. The next part of the assignment is easier. In the next assignment you will put all these together to build two models: A two-layer neural network An L-layer neural network You will in fact use these models to classify cat vs non-cat images!]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>课后习题及编程练习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（二）-- 模型评估与选择]]></title>
    <url>%2F2019%2F08%2F05%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89--%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（二）模型评估与选择 经验误差与过拟合 错误率 (error rate)： 分类错误样本数占总样本数的比例 精度 (accuracy)： 分类正确样本数占总样本数的比例 误差 (error)： 学习器的实际预测输出与真实输出之间的差异 训练误差 (training error)/经验误差(empirical error)： 学习器在训练集上的误差 泛化误差(generalization error): 学习器在新样本上的误差 过拟合(overfitting): 学习能力过于强大。学习器把训练样本学得太好，导致将训练样本中自身含有的特点当成所有潜在样本都会具有的一般性质，从而训练后使得泛化性能下降 欠拟合(underfitting): 学习能力低下，对训练样本的一般性质尚未学好 评估方法理想： 通过评估学习器的泛化误差，选出泛化误差最小的学习器 实际： 泛化误差 只能通过测试集上的 测试误差 作为近似 机器学习的目的是产生泛化能力好的模型，那么什么样的模型才是泛化能力好的模型呢? 这需要按照一定的评估方法和度量指标去衡量。 给定一个包含m个样例的数据集 $ D = \{(x_1, y_1), (x_2, y_2), … ,(x_m, y_m)\}$ ,通过对D进行适当的处理，从中产生出训练集S和测试集T，测试集应该尽可能与训练集互斥，常见的方法有以下三种： 1.留出法 (hold-out)留出法： 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个集合作为测试集T，即 D=S∪T，S∩T=∅. 注意点： 要保持数据分布的一致性 分层采样 采用多次随机划分取均值的评估方法 训练集的比例应当适当(2/3 ~ 4/5) 2.交叉验证法 (cross validation)交叉验证法： 将数据集平均分成 K 份，并尽量保证每份数据分布一致。依次用其中 K - 1 份作为训练集，剩下的一份作为测试集。这样就有 K 组训练/测试集。从而可以进行 K 次训练和测试，返回K次测试结果的均值，也称为”K折交叉验证法” 注意点： K折交叉验证要随机使用不同的划分重复p次，最终取p次K折交叉验证的均值 留一法： 若令K = m, 则称为“留一法 (LOO)” 优点 不受随机样本划分的影响，因为m个样本只有唯一的方式划分为m个子集，即每个子集只含有一个样本 被实际评估的模型与期望评估的用D训练出的模型很相似，因为使用的训练集与初始数据集相比只少了一个样本 缺点 当数据集比较大时，训练m个模型的计算开销比较大 3.自助法 (bootstrapping)自助法： 给定包含m个样本的数据集 D，从 D 中进行有放回地采样产生包含 m 个样本的数据集 D’，这样 D 中大概有36.8%的样本不会出现在 D’ 中，将 D’ 用作训练集，D - D’ 用作测试集 (即在D’ 中没出现的样本) 优点： 实际评估模型和期望评估模型都使用 m 个训练样本 保证了仍有数据总量约1/3的、没在训练集中出现的样本用于测试 自助法在数据量较小，难以有效划分训练集/测试集时很有用 缺点： 自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差 性能度量性能度量(performance measure)： 衡量模型泛化能力的评价标准 回归任务 均方误差 分类任务 错误率和精度 查准率、查全率和F1 ROC和AUC 代价敏感错误率和代价曲线 1. 回归任务的性能度量 —— 均方误差离散样本： E(f;D) = \frac{1}{m}\sum_{i = 1}^{m}{(f(x_i)-y_i)^{2}}连续样本： 设 数据分布 D 和 概率密度 p(·) E(f;D) = \int_{x\sim D}{(f(x) - y)^2p(x)dx}性能度量方法： 通常，均方误差大的模型性能差，均方误差小的模型性能好。 2. 分类任务的性能度量1 —— 错误率与精度错误率(error rate)： 分类错误的样本占样本总数的比例 E(f;D) = \frac{1}{m}\sum_{i = 1}^{m}II{(f(x_i)\ne y_i)}精度(Accuracy)： 分类正确的样本占样本总数的比例 acc(f;D) = \frac{1}{m}\sum_{i = 1}^{m}II{(f(x_i)= y_i)} = 1 - E(f;D)性能度量方法： 通常，错误率低精度高的模型性能好，错误率高精度低的模型性能差。 3. 分类任务的性能度量2 —— 查准率、查全率与F1 查准率/准确率(Precision)： 【真正例样本数】与【预测结果是正例的样本数】的比值 P = \frac{TP}{TP + FP}查全率/召回率(Recall)： 【真正例样本数】与【真实情况是正例的样本数】的比值 R = \frac{TP}{TP + FN}解释： 查准率是在讲，挑出的好瓜里头，有多少是真正的好瓜，因此，若希望选出的瓜中好瓜的比例尽可能高，则查准率要高。 查全率是在讲，挑出的真正好瓜，占总共好瓜数的多少，因此，若希望将好瓜尽可能多的选出来，则查全率要高。 性能度量方法： 直接观察数值 建立P-R图 “P-R曲线”是描述查准/查全率变化的曲线 P-R曲线定义如下：根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值，如下图所示： 当曲线没有交叉的时候： 外侧学习器的性能优于内侧 当曲线有交叉的时候： 第一种方法是比较曲线下面积，但这个值不易估算 第二种方法是比较两条曲线的平衡点，平衡点是“查准率 = 查全率”时的取值，在图中表示为曲线和对角线的交点，平衡点在外侧的曲线的学习器性能优于内侧 第三种方法是F1度量和Fβ度量。F1是基于查准率与查全率的调和平均定义的，Fβ则是加权调和平均。 F1: 基于查准率和查全率的调和平均 \frac{1}{F1} = \frac{1}{2} · (\frac{1}{P} + \frac{1}{R}) F1 = \frac{2 \times P \times R}{P + R} = \frac{2 \times TP}{样例总数 + TP - TN}Fβ: 基于查准率和查全率的加权调和平均 \frac{1}{F_\beta} = \frac{1}{1 + \beta^2} · (\frac{1}{P} + \frac{\beta^2}{R}) F_\beta = \frac{(1 + \beta^2) \times P \times R}{(\beta^2 \times P) + R}说明： β &gt; 0 度量了查全率和查准率的相对重要性 β &gt; 1 时查全率有更大的影响 β &lt; 1 时查准率有更大的影响 在n个二分类混淆矩阵上综合考虑查准率和查全率： 方法一：宏(macro)： 先在各混淆矩阵上分别计算出查准率和查全率，记为 $(P_1, R_1)$, $(P_2, R_2)$, …… ,$(P_n, R_n)$, 再计算平均值，这样就得到了： 宏查准率(macro-P) macro\_P = \frac{1}{n}\sum_{i = 1}^{n}{P_i} 宏查全率(macro-R) macro\_R = \frac{1}{n}\sum_{i = 1}^{n}{R_i} 宏F1(macro-F1) macro\_F1 = \frac{2 \times macro\_P \times macro\_R}{macro\_P + macro\_R} 方法二：微(micro)： 先将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、FN的平均值，分别记为 $\overline{TP}$，$\overline{FP}$，$\overline{TN}$，$\overline{FN}$，再基于这些平均值计算出： 微查准率(micro-P) micro\_P = \frac{\overline{TP}}{\overline{TP} + \overline{FP}} 微查全率(micro-R) micro\_R = \frac{\overline{TP}}{\overline{TP} + \overline{FN}} 微F1(micro-F1) micro\_F1 = \frac{2 \times micro\_P \times micro\_R}{micro\_P + micro\_R} 4. 分类任务的性能度量3 —— ROC与AUC与P-R图相同，ROC图通过对测试样本设置不同的阈值并与预测值比较，划分出正例和反例。再计算出真正例率和假正例率。P-R图逐个将样本作为正例，ROC图逐次与阈值进行比较后划分正例。本质上，都是将测试样本进行排序。 真正例率(TPR): 【真正例样本数】与【真实情况是正例的样本数】的比值 TPR = \frac{TP}{TP + FN}假正例率(FPR): 【假正例样本数】与【真实情况是反例的样本数】的比值 FPR = \frac{FP}{TN + FP}ROC: 全称是“受试者工作特征” (Receiver Operating Characteristic)曲线，以真正例率为纵轴，以假正例率为横轴 性能度量方法： 绘制ROC曲线 当曲线没有交叉的时候： 外侧曲线的学习器性能优于内侧 当曲线有交叉的时候： 比较ROC面积，如AUC AUC = \frac{1}{2}\sum_{i = 1}^{m - 1}{(x_{i+1}-x_{i})\times(y_{i}+y_{i+1})} 5. 分类任务的性能度量4 —— 代价敏感错误率与代价曲线前面介绍的性能度量，大都隐式地假设了“均等代价”，而为权衡不同类型错误所造成的不同损失，应为错误赋予：“非均等代价”。 下图为二分类代价矩阵，其中 $cost_{ij}$ 表示将第i类样本预测为第j类样本的代价 代价敏感(cost-sensitive)错误率: E(f;D;cost)=\frac{1}{m}(\sum_{x_i \in D^+} II (f(x_i) \ne y_i) \times cost_{01} + \sum_{x_i \in D^-} II(f(x^i) \ne y_i) \times cost_{10})性能度量的方法：绘制代价曲线 代价曲线的横轴是正例概率代价 $P(+)cost$，纵轴是归一化代价 $cost_{norm}$ P(+)_{cost} = \frac{p\times cost_{01}}{p\times{cost_{01}} + (1-p)\times{cost_{10}}} cost_{norm} = \frac{FNR \times p\times cost_{01} + FPR \times (1 - p) \times cost_{10}}{p \times cost_{01} + (1 - p) \times cost_{10}} 比较检验机器学习中性能比较需要考虑的因素： 性能比较的目标是比较泛化性能，但通过实验评估方法得到的是测试集上的性能，两者的对比结果可能未必相同 测试集上的性能受测试集本身的影响较大，使用不同大小的测试集会得到不同的结果，即使相同大小的测试集，若包含的测试样例不同，则测试结果也会不同 很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会不同 统计假设检验 (hypothesis test)： 为进行机器学习的性能比较提供了重要依据 基于假设检验的结果可以推断出：若在测试集上观察到学习器 A 比学习器 B 好，则 A 的泛化性能是否在统计意义上优于 B，以及这个结论的把握有多大 假设检验交叉验证 t 检验McNemar 检验Friedman 检验与 Nemenyi 检验 偏差与方差“偏差—方差分解” ：是解释学习器泛化性能的重要工具，在解释这个概念之前，先明确以下各变量名： 测试样本：$\boldsymbol x$ 测试样本 $\boldsymbol x$ 在数据集中的标记：$y_D$ 测试样本 $\boldsymbol x$ 的真实标记：$y$ 训练集：$D$ 从训练集 $D$ 中学得的模型：$f$ 模型 $f$ 在测试样本 $\boldsymbol x$上的预测输出：$f(x; D)$ 数据分布：Ɗ 1. $\overline f(x)$ (预测输出的期望) ：学习算法的期望预测 \overline f(x) = E_Ɗ[f(x;D)]2. $Variance$ (方差)：使用样本数相同的不同训练集产生的方差 var(x) = E_Ɗ[(f(x;D) - \overline f(x))^2]方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响 3. $Bias$ (偏差)：期望输出与真实标记之间的差别 bias^2(x) = (\overline f(x) - y)^2偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力 4. $\varepsilon^2$ (噪声)：数据集标记和真实标记的方差 \varepsilon ^2 = E_Ɗ[(y_Ɗ - y)^2]噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度 噪声数据主要来源是训练数据的错误标签的情况以及输入数据某一维不确定的情况。 为了方便讨论，假定噪声期望为0，则对算法的期望泛化误差进行分解可得： 故： E(f;D) = bias^2 (x) + var(x) + \varepsilon^2 即：泛化误差 = 偏差 + 方差 + 噪声 二项分布参数p的检验设某事件发生的概率为 p ， p 未知，作 m 次独立试验，每次观察该事件是否发生，以X记该事件发生的次数，则X服从二项分布 B(m, p)，现根据X检验如下假设： H_0: p \le p_0\\ H_1: p > p_0由二项分布本身的特性可知：p越小，X取到较小值的概率越大。因此，对于上述假设，一个直观上合理的检验为： \varphi: 当 X \le C 时接受H_0，否则拒绝H_0其中，$C \in N$表示事件最大发生次数。此检验对应的功效函数为： \begin{align} \beta_\varphi(p) &= P(X > C)\\ &= 1 - P(X \le C)\\ &= 1 -\sum_{i = 0}^{C} \begin{pmatrix} m\\ i \end{pmatrix} p^i(1-p)^{m-i}\\ &=\sum_{i=C+1}^{m} \begin{pmatrix} m\\ i \end{pmatrix} p^i(1-p)^{m-i}\\ \end{align}由于“p越小，X取到较小值的概率越大“可以等价表示为：$P(X \le C)$ 是关于p的减函数，所以$\beta_\varphi (p) = P(X &gt; C) = 1 - P(X \le C)$ 是关于p的增函数，那么当 $p \le p_0$ 时，$\beta_\varphi (p_0) $ 即为 $\beta_\varphi (p) $ 的上确界。 又因为，检验水平 $\alpha$ 默认取最小可能水平，所以在给定检验水平 $\alpha$ 时，可以通过如下方程解得满足检验水平$\alpha$ 的整数C: \alpha = sup\{\beta_\varphi(p)\}显然，当$p \le p_0$时： \begin{align} \alpha &= sup\{\beta_\varphi(p)\}\\ &= \beta_\varphi(p_0)\\ &= \sum_{i = C+1}^{m} \begin{pmatrix} m\\ i \end{pmatrix} (p_0)^i(1 - p_0)^{m-i} \end{align}对于此方程，通常不一定正好解得一个整数C使得方程成立，常见的情况是存在这样一个 $\overline {C}$ 使得： \sum_{i = \overline C+1}^{m} \begin{pmatrix} m\\ i \end{pmatrix} (p_0)^i(1 - p_0)^{m-i} < \alpha \sum_{i = \overline C}^{m} \begin{pmatrix} m\\ i \end{pmatrix} (p_0)^i(1 - p_0)^{m-i} > \alpha此时，C只能取 $\overline {C}$ 或者 $\overline {C} + 1$ ，若 C 取 $\overline C$ ，则相当于升高了校验水平 $\alpha$ , 若 C 取 $\overline{C} + 1$ 则相当于降低了检验水平 $\alpha$ ，具体如何取舍需要结合实际情况，但是通常为了减小犯第一类错误的概率，会倾向于令 C 取 $\overline C + 1$. 下面考虑如何求解 $\overline C$: 易证 $\beta_{\varphi}(p_0)$ 是关于 C 的减函数，所以再结合上述关于 $\overline C$ 的两个不等式，易推得： \overline C = minC \quad s.t.\ \sum_{i = C+1}^{m}{p_0^i + (1-p_0)^{m-i}} < \alpha]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习》西瓜书学习笔记（一）-- 绪论]]></title>
    <url>%2F2019%2F08%2F05%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89--%20%E7%BB%AA%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[《机器学习》西瓜书学习笔记（一）绪论 引言 学习算法(learning algorithm): 机器学习研究的主要内容，是关于在计算机上从数据产生“模型”的算法，即“学习算法”. 学习算法的作用： 基于提供的经验数据产生模型 面对新情况，模型可提供相应的判断 模型(model): 泛指从数据中学到的结果 学习器(learner): 学习算法在给定参数空间上的实例化 基本术语 数据集(data set): 一组记录的集合 示例(instance)/样本(sample)/特征向量(feature vector): 每条记录（关于一个事件或对象的描述）或空间中的每一个点（对应一个坐标向量） 属性(attribute)/特征(feature): 反映事件或对象在某方面的表现或性质的事项 属性值(attribute value): 属性上的取值 属性空间(attribute space)/样本空间(sample space)/输入空间(input space): 属性张成的空间 维数(dimensionality): 属性的个数 学习(learning)/训练(training): 从数据中学得模型的过程 训练数据(training data): 训练过程中使用的数据 训练样本(training sample): 训练数据中的每个样本 训练集(training set): 训练样本组成的集合 假设(hypothesis): 学得模型对应了关于数据的某种潜在的规律 真相/真实(ground-truth): 这种潜在规律的自身 预测(prediction): 获得训练样本的结果信息，才能建立“预测”的模型 标记(label): 关于示例结果的信息 样例(example): 拥有了标记信息的示例 标记空间(label space): 所有标记的集合 分类(classification): 预测的离散值 二分类(binary classification) 正类(positive class) 负类(negative class) 多分类(multi-class classification) 回归(regression): 预测的连续值 测试(testing): 学的模型后，使用其进行预测的过程 测试样本(testing sample): 被预测的样本 学习任务分类： 监督学习(supervised learning): 有标记 分类 (classification) 回归 (regression) 无监督学习(unsupervised learning): 无标记 聚类 (clustering) 泛化(generalization)能力: 学得模型适用于新样本的能力 假设空间 科学推理: 归纳(induction): 特殊 —-&gt; 一般，泛化 假设(deduction): 一般 —-&gt; 特殊，特化 归纳学习： 广义：从样例中学习 狭义：从训练数据学得概念，概念学习、概念形成 归纳偏好 归纳偏好: 机器学习算法在学习过程中对某种类型假设的偏好 任何一个有效的机器学习算法必有其归纳偏好 “奥卡姆剃刀”原则: 若有多个假设与观察一致，则选最简单的那个 “没有免费的午餐”定理(NFL定理): 总误差与学习算法无关]]></content>
      <categories>
        <category>《机器学习》西瓜书学习笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[课程一(Neural Networks and Deep Learning), 第三周(Shallow neural networks)——Programming assignment 3、Planar data classification with a hidden layer]]></title>
    <url>%2F2019%2F08%2F03%2F%E8%AF%BE%E7%A8%8B%E4%B8%80(Neural%20Networks%20and%20Deep%20Learning)%2C%20%E7%AC%AC%E4%B8%89%E5%91%A8(Shallow%20neural%20networks)%E2%80%94%E2%80%94Programming%20assignment%203%E3%80%81Planar%20data%20classification%20with%20a%20hidden%20layer%2F</url>
    <content type="text"><![CDATA[Planar data classification with a hidden layer Welcome to your week 3 programming assignment. It’s time to build your first neural network, which will have a hidden layer. You will see a big difference between this model and the one you implemented using logistic regression. You will learn how to: Implement a 2-class classification neural network with a signal hidden layer Use units with a non-linear activation function, such as tanh Compute the cross entropy loss Implement forward and backward propagation PackagesLet’s first import all the packages that you will need during this assignment. numpy is the fundamental packages for scientific computing with Python. sklearn provides simple and efficient tools for data mining and data and analysis. matplotlib is a library for plotting graphs in Python. testCases provides some test examples to assess the correctness of your functions planar_utils provide various useful functions used in this assignment Code: 12345678910# Package importsimport numpy as npimport matplotlib.pyplot as pltfrom testCases_v2 import *import sklearnimport sklearn.datasetsimport sklearn.linear_modelfrom planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasetsnp.random.seed(1) # set a seed so that the results are consistent DatasetFirst, let’s get the dataset you will work on. The following code will load a “flower” 2-class dataset into variables X and Y. Code: 123456789101112# load datasetdef load_dataset(): ''' load planar dataset Arguments: Returns: @X: your dataset features @Y: your dataset labels ''' X, Y = load_planar_dataset() # load dataset return X, Y Visualize the dataset using matplotlib. The data looks like a “flower” with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. Code: 123# Visualize the data:plt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral);plt.show() Result: You have: a numpy array (matrix) X that contains your features (x1, x2) a numpy array (vector) Y that contains your labels (red: 0, blue: 1) Let’s first get a better sense of what our data is like. Exercise: How many training examples do you have? In addition, what is the shape of the variables Xand Y ? Code: 123456shape_X = X.shapeshape_Y = Y.shapem = X.shape[1] # training set sizeprint ('The shape of X is: ' + str(shape_X))print ('The shape of Y is: ' + str(shape_Y))print ('I have m = %d training examples!' % (m)) Result: 123The shape of X is: (2, 400)The shape of Y is: (1, 400)I have m = 400 training examples! Simple Logistic RegressionBefore building a full neural network, let’s first see how logistic regression performs on this problem. You can use sklearn’s built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset. Code: 123# Train the logistic regression classifierclf = sklearn.linear_model.LogisticRegressionCV();clf.fit(X.T, Y.T); You can now plot the decision boundary of these models. Run the code below. Code: 12345678# Plot the decision boundary for logistic regressionplot_decision_boundary(lambda x: clf.predict(x), X, Y)plt.title("Logistic Regression")plt.show()# Print accuracyLR_predictions = clf.predict(X.T)print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) + '% ' + "(percentage of correctly labelled datapoints)") Result: 1Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints) Interpretation: The dataset is not linearly separable, so logistic regression doesn’t perform well. Hopefully a neural network will do better. Let’s try this now. Neural Network modelLogistic regression did not work well on the “flower dataset”. You are going to train a Neural Network with a single hidden layer. Here is our model: Mathematically: For one example x(i): Given the predictions on all the examples, you can also compute the cost J as follows: J = -\frac{1}{m}\sum_{i = 0}^{m}{(y^{(i)}{log(a^{[2](i)})} + (1 - y^{(i)}){log(1 - a^{[2](i)}))}}Reminder: The general methodology to build a Neural Network is to: Define the neural network structure (# of input units, # of hidden units, etc). Initialize the model’s parameters Loop: Implement forward propagation Compute loss Implement backward propagation to get the gradients Update parameters (gradient descent) You often build helper functions to compute steps 1-3 and then merge them into one function we call nn_model(). Once you’ve built nn_model() and learned the right parameters, you can make predictions on new data. Defining the neural network structureExercise: Define three variables: 123- n_X: the size of the input layer- n_h: the size of the hidden layer (set this to 4)- n_y: the size of the output layer Hint: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4. Code: 12345678910111213141516171819# Defining the neural network structuredef layer_sizes(X, Y): ''' Defining the neural network structure Arguments: @x: input dataset of shape (input size, number of examples) @y: labels of shape (output size, number of examples) Returns: @n_x: the size of input layer @n_h: the size of hidden layer @n_y: the size of output layer ''' n_x = X.shape[0] n_h = 4 n_y = Y.shape[0] return (n_x, n_h, n_y) Test: 12345X_assess, Y_assess = layer_sizes_test_case()(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)print("The size of the input layer is: n_x = " + str(n_x))print("The size of the hidden layer is: n_h = " + str(n_h))print("The size of the output layer is: n_y = " + str(n_y)) Result: 123The size of the input layer is: n_x = 5The size of the hidden layer is: n_h = 4The size of the output layer is: n_y = 2 Initialize the model’s parametersExercise: Implement the function initialize_parameters(). Instructions: Make sure your parameters’ sizes are right. Refer to the neural network figure above if you needed. You will initialize the weights matrices with random values. Use: np.random.randn (a, b) * 0.01 to randomly initialize a matrix of shape (a, b). You will initialize the bias vectors as zeros. Use: np.zeros((a, b)) to initialize a matrix of shape (a, b) with zeros. Code: 1234567891011121314151617181920212223242526272829303132333435# Initialize the model's parametersdef initialize_parameters(n_x, n_h, n_y): ''' Initialize the model's parameters Argument: @n_x: the size of the input layer @n_h: the size of the hidden layer @n_y: the size of the output layer Returns: @params: python dictionary containing your parameters: @W1: weight matrix of shape (n_h, n_x) @b1: bias vector of shape (n_h, 1) @W2: weight matrix of shape (n_y, n_h) @b2: bias vector of shape (n_y, 1) ''' np.random.seed(2) # set a seed so that the result are consisent W1 = np.random.randn(n_h, n_x) * 0.01 b1 = np.zeros((n_h, 1)) W2 = np.random.randn(n_y, n_h) * 0.01 b2 = np.zeros((n_y, 1)) assert(W1.shape == (n_h, n_x)) assert(b1.shape == (n_h, 1)) assert(W2.shape == (n_y, n_h)) assert(b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters Test: 1234567n_x, n_h, n_y = initialize_parameters_test_case()parameters = initialize_parameters(n_x, n_h, n_y)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) Result: 12345678910W1 = [[-0.00416758 -0.00056267] [-0.02136196 0.01640271] [-0.01793436 -0.00841747] [ 0.00502881 -0.01245288]]b1 = [[ 0.] [ 0.] [ 0.] [ 0.]]W2 = [[-0.01057952 -0.00909008 0.00551454 0.02292208]]b2 = [[ 0.]] The LoopExercise 1: Implement forward_propagation() . Instructions: Look above at the mathematical representation of your classifier. You can use the function sigmoid() . It is built-in (imported) in the notebook (planar_utils.py). You can use the function tanh() . It is part of the numpy library. The steps you have to implement are: Retrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using paramters[&quot;...&quot;] . Implement Forward Propagation. Compute Z[1], A[1], Z[2] and A[2] (the vector of all your predictions on all the examples in the training set). Values needed in the back propagation are stored in “cache“. The cache will be given as an input to the back propagation function. Code: 123456789101112131415161718192021222324252627282930313233# Implement forward propagationdef forward_propagation(X, parameters): ''' implement forward propagation Argument: @X: input data of size (n_x, m) @parameters: python dictionary containing your parameters Returns: @A2: The sigmoid output of the second activation @cache: a dictionary containing "Z1", "A1", "Z2" and "A2" ''' # Retrieve each parameter from the dictionary "parameters" W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Implement forward propagation to calculate A2 Z1 = np.dot(W1, X) + b1 A1 = tanh(Z1) Z2 = np.dot(W2, A1) + b2 A2 = sigmoid(Z2) assert(A2.shape == (1, X.shape[1])) cache = &#123;"Z1": Z1, "A1": A1, "Z2": Z2, "A2": A2&#125; return A2, cache Test: 12345X_assess, parameters = forward_propagation_test_case()A2, cache = forward_propagation(X_assess, parameters)# Note: we use the mean here just to make sure that your output matches ours. print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2'])) Result: 10.262818640198 0.091999045227 -1.30766601287 0.212877681719 Now that you have computed A[2] (in the Python variable “A2”), which contains a[2](i) for every examples, you can compute the cost function as follows: J = -\frac{1}{m}\sum_{i = 0}^{m}{(y^{(i)}{log(a^{[2](i)})} + (1 - y^{(i)}){log(1 - a^{[2](i)}))}}Exercise 2: Implement compute_cost() to compute the value of the cost J. Instructions: There are many ways to implement the cross-entropy loss (交叉熵损失). To help you, we give you how we would have implemented: -\sum_{i = 0}^{m}{y^{(i)}log(a^{[2](i)})}12logprobs = np.multiply(np.log(A2), Y)cost = -np.sum(logprobs) # no need to use a for loop Code: 123456789101112131415161718192021222324# Implement compute costdef compute_cost(A2, Y, parameters): ''' Computes the cross-entropy cost Arguments: @A2: The sigmoid output of the second activation, of shape(1, number of examples) @Y: "true" labels vector of shape (1, number of examples) @parameters: python dictionary containing your parameters W1, b1, W2, b2 Returns: @cost: cross-entropy cost ''' m = Y.shape[1] #number of examples # Compute the cross-entropy cost logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), 1 - Y) cost = -1 / m * np.sum(logprobs) cost = np.squeeze(cost) # make sure cost is the dimension we expect # E.g. turns [[17]] into 17 assert(isinstance(cost, float)) return cost Test: 123A2, Y_assess, parameters = compute_cost_test_case()print("cost = " + str(compute_cost(A2, Y_assess, parameters))) Result: 1cost = 0.693058761 Using the cache computed during forward propagation, you can now implement backward propagation. Exercise 3: Implement the function backward_propagation(). Instructions: Backward propagation is usually the hardest (most mathematical) part in deep learning. o help you, here again is the slide from the lecture on backward propagation. You’ll want to use the six equations on the right of this slide, since you are building a vectorized implementation. Tips: To compute dZ1 you’ll need to compute g[1]′(Z[1]). Since g[1](.)is the tanh activation function, if a=g[1](z) then g[1]′(z)=1−a2. So you can compute g[1]′(Z[1]) using (1 - np.power(A1, 2)). Code: 1234567891011121314151617181920212223242526272829303132333435363738# Implement the function backward propagrationdef backward_propagation(parameters, cache, X, Y): ''' Implement the backward propagation Arguments: @parameters: python dictionary containing out parameters (W1, b1, W2, b2) @cache: a dictionary containing "Z1", "A1", "Z2", "A2". @X: input data of shape (2, number of examples) @Y: "true" labels vector of shape(1, number of examples) Returns: @grads: python dictionary containing your gradients with respect to different parameters ''' m = X.shape[1] # retrieve W1 and W2 from the dictionary parameters W1 = parameters["W1"] W2 = parameters["W2"] # retrieve A1 and A2 from dictionary "cache" A1 = cache["A1"] A2 = cache["A2"] # Backward propagation: calculate dW1, db1, dW2, db2 dZ2 = A2 - Y dW2 = 1 / m * np.dot(dZ2, A1.T) db2 = 1 / m * np.sum(dZ2, axis = 1, keepdims = True) dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2)) dW1 = 1 / m * np.dot(dZ1, X.T) db1 = 1 / m * np.sum(dZ1, axis = 1, keepdims = True) grads = &#123;"dW1": dW1, "db1": db1, "dW2": dW2, "db2": db2&#125; return grads Test: 1234567parameters, cache, X_assess, Y_assess = backward_propagation_test_case()grads = backward_propagation(parameters, cache, X_assess, Y_assess)print ("dW1 = "+ str(grads["dW1"]))print ("db1 = "+ str(grads["db1"]))print ("dW2 = "+ str(grads["dW2"]))print ("db2 = "+ str(grads["db2"])) Result: 12345678910dW1 = [[ 0.00301023 -0.00747267] [ 0.00257968 -0.00641288] [-0.00156892 0.003893 ] [-0.00652037 0.01618243]]db1 = [[ 0.00176201] [ 0.00150995] [-0.00091736] [-0.00381422]]dW2 = [[ 0.00078841 0.01765429 -0.00084166 -0.01022527]]db2 = [[-0.16655712]] Exercise 4: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2). General gradient descent rule: θ=θ−α∂J∂θ where α is the learning rate and θ represents a parameter. Illustration: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Code: 12345678910111213141516171819202122232425262728293031323334def update_parameters(parameters, grads, learning_rate = 1.2): ''' Update parameters using the gradient descent update rule Arguments: @parameters: python dictionary containing your parameters @grads: python dictionary containing your gradient with respect to different parameters @learning_rate: the learning rate used to update parameters Returns: @parameters: python dictionary containing your updated parameters ''' # Retrieve each parameter from the dictionary "parameters" W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Retrieve each grident from the dictionary "grads" dW1 = grads["dW1"] db1 = grads["db1"] dW2 = grads["dW2"] db2 = grads["db2"] # Update rule for each parameter W1 = W1 - learning_rate * dW1 b1 = b1 - learning_rate * db1 W2 = W2 - learning_rate * dW2 b2 = b2 - learning_rate * db2 parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters Test: 1234567parameters, grads = update_parameters_test_case()parameters = update_parameters(parameters, grads)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) Result: 12345678910W1 = [[-0.00643025 0.01936718] [-0.02410458 0.03978052] [-0.01653973 -0.02096177] [ 0.01046864 -0.05990141]]b1 = [[ -1.02420756e-06] [ 1.27373948e-05] [ 8.32996807e-07] [ -3.20136836e-06]]W2 = [[-0.01041081 -0.04463285 0.01758031 0.04747113]]b2 = [[ 0.00010457]] Integrate part 5.1, 5.2 and 5.3 in nn_model()Question: Build your neural network model in nn_model(). Instructions: The neural network model has to use the previous functions in the right order. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# Merge all function into the nerual network modeldef nn_model(X, Y, n_h, num_iterations = 10000, print_cost = False): ''' Build your neural network in nn_model Arguments: @X: dataset of shape (2, number of examples) @Y: labels of shape (1, number of exampless) @n_h: size of the hidden layer @num_iterations: Number of iterations in gradient descent loop @print_cost: if True, print the cost every 100 iterations Returns: @parameters: parameters learnt by the model. They can then be used to predict ''' np.random.seed(3) n_x = layer_sizes(X, Y)[0] n_y = layer_sizes(X, Y)[2] # Initialize paramters, then retrieve W1, b1, W2, b2. # Inputs: "n_x, n_h, n_y" # Outputs: " parameters(W1, b1, W2, b2)" parameters = initialize_parameters(n_x, n_h, n_y) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation. # Inputs: "X, parameters". # Outputs: "A2, cache" A2, cache = forward_propagation(X, parameters) # Cost Function. # Inputs: "A2, Y, parameters" # Output: "cost" cost = compute_cost(A2, Y, parameters) # Backward propagation. # Inputs: "parameters, cache, X, Y" # Outputs: "grads" grads = backward_propagation(parameters, cache, X, Y) # Update parameters by using gradient descent. # Inputs: "parameters, grads" # Outputs: "parameters" parameters = update_parameters(parameters, grads, learning_rate=1.2) # Print the cost every 1000 iterations: if print_cost and i % 1000 == 0: print("Cost after iterations %i: %f" %(i, cost)) return parameters Test: 123456X_assess, Y_assess = nn_model_test_case()parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"])) Result: 1234567891011121314151617181920Cost after iteration 0: 0.692739Cost after iteration 1000: 0.000218Cost after iteration 2000: 0.000107Cost after iteration 3000: 0.000071Cost after iteration 4000: 0.000053Cost after iteration 5000: 0.000042Cost after iteration 6000: 0.000035Cost after iteration 7000: 0.000030Cost after iteration 8000: 0.000026Cost after iteration 9000: 0.000023W1 = [[-0.65848169 1.21866811] [-0.76204273 1.39377573] [ 0.5792005 -1.10397703] [ 0.76773391 -1.41477129]]b1 = [[ 0.287592 ] [ 0.3511264 ] [-0.2431246 ] [-0.35772805]]W2 = [[-2.45566237 -3.27042274 2.00784958 3.36773273]]b2 = [[ 0.20459656]] PredictionsQuestion: Use your model to predict by building predict(). Use forward propagation to predict results. Reminder: Code: 12345678910111213141516# Use forward propagation to predict resultsdef predict(parameters, X): ''' Using the learned parameters, predicts a class for each example in X Arguments: @parameters: python dictionary containing your paramters @X: input data of size (n_x, m) Returns: @predictions: vector of predictions of our model (red: 0 / bule: 1) ''' # Computes probabilities using forward propagation, and classfies to 0/1 using 0.5 as threshold A2 = forward_propagation(X, parameters)[0] predictions = (A2 &gt; 0.5) return predictions Test: 1234parameters, X_assess = predict_test_case()predictions = predict(parameters, X_assess)print("predictions mean = " + str(np.mean(predictions))) Result: 1predictions mean = 0.666666666667 It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of `n_h` hidden units. Code: 12345678910# Build a model with a n_h-dimensional hidden layerparameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)# Plot the decision boundaryplot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)plt.title("Decision Boundary for hidden layer size " + str(4))# Print accuracypredictions = predict(parameters, X)print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%') Result: 1234567891011Cost after iteration 0: 0.693048Cost after iteration 1000: 0.288083Cost after iteration 2000: 0.254385Cost after iteration 3000: 0.233864Cost after iteration 4000: 0.226792Cost after iteration 5000: 0.222644Cost after iteration 6000: 0.219731Cost after iteration 7000: 0.217504Cost after iteration 8000: 0.219454Cost after iteration 9000: 0.218607Accuracy: 90% Interpretation: Accuracy is really high compared to Logistic Regression. The model has learned the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression. Now, let’s try out several hidden layer sizes. Tuning hidden layer size(optional/ungraded exercise)Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes. Code: 123456789101112# This may take about 2 minutes to runplt.figure(figsize=(16, 32))hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]for i, n_h in enumerate(hidden_layer_sizes): plt.subplot(5, 2, i+1) # ？？？ plt.title('Hidden Layer of size %d' % n_h) parameters = nn_model(X, Y, n_h, num_iterations = 5000) plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) # ??? predictions = predict(parameters, X) accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) print ("Accuracy for &#123;&#125; hidden units: &#123;&#125; %".format(n_h, accuracy)) Result: 1234567Accuracy for 1 hidden units: 67.5 %Accuracy for 2 hidden units: 67.25 %Accuracy for 3 hidden units: 90.75 %Accuracy for 4 hidden units: 90.5 %Accuracy for 5 hidden units: 91.25 %Accuracy for 20 hidden units: 90.0 %Accuracy for 50 hidden units: 90.25 % Interpretation: The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to fits the data well without also incurring noticable overfitting. You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. You’ve learnt to: Build a complete neural network with a hidden layer Make a good use of a non-linear unit Implemented forward propagation and backpropagation, and trained a neural network See the impact of varying the hidden layer size, including overfitting. Nice work! Source Code]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>课后习题及编程练习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何上传本地代码到github]]></title>
    <url>%2F2019%2F08%2F02%2F%E5%A6%82%E4%BD%95%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E4%BB%A3%E7%A0%81%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[如何上传本地代码到github 第一步：去github上创建自己的仓库Repository，创建后的页面如下图所示： 点击Clone or download按钮，复制弹出的地址git@github.com:***/***.git 注意要用SSH地址。 第二步：建立git仓库，cd到你的本地项目根目录下，执行git命令1git init 第三步：将项目的所有文件添加到仓库中1git add . 第四步：将添加的文件提交到仓库中1git commit -m &quot;注释语句&quot; 第五步：将本地仓库关联到github上1git remote add origin git@github.com:***/test.git 第六步：上传之前，先要pull一下，执行如下命令：1git pull origin master 第七步：上传代码到github远程仓库1git push -u origin master 更新代码第一步：查看当前的 git 仓库状态，执行如下命令1git status 第二步：更新全部1git add * 第三步：输入更新说明1git commit -m &quot;更新说明&quot; 第四步：先 git pull，拉取当前分支最新代码1git pull 第五步：push 到远程 master 分支上1git push origin master 不出意外，打开github，可发现已经同步了 如何在 VScode 上提交代码到 github第一步： 第二步： 第三步： 祝你成功！]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[课程一(Neural Networks and Deep Learning)，第二周（Basics of Neural Network programming）—— Programming assignment 2、Logistic Regression with a Neural Network mindset]]></title>
    <url>%2F2019%2F08%2F01%2F%E8%AF%BE%E7%A8%8B%E4%B8%80(Neural%20Networks%20and%20Deep%20Learning)%EF%BC%8C%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%88Basics%20of%20Neural%20Network%20programming%EF%BC%89%E2%80%94%E2%80%94%20Programming%20assignment%202%E3%80%81Logistic%20Regression%20with%20a%20Neural%20Network%20mindset%2F</url>
    <content type="text"><![CDATA[Logistic Regression with a Neural Network mindset Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning. Instructions: Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so. You will learn to: Build the general architecture of a learning algorithm, including: Initializing parameters Calculating the cost function and its gradient Using an optimization algorithm (gradient descent) Gather all three functions above into a main function, in the right order. PackagesFirst, let’s run the cell below to import all the packages that you will need during this assignment. numpy is the fundamental package for scientific computing with Python. h5py is a common package to interact with a dataset that is stored on an H5 file. matplotlib is a famous library to plot graphs in Python. PIL and scipy are used here to test your model with your own picture at the end. code ————-&gt; 1234567import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset Overview of the Problem setProblem Statement: You are given a dataset (“data.h5”) containing: a training set of m_train images labeled as cat (y = 1) or non-cat (y = 0) a test set of m_test images labeled as cat or non-cat each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px) You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat. Let’s get more familiar with the dataset. Load the data by running the following code. 12# Loading the data (cat/non-cat)train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset() We added “_orig” at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don’t need any preprocessing). Many software bugs in deep learning come from having matrix/vector dimensions that don’t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. code: 1234567891011121314151617181920# Data preprocessingdef data_Preprocess(): ''' load dataset and preprocess dataset Argument: Return: @train_set_x: your train set features @train_set_y: your train set labels @test_set_x: your test set features @test_set_y: your test set labels ''' train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset() # load dataset from dataset files train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T # vectorize the features of each examples train_set_x = train_set_x_flatten/255 test_set_x = test_set_x_flatten/255 # normalize the features vector return train_set_x, train_set_y, test_set_x, test_set_y, classes **What you need remember:** Common steps for pre-processing a new dataset are: Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …) Reshape the datasets such that each examples is now a vector of size (num_px * num_px * 3, 1) “Standardize” the data General Architecture of the learning algorithmIt’s time to design a simple algorithm to distinguish cat images from non-cat images. You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why Logistic Regression is actually a very simple Neural Network! Mathematical expression of the algorithm: For one examples x(i): The cost is the computed by summing over all training examples: Key steps: In this exercise, you will carry out the following steps: Initialize the parameters of the model Learn the parameters for the model by minimizing the cost Use the learned parameters to make predictions (on the test set) Analyze the results and conclude Building the parts of our algorithmThe main steps for building a Neural Network are: Define the model structure (such as number of input features) Initialize the model’s parameters Loop: Calculate current loss (forward propagation) Calculate current gradient (backward propagation) Update parameters (gradient descent) You often build 1-3 separately and integrate them into one function we call model(). Helper functionsExercise: using your code from “Python Basics”, implement sigmoid(). As you’ve seen in the figure above, you need to compute sigmoid(w^T + b) = \frac{1}{1 + e^{-(w^T + b)}}to make predictions. Use np.exp(). code: 123456789101112# Helper functionsdef sigmoid(z): ''' Compute the sigmoid of z Arguments: @z: A scalar or numpy array of any size Return: @s: sigmoid(z) ''' s = 1 / (1 + np.exp(-z)) return s Initializing parametersExercise: Implement parameter initialization in the cell below. You will initialize w as a vector of zeros. If you don’t know what numpy function to use, loop up np.zeros() in the Numpy library’s documentation. code: 1234567891011121314151617# Initializing parametersdef initialize_with_zeros(dim): ''' This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0 Argument: @dim: size of the w vector we want Returns: @w: initialized vector of shape (dim, 1) @b: initialized scalar (corresponds to the bias) ''' w = np.zeros((dim, 1)) b = 0 assert(w.shape == (dim, 1)) assert(isinstance(b, float) or isinstance(b, int)) return w, b Forward and Backward propagationNow that your parameters are initialized, you can do the “forward” and “backward” propagation steps for learning the parameters. Exercise: Implement a function propagation() that computes the cost function and its gradient. Hints(提示): Forward Propagation: You get x You compute $ A = \sigma(w^TX + b) = (a^{(0)},a^{(1)},…a^{(m-1)},a^{(m)})$ You calculate the cost function: $J = - \frac{1}{m}\sum_{i = 1}^{m}{y^{(i)}log(a^{(i)}) +(1 - y^{(i)})log(1 - a^{(i)}) }$ Here are the two formulas you will be using: code: 123456789101112131415161718192021222324252627282930313233# Forward and Backword propagationdef propagate(w, b, X, Y): ''' Implement the cost function and its gradient for the propagation explained above Arguments: @w: weights, a numpy array of size (num_px * num_px * 3, 1) @b: bias, a scalar @X: data of size (num_px * num_px * 3, number of examples) @Y: true "label" vector(containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: @cost: negative log-likelihood cost for logistic regression @dw: gradient of the loss with respect to w, thus same shape as w @db: gradient of the loss with respect to b, thus same shape as b ''' m = X.shape[1] # nx A = sigmoid(np.add(np.dot(w.T, X), b)) # compute activation cost = -(np.dot(Y, np.log(A).T) + np.dot(1 - Y, np.log(1 - A).T)) / m # compute cost dw = np.dot(X, (A-Y).T) / m # compute dw db = np.sum(A - Y) / m # compute db assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) # 把shape中为1的维度去掉 assert(cost.shape == ()) # 判断剩下的是否为空 grads = &#123;"dw": dw, "db": db&#125; return grads, cost Optimization You have initialized your parameters. You are also able to compute a cost function and its gradient. Now, you want to update the parameters using gradient descent. Exercise: Write down the optimization function. The goal is to learn w and b by minimizing the cost function J. For a parameter θ, the update rule is θ = θ - α dθ, where α is the learning rate. Code: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#Optimizationdef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): ''' This function optimizes w and b by running a gradient descent algorithm Arguments: @w: weights, a numpy array of size (num_px * num_px * 3, 1) @b: bias, a scalar @X: data of shape (num_px * num_px * 3, number of examples) @Y: ture "label" vector (contaning 0 if non-cat, 1 if cat), of shape(1, number of examples) @num_iterations: number of iterations of the optimization loop @learning_rate: learning rate of the gradient descent update rule @print_cost: True to print the loss every 100 steps Returns: @params: dictionary containing the weights w and bias b @grads: dictionary containing the gradients of the weights and bias with respect to the cost function @costs: list of all the costs computed during the optimization, this will be used to plot the learning curve Tips: You basically need to write down two steps and iterate through them: (1) Calculate the cost and the gradient for the current parameters. Use propagate() (2) Update the parameters using gradient descent rule for w and b ''' costs = [] for i in range(num_iterations): # Cost and gradient calculation grads, cost = propagate(w, b, X, Y) # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # Update rule w = w - learning_rate * dw b = b - learning_rate * db # Record the costs if i % 100 == 0: costs.append(cost) # Print the cost every 100 training examples if print_cost and i % 100 == 0: print("Cost after iteration %d: %f" %(i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs PredictExercise: The previous function will output the learned w and b. We are able to use w and b to predict the labels for dataset X. Implement the predict() function. There is two steps to computing predictions: Calculate: $ \hat{Y} = A = \sigma(w^TX + b)$ Convert the entries of a into 0 (if activation &lt;= 0.5) or 1 (if activation &gt; 0.5), stores the predictions in a vector Y_Prediction. Code: 12345678910111213141516171819202122232425262728293031323334#Graded function: predictdef predict(w, b, X): ''' Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) Arguments: @w: weights, a numpy array of size (num_px * num_px * 3, 1) @b: bias, a scalar @X: data of shape (num_px * num_px * 3, number of examples) Returns: @Y_prediction: a numpy array (vector) containing all prediction (0 / 1) for the examples in X ''' m = X.shape[1] # number of examples Y_prediction = np.zeros((1, m)) w = w.reshape(X.shape[0], 1) # Compute vector "A" predicting the probabilities of a cat being present in the picture A = sigmoid(np.add(np.dot(w.T, X), b)) # (1, m) for i in range(A.shape[1]): # Convert probabilities A[0, i] to actual predictions p[0, i] if A[0, i] &lt;= 0.5: Y_prediction[0, i] = 0 else: Y_prediction[0, i] = 1 assert(Y_prediction.shape == (1, m)) return Y_prediction **What you need remember:** You've implemented several functions that: initialize (w, b) Optimize the loss iteratively to learn parameters (w, b): computing the cost and its gradient updating the parameters using gradient descent Use the learned (w, b) to predict the labels for a given set of examples Merge all functions into a modelYou will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order. Exercise: Implement the model function. Use the following notation: Y_prediction for your predictions on the test set Y_prediction_train for your predictions on the train set w, costs, grads for the outputs of optimize() Code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Merge all functions into a modeldef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): ''' Builds the logistic regression model by calling the function you have implemented previously Arguments: @X_train: training set represented by a numpy array of shape (num_px * num_px * 3, m_train) @Y_train: training labels represented by a numpy array (vector) of shape (1, m_train) @X_test: test set represented by a numpy array of shape (num_px * num_px * 3, m_test) @Y_test: test labels represented by a numpy array (vetcor) of shape (1, m_test) @num_iterations: hyperparmeter representing the number of iterations to optimize the parameters @learning_rate: hyperparmeter representing the learning rate used in the update rule of optimize() @print_cost: Set to true to print the cost every 100 iterations Returns: @d: dictionary containing information about the model ''' # initailize parameters with zeros w,b = initialize_with_zeros(X_train.shape[0]) # num_px * num_px * 3, w: (dim, 1), b: a scalar # Gradient descent parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost) # Retrieve parameters w and b from dictionary "parameters" w = parameters["w"] b = parameters["b"] # Predict test/train set examples Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) # Print train/test Errors print("train accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100)) print("test accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) d = &#123;"costs" : costs, "Y_prediction_test" : Y_prediction_test, "Y_prediction_train" : Y_prediction_train, "w" : w, "b" : b, "learning_rate" : learning_rate, "num_iterations" : num_iterations &#125; return d Run the following cell to train your model: 1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations =2000, learning_rate = 0.005, print_cost = True) The results are as follows: 12345678910111213141516171819202122Cost after iteration 0: 0.693147Cost after iteration 100: 0.584508Cost after iteration 200: 0.466949Cost after iteration 300: 0.376007Cost after iteration 400: 0.331463Cost after iteration 500: 0.303273Cost after iteration 600: 0.279880Cost after iteration 700: 0.260042Cost after iteration 800: 0.242941Cost after iteration 900: 0.228004Cost after iteration 1000: 0.214820Cost after iteration 1100: 0.203078Cost after iteration 1200: 0.192544Cost after iteration 1300: 0.183033Cost after iteration 1400: 0.174399Cost after iteration 1500: 0.166521Cost after iteration 1600: 0.159305Cost after iteration 1700: 0.152667Cost after iteration 1800: 0.146542Cost after iteration 1900: 0.140872train accuracy: 99.04306220095694 %test accuracy: 70.0 % Comment: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test error is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you’ll build an even better classifier next week! Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Let's also plot the cost function and the gradients: 1234567# Plot learning curve (with costs)costs = np.squeeze(d['costs'])plt.plot(costs)plt.ylabel('cost')plt.xlabel('iterations (per hundreds)')plt.title("Learning rate =" + str(d["learning_rate"]))plt.show() Interpretation: You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting. Further analysisCongratulations on building your first image classification model. Let’s analyze it further, and examine possible choices for the learning rate α. Choice of learning rateReminder: In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate α determines how rapidly we update the parameters. If the learning rate is too large we may “overshoot” the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That’s why it is crucial to use a well-tuned learning rate. Let’s compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens. Code: 1234567891011121314151617learning_rates = [0.01, 0.001, 0.0001]models = &#123;&#125;for i in learning_rates: print ("learning rate is: " + str(i)) models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False) print ('\n' + "-------------------------------------------------------" + '\n')for i in learning_rates: plt.plot(np.squeeze(models[str(i)]["costs"]), label= str(models[str(i)]["learning_rate"]))plt.ylabel('cost')plt.xlabel('iterations')legend = plt.legend(loc='upper center', shadow= True)frame = legend.get_frame()frame.set_facecolor('0.90')plt.show() Result: 1234567891011121314151617learning rate is: 0.01train accuracy: 99.52153110047847 %test accuracy: 68.0 %-------------------------------------------------------learning rate is: 0.001train accuracy: 88.99521531100478 %test accuracy: 64.0 %-------------------------------------------------------learning rate is: 0.0001train accuracy: 68.42105263157895 %test accuracy: 36.0 %------------------------------------------------------- Interpretation: Different learning rates give different costs and thus different predictions results. If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). A lower cost doesn’t mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy. In deep learning, we usually recommend that you: Choose the learning rate that better minimizes the cost function. If your model overfits, use other techniques to reduce overfitting. (We’ll talk about this in later videos.) Source Code]]></content>
      <categories>
        <category>Coursera深度学习笔记</category>
        <category>课后习题及编程练习</category>
      </categories>
      <tags>
        <tag>Coursera深度学习笔记</tag>
      </tags>
  </entry>
</search>
